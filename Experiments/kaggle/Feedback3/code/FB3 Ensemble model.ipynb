{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyP4lbMcdpUsT0cmKNq8cdrh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"bxC-cLpZXlc1"},"outputs":[],"source":["from google.colab import drive\n","\n","drive.mount('/content/drive/')"]},{"cell_type":"code","source":["import os\n","os.chdir(\"drive/\")\n","os.chdir('My Drive')\n","os.chdir('Kaggle')\n","os.chdir('Feedback3')"],"metadata":{"id":"LE_9TkG9Xsl7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["OUTPUT_DIR = './fb3-ensemble/'\n","if not os.path.exists(OUTPUT_DIR):\n","    os.makedirs(OUTPUT_DIR)"],"metadata":{"id":"AM-LAuccXsjT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Library"],"metadata":{"id":"FbrXq8LwX_Hs"}},{"cell_type":"code","source":["# ====================================================\n","# Library\n","# ====================================================\n","import os\n","import gc\n","import re\n","import ast\n","import sys\n","import copy\n","import json\n","import time\n","import math\n","import string\n","import pickle\n","import random\n","import joblib\n","import itertools\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","import scipy as sp\n","import numpy as np\n","import pandas as pd\n","pd.set_option('display.max_rows', 500)\n","pd.set_option('display.max_columns', 500)\n","pd.set_option('display.width', 1000)\n","from tqdm.auto import tqdm\n","from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n","from sklearn.metrics import mean_squared_error"],"metadata":{"id":"Jg12JisrXsgh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ====================================================\n","# Utils\n","# ====================================================\n","def MCRMSE(y_trues, y_preds):\n","    scores = []\n","    idxes = y_trues.shape[1]\n","    for i in range(idxes):\n","        y_true = y_trues[:,i]\n","        y_pred = y_preds[:,i]\n","        score = mean_squared_error(y_true, y_pred, squared=False) # RMSE\n","        scores.append(score)\n","    mcrmse_score = np.mean(scores)\n","    return mcrmse_score, scores\n","\n","\n","def get_score(y_trues, y_preds):\n","    mcrmse_score, scores = MCRMSE(y_trues, y_preds)\n","    return mcrmse_score, scores\n","\n","\n","def get_logger(filename=OUTPUT_DIR+'train'):\n","    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n","    logger = getLogger(__name__)\n","    logger.setLevel(INFO)\n","    handler1 = StreamHandler()\n","    handler1.setFormatter(Formatter(\"%(message)s\"))\n","    handler2 = FileHandler(filename=f\"{filename}.log\")\n","    handler2.setFormatter(Formatter(\"%(message)s\"))\n","    logger.addHandler(handler1)\n","    logger.addHandler(handler2)\n","    return logger\n","\n","LOGGER = get_logger()\n","\n","\n","def seed_everything(seed=42):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    \n","seed_everything(seed=42)"],"metadata":{"id":"PKt5tr0RXsdQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Data Loading"],"metadata":{"id":"pJw8UCPFYSd5"}},{"cell_type":"code","source":["# ====================================================\n","# Data Loading\n","# ====================================================\n","train = pd.read_csv('./train.csv')\n","test = pd.read_csv('./test.csv')\n","submission = pd.read_csv('./sample_submission.csv')\n","\n","print(f\"train.shape: {train.shape}\")\n","display(train.head())\n","print(f\"test.shape: {test.shape}\")\n","display(test.head())\n","print(f\"submission.shape: {submission.shape}\")\n","display(submission.head())"],"metadata":{"id":"bv2EIYbPXsZ_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Load Out-of-folds"],"metadata":{"id":"Msh-mjRAYWBL"}},{"cell_type":"code","source":["deberta_family_dir = './deberta_family_oof'\n","oof_files = os.listdir(deberta_family_dir)\n","oof_files.sort()\n","\n","print(oof_files)\n","\n","target_cols=['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']\n","oofs = [pd.read_pickle(f'{deberta_family_dir}/{oof_files[i]}') for i in range(10)]"],"metadata":{"id":"q4LkH1_hXsVM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Preprocess"],"metadata":{"id":"mqbhjJzIEkDI"}},{"cell_type":"code","source":["for i in range(10):\n","    oof = oofs[i]\n","    oof.rename(columns={\n","        \"pred_cohesion\": f\"cohesion{i}\", \n","        \"pred_syntax\": f\"syntax{i}\", \n","        \"pred_vocabulary\": f\"vocabulary{i}\", \n","        \"pred_phraseology\": f\"phraseology{i}\", \n","        \"pred_grammar\": f\"grammar{i}\", \n","        \"pred_conventions\": f\"conventions{i}\"\n","        }, inplace=True)\n","    display(oofs[i].head(3))"],"metadata":{"id":"CUZXDTQtXsO6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cols_to_drop = ['full_text', 'fold'] + target_cols\n","for i in range(1, 10):\n","    oofs[i] = oofs[i].drop(cols_to_drop, axis=1)"],"metadata":{"id":"TZ-dL6pcGwRy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["oof = pd.merge(oofs[0], oofs[1], on=['text_id'])\n","for i in range(2, 10):\n","    oof = pd.merge(oof, oofs[i], on=['text_id'])"],"metadata":{"id":"uWVZfKrkXsR9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["oof.head(10)"],"metadata":{"id":"djzy5FZnXsMI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["targets = ['text_id']\n","for col in target_cols:\n","    targets = targets + [f'{col}{i}' for i in range(0, 10)]\n","y_cols = ['text_id'] + target_cols\n","\n","X = oof[targets]\n","Y = oof[y_cols]"],"metadata":{"id":"clCpGpvNXsJn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Train"],"metadata":{"id":"SNDlGYV_IzGH"}},{"cell_type":"code","source":["import pickle\n","from joblib import dump, load\n","\n","\n","from sklearn.linear_model import LinearRegression\n","from sklearn.ensemble import RandomForestRegressor\n","\n","import xgboost as xgb"],"metadata":{"id":"g_jUbaZaXsHG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["models = [xgb.XGBRegressor(objective=\"reg:squarederror\", random_state=42, booster='dart') for _ in range(6)] # [gbtree, gblinear, dart]\n","# models = [LinearRegression() for _ in range(6)]\n","model_name_base = 'XGBRegressor'"],"metadata":{"id":"hqQIb8mmIz5-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["total_mcsmse = 0\n","\n","for col, model in zip(target_cols, models):\n","    x_cols = [f'{col}{i}' for i in range(0, 10)]\n","    y_cols = [col]\n","\n","    Xx = X[x_cols]\n","    Yy = Y[y_cols]\n","\n","    model = model.fit(Xx, Yy)\n","    score = model.score(Xx, Yy)\n","    preds1 = model.predict(Xx)\n","    preds2 = model.predict(Xx)\n","    preds3 = model.predict(Xx)\n","\n","    preds = preds1 * 0.1 + preds2 * 0.2 + preds3 * 0.7\n","    # print(Yy.to_numpy())\n","    # print(preds.reshape(-1, 1))\n","\n","    dump(model, f'{OUTPUT_DIR}{model_name_base}_{col}.pkl')\n","    # clf = load('filename.joblib')\n","\n","    mcrmse_score, _ = get_score(Yy.to_numpy(), preds.reshape(-1, 1))\n","    print(f\"{col} -> mcrmse_score={mcrmse_score}\")\n","    total_mcsmse += mcrmse_score\n","\n","    # print(model.coef_)\n","\n","\n","print('Total MCRMSE Score:', total_mcsmse / 6)"],"metadata":{"id":"YCLFRDT1JEb-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["| Model | MCR MSE |\n","| ----- | ------- |\n","| LinearRegression | 0.44499491163317245 |\n","| RandomForestRegressor | 0.17236466948046347 |\n","| XGB | 0.41306675952329736 |\n","\n","\n","-----\n","\n","1. LinearRegression\n","\n","cohesion -> mcrmse_score=0.47525212701691993\n","\n","syntax -> mcrmse_score=0.4387305454780827\n","\n","vocabulary -> mcrmse_score=0.4078519873744786\n","\n","phraseology -> mcrmse_score=0.447128036166492\n","\n","grammar -> mcrmse_score=0.4622838507361844\n","\n","conventions -> mcrmse_score=0.4387229230268769\n","\n","Total MCRMSE Score: 0.44499491163317245\n","\n","2. RandomForestRegressor\n","\n","cohesion -> mcrmse_score=0.18427490983107225\n","\n","syntax -> mcrmse_score=0.16950429329718303\n","\n","vocabulary -> mcrmse_score=0.15831520752852293\n","\n","phraseology -> mcrmse_score=0.17482226061765166\n","\n","grammar -> mcrmse_score=0.1795295031339569\n","\n","conventions -> mcrmse_score=0.16885819873788274\n","\n","Total MCRMSE Score: 0.17236466948046347\n","\n","3. XGB Regressor\n","\n","cohesion -> mcrmse_score=0.44134209921795237\n","\n","syntax -> mcrmse_score=0.40534709617943\n","\n","vocabulary -> mcrmse_score=0.37747949472382825\n","\n","phraseology -> mcrmse_score=0.4189509214088031\n","\n","grammar -> mcrmse_score=0.4281746852031484\n","\n","conventions -> mcrmse_score=0.4071062604066224\n","\n","Total MCRMSE Score: 0.41306675952329736"],"metadata":{"id":"W_Rod-ogLoLv"}},{"cell_type":"code","source":["for col in target_cols:\n","    x_cols = [f'{col}{i}' for i in range(0, 10)]\n","    y_cols = [col]\n","\n","    Xx = X[x_cols]\n","    Yy = Y[y_cols]\n","\n","    clf = load(f'{OUTPUT_DIR}{model_name_base}_{col}.pkl')"],"metadata":{"id":"UkWE1H02KDbu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"lNM3whryILHZ"},"execution_count":null,"outputs":[]}]}