{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"1juyGzghsMxC"},"outputs":[],"source":["# !pip install kaggle\n","# from google.colab import files\n","# files.upload()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":770,"status":"ok","timestamp":1667297873564,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"IqLBSZ137D_w","outputId":"1a5333ea-c573-45cb-8653-cf0a8fa7d812"},"outputs":[{"name":"stdout","output_type":"stream","text":["Tue Nov  1 10:17:52 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   36C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21745,"status":"ok","timestamp":1667297895305,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"2qqloURAtVXk","outputId":"0aa3dadb-700b-4c2b-9c45-b9d1938940a4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive/\n"]}],"source":["from google.colab import drive\n","\n","drive.mount('/content/drive/')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bQ42V6jOttQy"},"outputs":[],"source":["# !ls -1ha kaggle.json"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3140,"status":"ok","timestamp":1667297898441,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"9AEsu99A1RV_","outputId":"0ee5386a-0c4e-4579-fa56-e810b795d6d0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting iterative-stratification\n","  Downloading iterative_stratification-0.1.7-py3-none-any.whl (8.5 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from iterative-stratification) (1.21.6)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from iterative-stratification) (1.0.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from iterative-stratification) (1.7.3)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->iterative-stratification) (1.2.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->iterative-stratification) (3.1.0)\n","Installing collected packages: iterative-stratification\n","Successfully installed iterative-stratification-0.1.7\n"]}],"source":["!pip install iterative-stratification"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13725,"status":"ok","timestamp":1667297912160,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"5fQBEA6xxpMw","outputId":"e1b5b482-76e4-4e41-c479-ec6c3ab947ee"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.23.1-py3-none-any.whl (5.3 MB)\n","\u001b[K     |████████████████████████████████| 5.3 MB 35.0 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[K     |████████████████████████████████| 7.6 MB 89.3 MB/s \n","\u001b[?25hCollecting huggingface-hub<1.0,>=0.10.0\n","  Downloading huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n","\u001b[K     |████████████████████████████████| 163 kB 77.8 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.10.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.10.1 tokenizers-0.13.1 transformers-4.23.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 23.8 MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.97\n"]}],"source":["!pip install transformers\n","!pip install sentencepiece"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12323,"status":"ok","timestamp":1667297924465,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"bhO7fjARwhAB","outputId":"d0b9a572-f0ca-4469-bc63-10f644910858"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: tokenizers in /usr/local/lib/python3.7/dist-packages (0.13.1)\n","Collecting wandb\n","  Downloading wandb-0.13.4-py2.py3-none-any.whl (1.9 MB)\n","\u001b[K     |████████████████████████████████| 1.9 MB 34.9 MB/s \n","\u001b[?25hCollecting shortuuid>=0.5.0\n","  Downloading shortuuid-1.0.9-py3-none-any.whl (9.4 kB)\n","Requirement already satisfied: protobuf!=4.0.*,!=4.21.0,<5,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n","Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from wandb) (57.4.0)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n","Collecting setproctitle\n","  Downloading setproctitle-1.3.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n","Collecting pathtools\n","  Downloading pathtools-0.1.2.tar.gz (11 kB)\n","Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n","Collecting docker-pycreds>=0.4.0\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Collecting GitPython>=1.0.0\n","  Downloading GitPython-3.1.29-py3-none-any.whl (182 kB)\n","\u001b[K     |████████████████████████████████| 182 kB 91.2 MB/s \n","\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (6.0)\n","Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n","Collecting sentry-sdk>=1.0.0\n","  Downloading sentry_sdk-1.10.1-py2.py3-none-any.whl (166 kB)\n","\u001b[K     |████████████████████████████████| 166 kB 79.8 MB/s \n","\u001b[?25hCollecting gitdb<5,>=4.0.1\n","  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n","\u001b[K     |████████████████████████████████| 63 kB 2.0 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.1.1)\n","Collecting smmap<6,>=3.0.1\n","  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2022.9.24)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n","Collecting sentry-sdk>=1.0.0\n","  Downloading sentry_sdk-1.10.0-py2.py3-none-any.whl (166 kB)\n","\u001b[K     |████████████████████████████████| 166 kB 101.0 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.10-py2.py3-none-any.whl (162 kB)\n","\u001b[K     |████████████████████████████████| 162 kB 91.5 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.9-py2.py3-none-any.whl (162 kB)\n","\u001b[K     |████████████████████████████████| 162 kB 102.0 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.8-py2.py3-none-any.whl (158 kB)\n","\u001b[K     |████████████████████████████████| 158 kB 87.6 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.7-py2.py3-none-any.whl (157 kB)\n","\u001b[K     |████████████████████████████████| 157 kB 109.7 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.6-py2.py3-none-any.whl (157 kB)\n","\u001b[K     |████████████████████████████████| 157 kB 98.3 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.5-py2.py3-none-any.whl (157 kB)\n","\u001b[K     |████████████████████████████████| 157 kB 108.8 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.4-py2.py3-none-any.whl (157 kB)\n","\u001b[K     |████████████████████████████████| 157 kB 109.2 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.3-py2.py3-none-any.whl (157 kB)\n","\u001b[K     |████████████████████████████████| 157 kB 104.1 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.2-py2.py3-none-any.whl (157 kB)\n","\u001b[K     |████████████████████████████████| 157 kB 103.0 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.1-py2.py3-none-any.whl (157 kB)\n","\u001b[K     |████████████████████████████████| 157 kB 94.1 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.0-py2.py3-none-any.whl (156 kB)\n","\u001b[K     |████████████████████████████████| 156 kB 88.9 MB/s \n","\u001b[?25hBuilding wheels for collected packages: pathtools\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=ae65118bf4f68ffb3005719425a316f7b19a0be487dbf8a759bd5ace0560f0a2\n","  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n","Successfully built pathtools\n","Installing collected packages: smmap, gitdb, shortuuid, setproctitle, sentry-sdk, pathtools, GitPython, docker-pycreds, wandb\n","Successfully installed GitPython-3.1.29 docker-pycreds-0.4.0 gitdb-4.0.9 pathtools-0.1.2 sentry-sdk-1.9.0 setproctitle-1.3.2 shortuuid-1.0.9 smmap-5.0.0 wandb-0.13.4\n"]}],"source":["!pip3 install tokenizers wandb"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dXxUaSKftuvv"},"outputs":[],"source":["# !mkdir -p ~/.kaggle\n","# !cp kaggle.json ~/.kaggle/\n","# # Permission Warning 이 일어나지 않도록 \n","# !chmod 600 ~/.kaggle/kaggle.json\n","# # 본인이 참가한 모든 대회 보기 \n","# !kaggle competitions list"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V7QsENfyuT0y"},"outputs":[],"source":["import os\n","os.chdir(\"drive/\")\n","os.chdir('My Drive')\n","os.chdir('Kaggle')\n","os.chdir('Feedback3')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hUeBd2eGt1bW"},"outputs":[],"source":["# !kaggle competitions download -c feedback-prize-english-language-learning"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SvSSwcRstln8"},"outputs":[],"source":["# !unzip feedback-prize-english-language-learning.zip\n","\n","# !ls"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fl4G_mNCu1ed"},"outputs":[],"source":["OUTPUT_DIR = './fb3-dbv3b-outputs/'\n","if not os.path.exists(OUTPUT_DIR):\n","    os.makedirs(OUTPUT_DIR)"]},{"cell_type":"markdown","metadata":{"id":"xOMdcujXv9Z_"},"source":["## CFG"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fyzSgrTOqFVD"},"outputs":[],"source":["class CFG:\n","    wandb=True\n","    competition='FB3'\n","    _wandb_kernel='bluehills'\n","    debug=False\n","    apex=True\n","    print_freq=20\n","    model=\"microsoft/deberta-v3-base\" #[\"microsoft/deberta-v3-large\", \"microsoft/deberta-large-mnli\", \"microsoft/deberta-v2-xlarge\", \"microsoft/deberta-v2-xlarge-mnli\"]\n","    gradient_checkpointing=True\n","    scheduler='cosine' # ['linear', 'cosine']\n","    batch_scheduler=True\n","    num_cycles=0.5\n","    num_warmup_steps=50\n","    epochs=5\n","    encoder_lr=2e-5\n","    decoder_lr=2e-5\n","    min_lr=1e-6\n","    eps=1e-6\n","    betas=(0.9, 0.999)\n","    batch_size=16\n","    max_len=512\n","    weight_decay=0.01\n","    weight_decay_decoder=0.00\n","    gradient_accumulation_steps=1\n","    max_grad_norm=1000\n","    target_cols=['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']\n","    seed=42\n","    n_fold=10\n","    trn_fold=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n","    train=True\n","\n","    # CPMP\n","    num_workers=1\n","    sync_bn = False\n","\n","\n","if CFG.debug:\n","    CFG.epochs = 2\n","    CFG.trn_fold = [0]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":228},"executionInfo":{"elapsed":1010544,"status":"ok","timestamp":1667298935687,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"XA6QLrMQv-mc","outputId":"38f9c83e-786b-4ccc-e199-c6d455f59a85"},"outputs":[{"name":"stdout","output_type":"stream","text":["login to wandb\n"]},{"name":"stderr","output_type":"stream","text":["ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"]},{"data":{"application/javascript":["\n","        window._wandbApiKey = new Promise((resolve, reject) => {\n","            function loadScript(url) {\n","            return new Promise(function(resolve, reject) {\n","                let newScript = document.createElement(\"script\");\n","                newScript.onerror = reject;\n","                newScript.onload = resolve;\n","                document.body.appendChild(newScript);\n","                newScript.src = url;\n","            });\n","            }\n","            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n","            const iframe = document.createElement('iframe')\n","            iframe.style.cssText = \"width:0;height:0;border:none\"\n","            document.body.appendChild(iframe)\n","            const handshake = new Postmate({\n","                container: iframe,\n","                url: 'https://wandb.ai/authorize'\n","            });\n","            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n","            handshake.then(function(child) {\n","                child.on('authorize', data => {\n","                    clearTimeout(timeout)\n","                    resolve(data)\n","                });\n","            });\n","            })\n","        });\n","    "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit: "]},{"name":"stdout","output_type":"stream","text":["··········\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbluehills\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"data":{"text/html":["Tracking run with wandb version 0.13.4"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/drive/My Drive/Kaggle/Feedback3/wandb/run-20221101_103532-3gls29tj</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href=\"https://wandb.ai/bluehills/Feedback3-Public/runs/3gls29tj\" target=\"_blank\">microsoft/deberta-v3-base</a></strong> to <a href=\"https://wandb.ai/bluehills/Feedback3-Public\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["# ====================================================\n","# wandb\n","# ====================================================\n","if CFG.wandb:\n","    import wandb\n","    try:\n","        # from kaggle_secrets import UserSecretsClient\n","        # user_secrets = UserSecretsClient()\n","        # secret_value_0 = user_secrets.get_secret(\"wandb_api\")\n","        # wandb.login(key=secret_value_0)\n","        print('login to wandb')\n","        wandb.login()\n","        anony = None\n","    except:\n","        anony = \"must\"\n","        print('If you want to use your W&B account, go to Add-ons -> Secrets and provide your W&B access token. Use the Label name as wandb_api. \\nGet your W&B access token from here: https://wandb.ai/authorize')\n","\n","\n","    def class2dict(f):\n","        return dict((name, getattr(f, name)) for name in dir(f) if not name.startswith('__'))\n","\n","    run = wandb.init(project='Feedback3-Public', \n","                     name=CFG.model,\n","                     config=class2dict(CFG),\n","                     group=CFG.model,\n","                     job_type=\"train\",\n","                     anonymous=anony)"]},{"cell_type":"markdown","metadata":{"id":"qR8EYRj4wX8U"},"source":["## Library"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5132,"status":"ok","timestamp":1667298940813,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"a5048-HowFGB","outputId":"1194a221-52ec-4390-b69b-386a5aa18a35"},"outputs":[{"name":"stdout","output_type":"stream","text":["tokenizers.__version__: 0.13.1\n","transformers.__version__: 4.23.1\n","env: TOKENIZERS_PARALLELISM=true\n"]}],"source":["# ====================================================\n","# Library\n","# ====================================================\n","import os\n","import gc\n","import re\n","import ast\n","import sys\n","import copy\n","import json\n","import time\n","import math\n","import string\n","import pickle\n","import random\n","import joblib\n","import itertools\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","import argparse\n","\n","import scipy as sp\n","import numpy as np\n","import pandas as pd\n","pd.set_option('display.max_rows', 500)\n","pd.set_option('display.max_columns', 500)\n","pd.set_option('display.width', 1000)\n","from tqdm.auto import tqdm\n","from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n","from sklearn.metrics import mean_squared_error\n","from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n","\n","# PyTorch\n","import torch\n","import torch.nn as nn\n","from torch.nn import Parameter\n","import torch.nn.functional as F\n","from torch.optim import Adam, SGD, AdamW\n","from torch.utils.data import DataLoader, Dataset\n","\n","# CPMP imports for DDP\n","from torch.nn.parallel import DistributedDataParallel\n","from torch.utils.data.distributed import DistributedSampler\n","\n","\n","import tokenizers\n","import transformers\n","print(f\"tokenizers.__version__: {tokenizers.__version__}\")\n","print(f\"transformers.__version__: {transformers.__version__}\")\n","from transformers import AutoTokenizer, AutoModel, AutoConfig\n","from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n","%env TOKENIZERS_PARALLELISM=true\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"markdown","metadata":{"id":"Sw2QNpKyzBWS"},"source":["## Utils"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZS5qilDjwZHT"},"outputs":[],"source":["# ====================================================\n","# Utils\n","# ====================================================\n","def MCRMSE(y_trues, y_preds):\n","    scores = []\n","    idxes = y_trues.shape[1]\n","    for i in range(idxes):\n","        y_true = y_trues[:,i]\n","        y_pred = y_preds[:,i]\n","        score = mean_squared_error(y_true, y_pred, squared=False) # RMSE\n","        scores.append(score)\n","    mcrmse_score = np.mean(scores)\n","    return mcrmse_score, scores\n","\n","\n","def get_score(y_trues, y_preds):\n","    mcrmse_score, scores = MCRMSE(y_trues, y_preds)\n","    return mcrmse_score, scores\n","\n","\n","def get_logger(filename=OUTPUT_DIR+'train'):\n","    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n","    logger = getLogger(__name__)\n","    logger.setLevel(INFO)\n","    handler1 = StreamHandler()\n","    handler1.setFormatter(Formatter(\"%(message)s\"))\n","    handler2 = FileHandler(filename=f\"{filename}.log\")\n","    handler2.setFormatter(Formatter(\"%(message)s\"))\n","    logger.addHandler(handler1)\n","    logger.addHandler(handler2)\n","    return logger\n","\n","LOGGER = get_logger()\n","\n","\n","def seed_everything(seed=42):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    \n","seed_everything(seed=42)"]},{"cell_type":"markdown","metadata":{"id":"RoQICqwdmuat"},"source":["## Data Loading"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":511},"executionInfo":{"elapsed":2456,"status":"ok","timestamp":1667298943263,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"3J4wnJXszIx4","outputId":"3738137f-0a30-433e-9427-d4b615bdf8f6"},"outputs":[{"name":"stdout","output_type":"stream","text":["train.shape: (3911, 8)\n"]},{"data":{"text/html":["\n","  <div id=\"df-4aaf04d0-3165-4067-a085-b6753389501f\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text_id</th>\n","      <th>full_text</th>\n","      <th>cohesion</th>\n","      <th>syntax</th>\n","      <th>vocabulary</th>\n","      <th>phraseology</th>\n","      <th>grammar</th>\n","      <th>conventions</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0016926B079C</td>\n","      <td>I think that students would benefit from learn...</td>\n","      <td>3.5</td>\n","      <td>3.5</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>4.0</td>\n","      <td>3.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0022683E9EA5</td>\n","      <td>When a problem is a change you have to let it ...</td>\n","      <td>2.5</td>\n","      <td>2.5</td>\n","      <td>3.0</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>2.5</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>00299B378633</td>\n","      <td>Dear, Principal\\n\\nIf u change the school poli...</td>\n","      <td>3.0</td>\n","      <td>3.5</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>2.5</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>003885A45F42</td>\n","      <td>The best time in life is when you become yours...</td>\n","      <td>4.5</td>\n","      <td>4.5</td>\n","      <td>4.5</td>\n","      <td>4.5</td>\n","      <td>4.0</td>\n","      <td>5.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0049B1DF5CCC</td>\n","      <td>Small act of kindness can impact in other peop...</td>\n","      <td>2.5</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>2.5</td>\n","      <td>2.5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4aaf04d0-3165-4067-a085-b6753389501f')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-4aaf04d0-3165-4067-a085-b6753389501f button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-4aaf04d0-3165-4067-a085-b6753389501f');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["        text_id                                          full_text  cohesion  syntax  vocabulary  phraseology  grammar  conventions\n","0  0016926B079C  I think that students would benefit from learn...       3.5     3.5         3.0          3.0      4.0          3.0\n","1  0022683E9EA5  When a problem is a change you have to let it ...       2.5     2.5         3.0          2.0      2.0          2.5\n","2  00299B378633  Dear, Principal\\n\\nIf u change the school poli...       3.0     3.5         3.0          3.0      3.0          2.5\n","3  003885A45F42  The best time in life is when you become yours...       4.5     4.5         4.5          4.5      4.0          5.0\n","4  0049B1DF5CCC  Small act of kindness can impact in other peop...       2.5     3.0         3.0          3.0      2.5          2.5"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["test.shape: (3, 2)\n"]},{"data":{"text/html":["\n","  <div id=\"df-f832e125-e9e1-4af2-b39b-ccff32fedd9e\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text_id</th>\n","      <th>full_text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0000C359D63E</td>\n","      <td>when a person has no experience on a job their...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>000BAD50D026</td>\n","      <td>Do you think students would benefit from being...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>00367BB2546B</td>\n","      <td>Thomas Jefferson once states that \"it is wonde...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f832e125-e9e1-4af2-b39b-ccff32fedd9e')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-f832e125-e9e1-4af2-b39b-ccff32fedd9e button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-f832e125-e9e1-4af2-b39b-ccff32fedd9e');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["        text_id                                          full_text\n","0  0000C359D63E  when a person has no experience on a job their...\n","1  000BAD50D026  Do you think students would benefit from being...\n","2  00367BB2546B  Thomas Jefferson once states that \"it is wonde..."]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["submission.shape: (3, 7)\n"]},{"data":{"text/html":["\n","  <div id=\"df-f6e889a3-fdba-487e-95a1-9b5327530b8f\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text_id</th>\n","      <th>cohesion</th>\n","      <th>syntax</th>\n","      <th>vocabulary</th>\n","      <th>phraseology</th>\n","      <th>grammar</th>\n","      <th>conventions</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0000C359D63E</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>000BAD50D026</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>00367BB2546B</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f6e889a3-fdba-487e-95a1-9b5327530b8f')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-f6e889a3-fdba-487e-95a1-9b5327530b8f button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-f6e889a3-fdba-487e-95a1-9b5327530b8f');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["        text_id  cohesion  syntax  vocabulary  phraseology  grammar  conventions\n","0  0000C359D63E       3.0     3.0         3.0          3.0      3.0          3.0\n","1  000BAD50D026       3.0     3.0         3.0          3.0      3.0          3.0\n","2  00367BB2546B       3.0     3.0         3.0          3.0      3.0          3.0"]},"metadata":{},"output_type":"display_data"}],"source":["# ====================================================\n","# Data Loading\n","# ====================================================\n","train = pd.read_csv('./train.csv')\n","test = pd.read_csv('./test.csv')\n","submission = pd.read_csv('./sample_submission.csv')\n","\n","print(f\"train.shape: {train.shape}\")\n","display(train.head())\n","print(f\"test.shape: {test.shape}\")\n","display(test.head())\n","print(f\"submission.shape: {submission.shape}\")\n","display(submission.head())"]},{"cell_type":"markdown","metadata":{"id":"QM2WfrOuzkGG"},"source":["## CV split"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":225},"executionInfo":{"elapsed":633,"status":"ok","timestamp":1667298943883,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"qLsEGvn6ziAl","outputId":"9df8b94a-33be-4576-b325-1146fb2b4fd0"},"outputs":[{"data":{"text/plain":["fold\n","0    391\n","1    391\n","2    391\n","3    391\n","4    391\n","5    391\n","6    391\n","7    391\n","8    391\n","9    392\n","dtype: int64"]},"metadata":{},"output_type":"display_data"}],"source":["# ====================================================\n","# CV split\n","# ====================================================\n","Fold = MultilabelStratifiedKFold(n_splits=CFG.n_fold, shuffle=True, random_state=CFG.seed)\n","for n, (train_index, val_index) in enumerate(Fold.split(train, train[CFG.target_cols])):\n","    train.loc[val_index, 'fold'] = int(n)\n","\n","train['fold'] = train['fold'].astype(int)\n","display(train.groupby('fold').size())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D7Uwy_TIzm46"},"outputs":[],"source":["if CFG.debug:\n","    display(train.groupby('fold').size())\n","    train = train.sample(n=1000, random_state=0).reset_index(drop=True)\n","    display(train.groupby('fold').size())"]},{"cell_type":"markdown","metadata":{"id":"l3QrVKDBzrNj"},"source":["## Tokenizer"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":148,"referenced_widgets":["53c68ac5314d4722933f7052ce8f51c9","be14b7c80ad54495bb6517dcf4590793","c95be6dddca74a2bbe57f3b637c8dc42","aa3d2c2d6494462b9cbde88bf5da9996","49ed98230683453885bdbada339cb13e","b163927e4c994b8b8388ee2c94037a9a","afa9acc3085d445e9d1d43eb86785d7d","a3d91b1d07f44001b090a62f2e35fa9e","34cef67bb97a47edab90ead015c6c96d","77d3439d05de4b908e883d6a21a5e9e5","64ccac65453542719f622e5d10fa7959","976f3c01ce0a4b62856d5fd98296bcb6","a31cb778feb843788db07c703e59ed40","6da42264b48849abbf32e88de759ecf1","f40acac3043747b48e494ebd6a8c5688","1df217ad69a1422bb07501d61b43b06b","1bb086bfa59e4271b065b027776e3ec4","6ad45739ba8d40ff99e1a3dff93a37ae","9db1e8eac0864f689c985cc921de387d","4095f253459b4e12a606069f747156bf","f4b7b59fa3d2451f8487250f5254dde4","ea3cbe06f8c1470b81567b7137156d64","ad6d12abc5d44712ad561c9f51f7cf9e","a7b945ea2cbf481c9f2ccaa9812ad9c0","44d04bba88674054bdd2351a43d1ffd3","a81ed695cb9142ffbc3252dca1640e87","b42d846a49be40ed9cf3c9fcf4b29b90","578dde988c57499192b7c45bcad9edf3","a441a25be523482c917e48c0be50f610","9ff888daa1514741b33c65b39ffba3b8","552863caa19647678acc1e911df3b342","5c3036c9f29c4f3199ab104e12b5956f","2e069fed4cee46b8a2348d6352a41974"]},"executionInfo":{"elapsed":8759,"status":"ok","timestamp":1667298952637,"user":{"displayName":"성연우","userId":"12015659827226767816"},"user_tz":-540},"id":"uSWhHwRuzpM1","outputId":"bfe9db65-0f95-4f0a-ae73-a6633cf140ab"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"53c68ac5314d4722933f7052ce8f51c9","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"976f3c01ce0a4b62856d5fd98296bcb6","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/579 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ad6d12abc5d44712ad561c9f51f7cf9e","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}],"source":["# ====================================================\n","# tokenizer\n","# ====================================================\n","tokenizer = AutoTokenizer.from_pretrained(CFG.model)\n","tokenizer.save_pretrained(OUTPUT_DIR+'tokenizer/')\n","CFG.tokenizer = tokenizer"]},{"cell_type":"markdown","metadata":{"id":"TdPB7Q2dzwlB"},"source":["## Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VyjM4MdWzuTa"},"outputs":[],"source":["# ====================================================\n","# Define max_len\n","# ====================================================\n","# lengths = []\n","# tk0 = tqdm(train['full_text'].fillna(\"\").values, total=len(train))\n","# for text in tk0:\n","#     length = len(tokenizer(text, add_special_tokens=False)['input_ids'])\n","#     lengths.append(length)\n","# CFG.max_len = max(lengths) + 3 # cls & sep & sep\n","# LOGGER.info(f\"max_len: {CFG.max_len}\")\n","\n","CFG.max_len = 1024"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T1ol14Phzxd6"},"outputs":[],"source":["# ====================================================\n","# Dataset\n","# ====================================================\n","def prepare_input(cfg, text):\n","    inputs = cfg.tokenizer.encode_plus(\n","        text, \n","        return_tensors=None, \n","        add_special_tokens=True, \n","        max_length=CFG.max_len,\n","        pad_to_max_length=True,\n","        truncation=True\n","    )\n","    for k, v in inputs.items():\n","        inputs[k] = torch.tensor(v, dtype=torch.long)\n","    return inputs\n","\n","\n","class TrainDataset(Dataset):\n","    def __init__(self, cfg, df):\n","        self.cfg = cfg\n","        self.texts = df['full_text'].values\n","        self.labels = df[cfg.target_cols].values\n","\n","    def __len__(self):\n","        return len(self.texts)\n","\n","    def __getitem__(self, item):\n","        inputs = prepare_input(self.cfg, self.texts[item])\n","        label = torch.tensor(self.labels[item], dtype=torch.float)\n","        return inputs, label\n","    \n","\n","def collate(inputs):\n","    mask_len = int(inputs[\"attention_mask\"].sum(axis=1).max())\n","    for k, v in inputs.items():\n","        inputs[k] = inputs[k][:,:mask_len]\n","    return inputs"]},{"cell_type":"markdown","metadata":{"id":"4GtpqO_rz6FD"},"source":["## Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OmbliWj6z1-v"},"outputs":[],"source":["# ====================================================\n","# Model\n","# ====================================================\n","class MeanPooling(nn.Module):\n","    def __init__(self):\n","        super(MeanPooling, self).__init__()\n","        \n","    def forward(self, last_hidden_state, attention_mask):\n","        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n","        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n","        sum_mask = input_mask_expanded.sum(1)\n","        sum_mask = torch.clamp(sum_mask, min=1e-9)\n","        mean_embeddings = sum_embeddings / sum_mask\n","        return mean_embeddings\n","    \n","\n","\n","class CustomModel(nn.Module):\n","    def __init__(self, cfg, config_path=None, pretrained=False):\n","        super().__init__()\n","        self.cfg = cfg\n","        if config_path is None:\n","            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n","            self.config.hidden_dropout = 0.\n","            self.config.hidden_dropout_prob = 0.\n","            self.config.attention_dropout = 0.\n","            self.config.attention_probs_dropout_prob = 0.\n","            self.config.relative_attention = True\n","            self.config.max_position_embeddings = cfg.max_len\n","            LOGGER.info(self.config)\n","        else:\n","            self.config = torch.load(config_path)\n","        if pretrained:\n","            self.model = AutoModel.from_pretrained(cfg.model, config=self.config, ignore_mismatched_sizes=True) #torch_dtype=torch.float16\n","        else:\n","            self.model = AutoModel(self.config)\n","\n","        \n","        # Freeze the hidden layers for CUDA memory issue\n","        if 'deberta-v2-xxlarge' in cfg.model:\n","            print('freeze 32 deberta layers')\n","            self.model.embeddings.requires_grad_(False)\n","            self.model.encoder.layer[:32].requires_grad_(False) # 32/48\n","        if 'deberta-v2-xlarge' in cfg.model:\n","            print('freeze 12 deberta layers')\n","            self.model.embeddings.requires_grad_(False)\n","            self.model.encoder.layer[:12].requires_grad_(False) # 12/24\n","        if 'deberta-xlarge' in cfg.model:\n","            print(f'# of total layers = {len(self.model.encoder.layer)}')\n","            print('freeze 30 deberta layers')\n","            self.model.embeddings.requires_grad_(False)\n","            self.model.encoder.layer[:30].requires_grad_(False) # 30/48\n","        if 'funnel-transformer-xlarge' in cfg.model:\n","            self.model.embeddings.requires_grad_(False)\n","            self.model.encoder.blocks[:1].requires_grad_(False) # 1/3\n","\n","\n","        if self.cfg.gradient_checkpointing:\n","            self.model.gradient_checkpointing_enable()\n","        \n","        # attention-based stacked module\n","        self.attention = nn.Sequential(\n","            nn.Linear(self.config.hidden_size, 512),\n","            nn.Tanh(),\n","            nn.Linear(512, 1),\n","            nn.Softmax(dim=1)\n","        )\n","        # pooling layer for the concatenated tensors\n","        self.concat_pool = nn.Linear(self.config.hidden_size*3, self.config.hidden_size)\n","\n","        self.pool = MeanPooling()\n","        self.fc = nn.Linear(self.config.hidden_size, 6)\n","        self._init_weights(self.fc)\n","        \n","        \n","    def _init_weights(self, module):\n","        if isinstance(module, nn.Linear):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.bias is not None:\n","                module.bias.data.zero_()\n","        elif isinstance(module, nn.Embedding):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.padding_idx is not None:\n","                module.weight.data[module.padding_idx].zero_()\n","        elif isinstance(module, nn.LayerNorm):\n","            module.bias.data.zero_()\n","            module.weight.data.fill_(1.0)\n","        \n","    def feature(self, inputs):\n","        outputs = self.model(**inputs)\n","        last_hidden_states = outputs[0]\n","        mean_feature = self.pool(last_hidden_states, inputs['attention_mask'])\n","\n","        # attention based sentence representation\n","        weights = self.attention(last_hidden_states)\n","        attention_feature = torch.sum(weights * last_hidden_states, dim=1)\n","\n","        cls_token_feature = last_hidden_states[:, 0, :] # only cls token\n","\n","        # combine mean pooled feature, attention feature, and cls token feature to the stacked feature\n","        combine_feature = torch.cat([mean_feature, attention_feature, cls_token_feature], dim = -1)\n","        concat_pooled_feature = self.concat_pool(combine_feature)\n","        \n","        return concat_pooled_feature\n","\n","    def forward(self, inputs):\n","        feature = self.feature(inputs)\n","        output = self.fc(feature)\n","        return output"]},{"cell_type":"code","source":["class RMSELoss(nn.Module):\n","    def __init__(self, reduction='mean', eps=1e-9):\n","        super().__init__()\n","        self.mse = nn.MSELoss(reduction='none')\n","        self.reduction = reduction\n","        self.eps = eps\n","\n","    def forward(self, y_pred, y_true):\n","        loss = torch.sqrt(self.mse(y_pred, y_true) + self.eps)\n","        if self.reduction == 'none':\n","            loss = loss\n","        elif self.reduction == 'sum':\n","            loss = loss.sum()\n","        elif self.reduction == 'mean':\n","            loss = loss.mean()\n","        return loss"],"metadata":{"id":"65XOeMmL7vF2"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uyWPCCto7lcu"},"outputs":[],"source":["class FGM():\n","    def __init__(self, model):\n","        self.model = model\n","        self.backup = {}\n","\n","    def attack(self, epsilon=1., emb_name='word_embeddings'):\n","        for name, param in self.model.named_parameters():\n","            if param.requires_grad and emb_name in name:\n","                self.backup[name] = param.data.clone()\n","                norm = torch.norm(param.grad)\n","                if norm != 0:\n","                    r_at = epsilon * param.grad / norm\n","                    param.data.add_(r_at)\n","\n","    def restore(self, emb_name='word_embeddings'):\n","        for name, param in self.model.named_parameters():\n","            if param.requires_grad and emb_name in name:\n","                assert name in self.backup\n","                param.data = self.backup[name]\n","            self.backup = {}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FFtjzDcoINKx"},"outputs":[],"source":["class AWP:\n","    def __init__(self, model, optimizer, adv_param='weight', adv_lr=0.001, adv_eps=0.001):\n","        self.model = model\n","        self.optimizer = optimizer\n","        self.adv_param = adv_param\n","        self.adv_lr = adv_lr\n","        self.adv_eps = adv_eps\n","        self.backup = {}\n","\n","    def perturb(self, input_ids, attention_mask, y, criterion):\n","        \"\"\"\n","        Perturb model parameters for AWP gradient\n","        Call before loss and loss.backward()\n","        \"\"\"\n","        self._save()  # save model parameters\n","        self._attack_step()  # perturb weights\n","\n","    def _attack_step(self):\n","        e = 1e-6\n","        for name, param in self.model.named_parameters():\n","            if param.requires_grad and param.grad is not None and self.adv_param in name:\n","                grad = self.optimizer.state[param]['exp_avg']\n","                norm_grad = torch.norm(grad)\n","                norm_data = torch.norm(param.detach())\n","\n","                if norm_grad != 0 and not torch.isnan(norm_grad):\n","                    # Set lower and upper limit in change\n","                    limit_eps = self.adv_eps * param.detach().abs()\n","                    param_min = param.data - limit_eps\n","                    param_max = param.data + limit_eps\n","\n","                    # Perturb along gradient\n","                    # w += (adv_lr * |w| / |grad|) * grad\n","                    param.data.add_(grad, alpha=(self.adv_lr * (norm_data + e) / (norm_grad + e)))\n","\n","                    # Apply the limit to the change\n","                    param.data.clamp_(param_min, param_max)\n","\n","    def _save(self):\n","        for name, param in self.model.named_parameters():\n","            if param.requires_grad and param.grad is not None and self.adv_param in name:\n","                if name not in self.backup:\n","                    self.backup[name] = param.clone().detach()\n","                else:\n","                    self.backup[name].copy_(param.data)\n","\n","    def restore(self):\n","        \"\"\"\n","        Restore model parameter to correct position; AWP do not perturbe weights, it perturb gradients\n","        Call after loss.backward(), before optimizer.step()\n","        \"\"\"\n","        for name, param in self.model.named_parameters():\n","            if name in self.backup:\n","                param.data.copy_(self.backup[name])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hZRDUCIB1n0L"},"outputs":[],"source":["# ====================================================\n","# Loss\n","# ====================================================\n","class RMSELoss(nn.Module):\n","    def __init__(self, reduction='mean', eps=1e-9):\n","        super().__init__()\n","        self.mse = nn.MSELoss(reduction='none')\n","        self.reduction = reduction\n","        self.eps = eps\n","\n","    def forward(self, y_pred, y_true):\n","        loss = torch.sqrt(self.mse(y_pred, y_true) + self.eps)\n","        if self.reduction == 'none':\n","            loss = loss\n","        elif self.reduction == 'sum':\n","            loss = loss.sum()\n","        elif self.reduction == 'mean':\n","            loss = loss.mean()\n","        return loss"]},{"cell_type":"markdown","metadata":{"id":"OQ0GNu8R0BHC"},"source":["## Helper function"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-Au791lcz-Tp"},"outputs":[],"source":["# ====================================================\n","# Helper functions\n","# ====================================================\n","class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","\n","def asMinutes(s):\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return '%dm %ds' % (m, s)\n","\n","\n","def timeSince(since, percent):\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n","\n","\n","# CPMP utility to gather values from all workers\n","def my_gather(output, local_rank, world_size):\n","    # output must be a tensor on the cuda device\n","    # output must have the same size in all workers\n","    result = None\n","    if local_rank == 0:\n","        result = [torch.empty_like(output) for _ in range(world_size)]\n","    torch.distributed.gather(output, gather_list=result, dst=0)\n","    return result\n","\n","\n","def train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler,  device, local_rank, world_size):\n","    # CPMP pass rank, size as arg\n","\n","    model.train()\n","    scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n","    losses = AverageMeter()\n","    start = end = time.time()\n","    global_step = 0\n","\n","    fgm = FGM(model)\n","    awp = AWP(model, optimizer, adv_param=\"weight\", adv_lr=1e-5, adv_eps=1e-6)\n","\n","    awp_start = 10.0\n","    fgm_start = 1.0\n","\n","    for step, (inputs, labels) in enumerate(train_loader):\n","        inputs = collate(inputs)\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","\n","        #======================\n","        # AWP attack\n","        if epoch >= awp_start:\n","            awp.perturb(inputs['input_ids'], inputs['attention_mask'], labels, criterion)\n","        #======================\n","\n","        with torch.cuda.amp.autocast(enabled=CFG.apex):\n","            y_preds = model(inputs)\n","            loss = criterion(y_preds, labels)\n","        if CFG.gradient_accumulation_steps > 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        scaler.scale(loss).backward()\n","        # loss.backward()\n","\n","        #======================\n","        # AWP restore\n","        if epoch >= awp_start:\n","            awp.restore()\n","        #======================\n","\n","        #======================\n","        # FGM\n","        #======================\n","        if epoch >= fgm_start:\n","            fgm.attack()\n","            with torch.cuda.amp.autocast(enabled=CFG.apex):\n","                y_preds = model(inputs)\n","                loss_adv = criterion(y_preds, labels)\n","            scaler.scale(loss_adv).backward()\n","            # loss_adv.backward()\n","            fgm.restore()\n","        #======================\n","\n","        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n","        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n","            scaler.step(optimizer)\n","            # optimizer.step()\n","            scaler.update()\n","            optimizer.zero_grad()\n","            global_step += 1\n","            if CFG.batch_scheduler:\n","                scheduler.step()\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n","            print('Epoch: [{0}][{1}/{2}] '\n","                  'Elapsed {remain:s} '\n","                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                  'Grad: {grad_norm:.4f}  '\n","                  'LR: {lr:.8f}  '\n","                  .format(epoch+1, step, len(train_loader), \n","                          remain=timeSince(start, float(step+1)/len(train_loader)),\n","                          loss=losses,\n","                          grad_norm=grad_norm,\n","                          lr=scheduler.get_lr()[0]))\n","        if CFG.wandb:\n","            wandb.log({f\"[fold{fold}] loss\": losses.val,\n","                       f\"[fold{fold}] lr\": scheduler.get_lr()[0]})\n","        \n","        torch.cuda.empty_cache()\n","        gc.collect()\n","        \n","    torch.cuda.empty_cache()\n","    gc.collect()\n","\n","    # CPMP gather loss on worker 0\n","    loss_avg = torch.tensor([losses.avg], device=device)\n","    loss_avg = my_gather(loss_avg, local_rank, world_size)\n","    if local_rank == 0:\n","        loss_avg = torch.cat(loss_avg).mean().item()\n","    else:\n","        loss_avg = None\n","    return loss_avg\n","\n","\n","def valid_fn(valid_loader, model, criterion, device, local_rank, world_size, valid_dataset):\n","    # CPMP pass rank, size dataset as arg)\n","    \n","    losses = AverageMeter()\n","    model.eval()\n","    preds = []\n","    start = end = time.time()\n","    for step, (inputs, labels) in enumerate(valid_loader):\n","        inputs = collate(inputs)\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","        with torch.no_grad():\n","            y_preds = model(inputs)\n","            loss = criterion(y_preds, labels)\n","        if CFG.gradient_accumulation_steps > 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        preds.append(y_preds.to('cpu').numpy())\n","        end = time.time()\n","        if local_rank == 0: # CPMP\n","            if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n","                print('EVAL: [{0}/{1}] '\n","                      'Elapsed {remain:s} '\n","                      'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                      .format(step, len(valid_loader),\n","                              loss=losses,\n","                              remain=timeSince(start, float(step+1)/len(valid_loader))))\n","        torch.cuda.empty_cache()\n","        gc.collect()\n","    predictions = torch.cat(preds) # CPMP\n","    \n","    # CPMP gather on worker 0\n","    loss_avg = torch.tensor([losses.avg], device=device)\n","    loss_avg = my_gather(loss_avg, local_rank, world_size)\n","    predictions = my_gather(predictions, local_rank, world_size)\n","    \n","    # CPMP gather on worker 0\n","    if local_rank == 0:\n","        loss_avg = torch.cat(loss_avg).mean().item()\n","        predictions = torch.stack(predictions)\n","        # DistributedSampler interleaves workers\n","        # transpose restores the original order\n","        _, _, t = predictions.shape\n","        predictions = predictions.transpose(0, 1).reshape(-1, t) \n","        # DistributedSampler pads the dataset to get a multiple of world size\n","        predictions = predictions[:len(valid_dataset)]\n","        predictions = predictions.cpu().numpy()\n","        return loss_avg, predictions\n","    else:\n","        return None, None"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rbRozESi0C3r"},"outputs":[],"source":["# ====================================================\n","# train loop\n","# ====================================================\n","def train_loop(folds, fold, device, local_rank, world_size):  # CPMP pass device, rank, size as arg\n","    \n","    if local_rank == 0: # CPMP\n","        LOGGER.info(f\"========== fold: {fold} training ==========\")\n","\n","    # ====================================================\n","    # loader\n","    # ====================================================\n","    train_folds = folds[folds['fold'] != fold].reset_index(drop=True)\n","    valid_folds = folds[folds['fold'] == fold].reset_index(drop=True)\n","    valid_labels = valid_folds[CFG.target_cols].values\n","    \n","    train_dataset = TrainDataset(CFG, train_folds)\n","    valid_dataset = TrainDataset(CFG, valid_folds)\n","\n","    train_sampler = DistributedSampler(train_dataset,\n","                                       num_replicas=world_size,\n","                                       rank=local_rank,\n","                                       shuffle=True,\n","                                       seed=42,\n","                                       drop_last=True,\n","                                       )\n","    valid_sampler = DistributedSampler(valid_dataset,\n","                                       num_replicas=world_size,\n","                                       rank=local_rank,\n","                                       shuffle=False,\n","                                       seed=42,\n","                                       drop_last=False,\n","                                       )\n","\n","    train_loader = DataLoader(train_dataset,\n","                              batch_size=CFG.batch_size,\n","                              shuffle=False, # CPMP\n","                              sampler=train_sampler, # CPMP\n","                              num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n","    valid_loader = DataLoader(valid_dataset,\n","                              batch_size=CFG.batch_size,\n","                              shuffle=False, # CPMP\n","                              sampler=valid_sampler, # CPMP\n","                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n","\n","    # ====================================================\n","    # model & optimizer\n","    # ====================================================\n","    model = CustomModel(CFG, config_path=None, pretrained=True)\n","    torch.save(model.config, OUTPUT_DIR+'config.pth')\n","    model.to(device)\n","\n","    # wrap for DDP\n","    if CFG.sync_bn:\n","        model = torch.nn.SyncBatchNorm.convert_sync_batchnorm(model)\n","    model = DistributedDataParallel(model, device_ids=[local_rank])\n","    \n","    def get_optimizer_params(model, encoder_lr, decoder_lr, weight_decay=0.0, weight_decay_decoder=0.0):\n","        param_optimizer = list(model.named_parameters())\n","        no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n","        # CPMP: when using DDP the original model is now the module attribute\n","        optimizer_parameters = [\n","            {'params': [p for n, p in model.module.model.named_parameters() if not any(nd in n for nd in no_decay)],\n","             'lr': encoder_lr, 'weight_decay': weight_decay},\n","            {'params': [p for n, p in model.module.model.named_parameters() if any(nd in n for nd in no_decay)],\n","             'lr': encoder_lr, 'weight_decay': 0.0},\n","            {'params': [p for n, p in model.module.named_parameters() if \"model\" not in n],\n","             'lr': decoder_lr, 'weight_decay': 0.0}\n","        ]\n","        return optimizer_parameters\n","\n","    optimizer_parameters = get_optimizer_params(model,\n","                                                encoder_lr=CFG.encoder_lr, \n","                                                decoder_lr=CFG.decoder_lr,\n","                                                weight_decay=CFG.weight_decay,\n","                                                weight_decay_decoder=CFG.weight_decay_decoder)\n","    optimizer = AdamW(optimizer_parameters, lr=CFG.encoder_lr, eps=CFG.eps, betas=CFG.betas)\n","\n","\n","    # ====================================================\n","    # scheduler\n","    # ====================================================\n","    def get_scheduler(cfg, optimizer, num_train_steps):\n","        if cfg.scheduler == 'linear':\n","            scheduler = get_linear_schedule_with_warmup(\n","                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps\n","            )\n","        elif cfg.scheduler == 'cosine':\n","            scheduler = get_cosine_schedule_with_warmup(\n","                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps, num_cycles=cfg.num_cycles\n","            )\n","        return scheduler\n","    \n","    num_train_steps = int(len(train_folds) / CFG.batch_size * CFG.epochs)\n","    scheduler = get_scheduler(CFG, optimizer, num_train_steps)\n","\n","    # ====================================================\n","    # loop\n","    # ====================================================\n","    criterion = nn.SmoothL1Loss(reduction='mean')\n","    # criterion = RMSELoss(reduction=\"mean\")\n","    \n","    best_score = np.inf\n","\n","    for epoch in range(CFG.epochs):\n","\n","        start_time = time.time()\n","\n","        # train\n","        # CPMP pass rank and world size\n","        avg_loss = train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, \n","                            device, local_rank, world_size) \n","\n","        # eval\n","        # CPMP pass rank, world size, and valid dataset\n","        avg_val_loss, predictions = valid_fn(valid_loader, model, criterion, \n","                                             device, local_rank, world_size, valid_dataset) \n","        \n","        # scoring\n","        if local_rank == 0: # CPMP\n","            score, scores = get_score(valid_labels, predictions)\n","\n","            elapsed = time.time() - start_time\n","\n","            LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n","            LOGGER.info(f'Epoch {epoch+1} - Score: {score:.4f}  Scores: {scores}')\n","            if CFG.wandb:\n","                wandb.log({f\"[fold{fold}] epoch\": epoch+1, \n","                           f\"[fold{fold}] avg_train_loss\": avg_loss, \n","                           f\"[fold{fold}] avg_val_loss\": avg_val_loss,\n","                           f\"[fold{fold}] score\": score})\n","\n","            if best_score > score:\n","                best_score = score\n","                LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n","                # CPMP: save the original model. It is stored as the module attribute of the DP model.\n","                torch.save({'model': model.module.state_dict(),\n","                            'predictions': predictions},\n","                            OUTPUT_DIR+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\")\n","\n","    if local_rank == 0: # CPMP\n","        predictions = torch.load(OUTPUT_DIR+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\", \n","                             map_location=torch.device('cpu'))['predictions']\n","        valid_folds[[f\"pred_{c}\" for c in CFG.target_cols]] = predictions\n","\n","        torch.cuda.empty_cache()\n","        gc.collect()\n","\n","        return valid_folds\n","    else:\n","        return None"]},{"cell_type":"markdown","metadata":{"id":"838KSKWa0Ktz"},"source":["## Training"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["860e502a3e884db3bea649ae3f231392","974d70ec38c945e5b75f97ecb83e846b","ac0969d512704d2ca8d69563ef9718fc","66ac4e1728a54a67864a751b3af53e3d","d43b7ae66781497e9f142077d8404c67","cf8cb528f47a41a3aa2888f90d26e549","7afb0495ff2b412e9a2394cd1e69eed2","69f9be038ddc4763a4eabbf473383d58","484fea0c5e1c40d78a9f54ef24c7199f","9902e05a45a4413a88dbd3499ab967de","1586fa5f923f4ef38b93870397e5a694"]},"id":"no8nLUEy0J-k","executionInfo":{"status":"ok","timestamp":1667373549491,"user_tz":-540,"elapsed":5101840,"user":{"displayName":"성연우","userId":"12015659827226767816"}},"outputId":"cb0f3c77-6534-4461-f61e-948b2201dbfb"},"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["========== fold: 0 training ==========\n","INFO:__main__:========== fold: 0 training ==========\n","DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 1024,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.23.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","INFO:__main__:DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 1024,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.23.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"860e502a3e884db3bea649ae3f231392","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/371M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['mask_predictions.LayerNorm.weight', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.bias', 'mask_predictions.LayerNorm.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: [1][0/220] Elapsed 0m 6s (remain 25m 13s) Loss: 2.6307(2.6307) Grad: 687010.1875  LR: 0.00000040  \n","Epoch: [1][20/220] Elapsed 1m 18s (remain 12m 24s) Loss: 1.9731(2.5571) Grad: 725475.5625  LR: 0.00000840  \n","Epoch: [1][40/220] Elapsed 2m 31s (remain 10m 59s) Loss: 0.9498(2.1719) Grad: 803341.9375  LR: 0.00001640  \n","Epoch: [1][60/220] Elapsed 3m 48s (remain 9m 54s) Loss: 0.1468(1.5812) Grad: 250520.6562  LR: 0.00001999  \n","Epoch: [1][80/220] Elapsed 5m 5s (remain 8m 44s) Loss: 0.1115(1.2353) Grad: 182405.9219  LR: 0.00001996  \n","Epoch: [1][100/220] Elapsed 6m 19s (remain 7m 27s) Loss: 0.1034(1.0164) Grad: 177441.4375  LR: 0.00001988  \n","Epoch: [1][120/220] Elapsed 7m 32s (remain 6m 9s) Loss: 0.1101(0.8702) Grad: 200393.6094  LR: 0.00001978  \n","Epoch: [1][140/220] Elapsed 8m 52s (remain 4m 58s) Loss: 0.1026(0.7644) Grad: 264691.8750  LR: 0.00001963  \n","Epoch: [1][160/220] Elapsed 10m 1s (remain 3m 40s) Loss: 0.1129(0.6840) Grad: 136949.9688  LR: 0.00001945  \n","Epoch: [1][180/220] Elapsed 11m 15s (remain 2m 25s) Loss: 0.1165(0.6234) Grad: 135612.7656  LR: 0.00001924  \n","Epoch: [1][200/220] Elapsed 12m 29s (remain 1m 10s) Loss: 0.1057(0.5723) Grad: 115593.3516  LR: 0.00001900  \n","Epoch: [1][219/220] Elapsed 13m 32s (remain 0m 0s) Loss: 0.1303(0.5326) Grad: 178549.8125  LR: 0.00001873  \n","EVAL: [0/25] Elapsed 0m 1s (remain 0m 38s) Loss: 0.1140(0.1140) \n","EVAL: [20/25] Elapsed 0m 43s (remain 0m 8s) Loss: 0.1303(0.1082) \n","EVAL: [24/25] Elapsed 0m 49s (remain 0m 0s) Loss: 0.1303(0.1088) \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 1 - avg_train_loss: 0.5326  avg_val_loss: 0.1088  time: 863s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.5326  avg_val_loss: 0.1088  time: 863s\n","Epoch 1 - Score: 0.4666  Scores: [0.5089415376609027, 0.4495655473407141, 0.4331213180053301, 0.4252158696444778, 0.5219629489156603, 0.4609638273360511]\n","INFO:__main__:Epoch 1 - Score: 0.4666  Scores: [0.5089415376609027, 0.4495655473407141, 0.4331213180053301, 0.4252158696444778, 0.5219629489156603, 0.4609638273360511]\n","Epoch 1 - Save Best Score: 0.4666 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.4666 Model\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: [2][0/220] Elapsed 0m 7s (remain 29m 7s) Loss: 0.0989(0.0989) Grad: 367353.0938  LR: 0.00001872  \n","Epoch: [2][20/220] Elapsed 2m 37s (remain 24m 50s) Loss: 0.0858(0.1167) Grad: 266486.6562  LR: 0.00001841  \n","Epoch: [2][40/220] Elapsed 4m 58s (remain 21m 43s) Loss: 0.0911(0.1135) Grad: 162772.7031  LR: 0.00001807  \n","Epoch: [2][60/220] Elapsed 7m 38s (remain 19m 54s) Loss: 0.1258(0.1175) Grad: 604007.4375  LR: 0.00001771  \n","Epoch: [2][80/220] Elapsed 10m 5s (remain 17m 18s) Loss: 0.0939(0.1178) Grad: 171467.7344  LR: 0.00001731  \n","Epoch: [2][100/220] Elapsed 12m 34s (remain 14m 48s) Loss: 0.1013(0.1160) Grad: 415578.7188  LR: 0.00001689  \n","Epoch: [2][120/220] Elapsed 14m 56s (remain 12m 13s) Loss: 0.1030(0.1145) Grad: 142711.0156  LR: 0.00001644  \n","Epoch: [2][140/220] Elapsed 17m 27s (remain 9m 46s) Loss: 0.1714(0.1135) Grad: 565370.8125  LR: 0.00001597  \n","Epoch: [2][160/220] Elapsed 19m 51s (remain 7m 16s) Loss: 0.1084(0.1130) Grad: 407675.2188  LR: 0.00001548  \n","Epoch: [2][180/220] Elapsed 22m 17s (remain 4m 48s) Loss: 0.1529(0.1128) Grad: 414323.7188  LR: 0.00001497  \n","Epoch: [2][200/220] Elapsed 24m 26s (remain 2m 18s) Loss: 0.1711(0.1125) Grad: 749437.0625  LR: 0.00001445  \n","Epoch: [2][219/220] Elapsed 26m 44s (remain 0m 0s) Loss: 0.1126(0.1129) Grad: 229903.6562  LR: 0.00001393  \n","EVAL: [0/25] Elapsed 0m 1s (remain 0m 38s) Loss: 0.1016(0.1016) \n","EVAL: [20/25] Elapsed 0m 43s (remain 0m 8s) Loss: 0.1155(0.1048) \n","EVAL: [24/25] Elapsed 0m 49s (remain 0m 0s) Loss: 0.1292(0.1054) \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 2 - avg_train_loss: 0.1129  avg_val_loss: 0.1054  time: 1655s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.1129  avg_val_loss: 0.1054  time: 1655s\n","Epoch 2 - Score: 0.4596  Scores: [0.5071773586962509, 0.44199144654420164, 0.41865008487802974, 0.4293710215467987, 0.5080256741976343, 0.4521272291630452]\n","INFO:__main__:Epoch 2 - Score: 0.4596  Scores: [0.5071773586962509, 0.44199144654420164, 0.41865008487802974, 0.4293710215467987, 0.5080256741976343, 0.4521272291630452]\n","Epoch 2 - Save Best Score: 0.4596 Model\n","INFO:__main__:Epoch 2 - Save Best Score: 0.4596 Model\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: [3][0/220] Elapsed 0m 5s (remain 21m 15s) Loss: 0.1192(0.1192) Grad: 509961.0938  LR: 0.00001390  \n","Epoch: [3][20/220] Elapsed 2m 28s (remain 23m 28s) Loss: 0.1159(0.1065) Grad: 481882.0000  LR: 0.00001335  \n","Epoch: [3][40/220] Elapsed 4m 57s (remain 21m 38s) Loss: 0.1455(0.1103) Grad: 684658.4375  LR: 0.00001278  \n","Epoch: [3][60/220] Elapsed 7m 17s (remain 18m 59s) Loss: 0.0883(0.1074) Grad: 353371.2188  LR: 0.00001220  \n","Epoch: [3][80/220] Elapsed 9m 37s (remain 16m 31s) Loss: 0.0727(0.1060) Grad: 519001.0000  LR: 0.00001161  \n","Epoch: [3][100/220] Elapsed 12m 3s (remain 14m 12s) Loss: 0.1338(0.1061) Grad: 248212.3281  LR: 0.00001102  \n","Epoch: [3][120/220] Elapsed 14m 33s (remain 11m 54s) Loss: 0.0952(0.1060) Grad: 373963.3125  LR: 0.00001042  \n","Epoch: [3][140/220] Elapsed 16m 58s (remain 9m 30s) Loss: 0.1077(0.1065) Grad: 549942.2500  LR: 0.00000982  \n","Epoch: [3][160/220] Elapsed 19m 21s (remain 7m 5s) Loss: 0.1007(0.1057) Grad: 339987.8125  LR: 0.00000922  \n","Epoch: [3][180/220] Elapsed 21m 50s (remain 4m 42s) Loss: 0.1199(0.1052) Grad: 277763.6875  LR: 0.00000863  \n","Epoch: [3][200/220] Elapsed 24m 13s (remain 2m 17s) Loss: 0.0936(0.1048) Grad: 405873.8125  LR: 0.00000804  \n","Epoch: [3][219/220] Elapsed 26m 37s (remain 0m 0s) Loss: 0.1121(0.1045) Grad: 519092.7500  LR: 0.00000748  \n","EVAL: [0/25] Elapsed 0m 1s (remain 0m 38s) Loss: 0.0972(0.0972) \n","EVAL: [20/25] Elapsed 0m 43s (remain 0m 8s) Loss: 0.1203(0.1011) \n","EVAL: [24/25] Elapsed 0m 49s (remain 0m 0s) Loss: 0.1272(0.1022) \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 3 - avg_train_loss: 0.1045  avg_val_loss: 0.1022  time: 1648s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.1045  avg_val_loss: 0.1022  time: 1648s\n","Epoch 3 - Score: 0.4521  Scores: [0.49847824574107763, 0.4402829963455268, 0.41644749761463057, 0.4183608561312162, 0.47943840748942534, 0.45944154346211213]\n","INFO:__main__:Epoch 3 - Score: 0.4521  Scores: [0.49847824574107763, 0.4402829963455268, 0.41644749761463057, 0.4183608561312162, 0.47943840748942534, 0.45944154346211213]\n","Epoch 3 - Save Best Score: 0.4521 Model\n","INFO:__main__:Epoch 3 - Save Best Score: 0.4521 Model\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: [4][0/220] Elapsed 0m 6s (remain 23m 27s) Loss: 0.1051(0.1051) Grad: 291642.8125  LR: 0.00000746  \n","Epoch: [4][20/220] Elapsed 2m 26s (remain 23m 8s) Loss: 0.1056(0.1066) Grad: 181906.1094  LR: 0.00000688  \n","Epoch: [4][40/220] Elapsed 5m 1s (remain 21m 57s) Loss: 0.0762(0.1033) Grad: 240273.3281  LR: 0.00000632  \n","Epoch: [4][60/220] Elapsed 7m 15s (remain 18m 54s) Loss: 0.0856(0.1022) Grad: 189246.4688  LR: 0.00000577  \n","Epoch: [4][80/220] Elapsed 9m 50s (remain 16m 53s) Loss: 0.1074(0.1001) Grad: 478910.5312  LR: 0.00000523  \n","Epoch: [4][100/220] Elapsed 12m 18s (remain 14m 29s) Loss: 0.0781(0.0992) Grad: 223361.5469  LR: 0.00000472  \n","Epoch: [4][120/220] Elapsed 14m 37s (remain 11m 57s) Loss: 0.0954(0.0990) Grad: 325312.2812  LR: 0.00000422  \n","Epoch: [4][140/220] Elapsed 17m 11s (remain 9m 37s) Loss: 0.0828(0.0988) Grad: 451928.7812  LR: 0.00000374  \n","Epoch: [4][160/220] Elapsed 19m 29s (remain 7m 8s) Loss: 0.0896(0.0991) Grad: 284288.0938  LR: 0.00000329  \n","Epoch: [4][180/220] Elapsed 21m 54s (remain 4m 43s) Loss: 0.0896(0.0991) Grad: 311666.5938  LR: 0.00000286  \n","Epoch: [4][200/220] Elapsed 24m 25s (remain 2m 18s) Loss: 0.1074(0.0990) Grad: 241850.8750  LR: 0.00000245  \n","Epoch: [4][219/220] Elapsed 26m 38s (remain 0m 0s) Loss: 0.0828(0.0984) Grad: 140322.5000  LR: 0.00000209  \n","EVAL: [0/25] Elapsed 0m 1s (remain 0m 38s) Loss: 0.0910(0.0910) \n","EVAL: [20/25] Elapsed 0m 43s (remain 0m 8s) Loss: 0.1132(0.1021) \n","EVAL: [24/25] Elapsed 0m 49s (remain 0m 0s) Loss: 0.1274(0.1035) \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 4 - avg_train_loss: 0.0984  avg_val_loss: 0.1035  time: 1649s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.0984  avg_val_loss: 0.1035  time: 1649s\n","Epoch 4 - Score: 0.4550  Scores: [0.5093140568578925, 0.43886920890631936, 0.41875154737984094, 0.4239100255727335, 0.4974236601936293, 0.44156136220427317]\n","INFO:__main__:Epoch 4 - Score: 0.4550  Scores: [0.5093140568578925, 0.43886920890631936, 0.41875154737984094, 0.4239100255727335, 0.4974236601936293, 0.44156136220427317]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: [5][0/220] Elapsed 0m 8s (remain 29m 45s) Loss: 0.0905(0.0905) Grad: 395598.6562  LR: 0.00000207  \n","Epoch: [5][20/220] Elapsed 2m 32s (remain 24m 2s) Loss: 0.0795(0.0972) Grad: 211757.3594  LR: 0.00000172  \n","Epoch: [5][40/220] Elapsed 4m 59s (remain 21m 47s) Loss: 0.0776(0.0977) Grad: 377541.6250  LR: 0.00000140  \n","Epoch: [5][60/220] Elapsed 7m 26s (remain 19m 24s) Loss: 0.1009(0.0969) Grad: 343905.0000  LR: 0.00000111  \n","Epoch: [5][80/220] Elapsed 9m 47s (remain 16m 48s) Loss: 0.0961(0.0971) Grad: 161192.3906  LR: 0.00000085  \n","Epoch: [5][100/220] Elapsed 12m 11s (remain 14m 22s) Loss: 0.0718(0.0968) Grad: 140122.8750  LR: 0.00000063  \n","Epoch: [5][120/220] Elapsed 14m 44s (remain 12m 3s) Loss: 0.1067(0.0961) Grad: 162161.1875  LR: 0.00000044  \n","Epoch: [5][140/220] Elapsed 17m 1s (remain 9m 32s) Loss: 0.0903(0.0960) Grad: 529636.8125  LR: 0.00000028  \n","Epoch: [5][160/220] Elapsed 19m 32s (remain 7m 9s) Loss: 0.1030(0.0950) Grad: 150053.0000  LR: 0.00000016  \n","Epoch: [5][180/220] Elapsed 21m 57s (remain 4m 43s) Loss: 0.1129(0.0948) Grad: 296054.4062  LR: 0.00000007  \n","Epoch: [5][200/220] Elapsed 24m 28s (remain 2m 18s) Loss: 0.1130(0.0941) Grad: 261519.1406  LR: 0.00000002  \n","Epoch: [5][219/220] Elapsed 26m 55s (remain 0m 0s) Loss: 0.1110(0.0946) Grad: 423173.9375  LR: 0.00000000  \n","EVAL: [0/25] Elapsed 0m 1s (remain 0m 38s) Loss: 0.0911(0.0911) \n","EVAL: [20/25] Elapsed 0m 43s (remain 0m 8s) Loss: 0.1117(0.0987) \n","EVAL: [24/25] Elapsed 0m 49s (remain 0m 0s) Loss: 0.1212(0.0994) \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 5 - avg_train_loss: 0.0946  avg_val_loss: 0.0994  time: 1666s\n","INFO:__main__:Epoch 5 - avg_train_loss: 0.0946  avg_val_loss: 0.0994  time: 1666s\n","Epoch 5 - Score: 0.4460  Scores: [0.4910301674779384, 0.4380049976649395, 0.41119449044098705, 0.41730256619304334, 0.48126208257303427, 0.4369323443582454]\n","INFO:__main__:Epoch 5 - Score: 0.4460  Scores: [0.4910301674779384, 0.4380049976649395, 0.41119449044098705, 0.41730256619304334, 0.48126208257303427, 0.4369323443582454]\n","Epoch 5 - Save Best Score: 0.4460 Model\n","INFO:__main__:Epoch 5 - Save Best Score: 0.4460 Model\n","========== fold: 0 result ==========\n","INFO:__main__:========== fold: 0 result ==========\n","Score: 0.4460  Scores: [0.4910301674779384, 0.4380049976649395, 0.41119449044098705, 0.41730256619304334, 0.48126208257303427, 0.4369323443582454]\n","INFO:__main__:Score: 0.4460  Scores: [0.4910301674779384, 0.4380049976649395, 0.41119449044098705, 0.41730256619304334, 0.48126208257303427, 0.4369323443582454]\n","========== fold: 1 training ==========\n","INFO:__main__:========== fold: 1 training ==========\n","DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 1024,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.23.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","INFO:__main__:DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 1024,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.23.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['mask_predictions.LayerNorm.weight', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.bias', 'mask_predictions.LayerNorm.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: [1][0/220] Elapsed 0m 4s (remain 15m 7s) Loss: 2.4702(2.4702) Grad: 722133.0625  LR: 0.00000040  \n","Epoch: [1][20/220] Elapsed 1m 11s (remain 11m 19s) Loss: 2.2174(2.2889) Grad: 741387.6250  LR: 0.00000840  \n","Epoch: [1][40/220] Elapsed 2m 30s (remain 10m 58s) Loss: 0.5355(1.8295) Grad: 623163.1250  LR: 0.00001640  \n","Epoch: [1][60/220] Elapsed 3m 49s (remain 9m 58s) Loss: 0.1585(1.3012) Grad: 172137.2188  LR: 0.00001999  \n","Epoch: [1][80/220] Elapsed 5m 5s (remain 8m 44s) Loss: 0.2327(1.0162) Grad: 331678.2500  LR: 0.00001996  \n","Epoch: [1][100/220] Elapsed 6m 13s (remain 7m 20s) Loss: 0.0912(0.8428) Grad: 57610.4102  LR: 0.00001988  \n","Epoch: [1][120/220] Elapsed 7m 28s (remain 6m 7s) Loss: 0.1095(0.7248) Grad: 68192.4531  LR: 0.00001978  \n","Epoch: [1][140/220] Elapsed 8m 39s (remain 4m 51s) Loss: 0.1052(0.6397) Grad: 49102.2773  LR: 0.00001963  \n","Epoch: [1][160/220] Elapsed 9m 57s (remain 3m 39s) Loss: 0.1074(0.5739) Grad: 115585.2656  LR: 0.00001945  \n","Epoch: [1][180/220] Elapsed 11m 11s (remain 2m 24s) Loss: 0.1429(0.5235) Grad: 85512.0938  LR: 0.00001924  \n","Epoch: [1][200/220] Elapsed 12m 31s (remain 1m 11s) Loss: 0.1161(0.4823) Grad: 102142.8359  LR: 0.00001900  \n","Epoch: [1][219/220] Elapsed 13m 42s (remain 0m 0s) Loss: 0.1423(0.4511) Grad: 156825.0781  LR: 0.00001873  \n","EVAL: [0/25] Elapsed 0m 2s (remain 0m 49s) Loss: 0.1165(0.1165) \n","EVAL: [20/25] Elapsed 0m 40s (remain 0m 7s) Loss: 0.1085(0.1154) \n","EVAL: [24/25] Elapsed 0m 47s (remain 0m 0s) Loss: 0.0882(0.1165) \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 1 - avg_train_loss: 0.4511  avg_val_loss: 0.1165  time: 871s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.4511  avg_val_loss: 0.1165  time: 871s\n","Epoch 1 - Score: 0.4834  Scores: [0.5119865041331083, 0.4547660904782616, 0.45277884094239734, 0.4715507339984193, 0.4694621621999787, 0.5396172993355681]\n","INFO:__main__:Epoch 1 - Score: 0.4834  Scores: [0.5119865041331083, 0.4547660904782616, 0.45277884094239734, 0.4715507339984193, 0.4694621621999787, 0.5396172993355681]\n","Epoch 1 - Save Best Score: 0.4834 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.4834 Model\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: [2][0/220] Elapsed 0m 6s (remain 22m 12s) Loss: 0.1366(0.1366) Grad: 484744.5312  LR: 0.00001872  \n","Epoch: [2][20/220] Elapsed 2m 29s (remain 23m 40s) Loss: 0.0812(0.1055) Grad: 405956.3438  LR: 0.00001841  \n","Epoch: [2][40/220] Elapsed 4m 45s (remain 20m 48s) Loss: 0.1153(0.1059) Grad: 585616.6875  LR: 0.00001807  \n","Epoch: [2][60/220] Elapsed 7m 15s (remain 18m 54s) Loss: 0.0891(0.1068) Grad: 513928.8125  LR: 0.00001771  \n","Epoch: [2][80/220] Elapsed 9m 48s (remain 16m 49s) Loss: 0.1064(0.1074) Grad: 294800.1875  LR: 0.00001731  \n","Epoch: [2][100/220] Elapsed 11m 57s (remain 14m 5s) Loss: 0.0911(0.1062) Grad: 337137.0312  LR: 0.00001689  \n","Epoch: [2][120/220] Elapsed 14m 27s (remain 11m 50s) Loss: 0.0819(0.1070) Grad: 214041.2188  LR: 0.00001644  \n","Epoch: [2][140/220] Elapsed 16m 56s (remain 9m 29s) Loss: 0.0828(0.1063) Grad: 394603.9062  LR: 0.00001597  \n","Epoch: [2][160/220] Elapsed 19m 22s (remain 7m 6s) Loss: 0.1039(0.1062) Grad: 318577.8750  LR: 0.00001548  \n","Epoch: [2][180/220] Elapsed 21m 36s (remain 4m 39s) Loss: 0.0810(0.1059) Grad: 164323.4219  LR: 0.00001497  \n","Epoch: [2][200/220] Elapsed 23m 57s (remain 2m 15s) Loss: 0.1233(0.1060) Grad: 131516.7344  LR: 0.00001445  \n","Epoch: [2][219/220] Elapsed 26m 12s (remain 0m 0s) Loss: 0.1435(0.1064) Grad: 271417.3750  LR: 0.00001393  \n","EVAL: [0/25] Elapsed 0m 2s (remain 0m 49s) Loss: 0.1026(0.1026) \n","EVAL: [20/25] Elapsed 0m 40s (remain 0m 7s) Loss: 0.1064(0.1066) \n","EVAL: [24/25] Elapsed 0m 48s (remain 0m 0s) Loss: 0.0793(0.1072) \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 2 - avg_train_loss: 0.1064  avg_val_loss: 0.1072  time: 1621s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.1064  avg_val_loss: 0.1072  time: 1621s\n","Epoch 2 - Score: 0.4637  Scores: [0.5125900690163793, 0.44898869077026243, 0.4306684423419355, 0.45097661554321, 0.4698070546360336, 0.46920440119291223]\n","INFO:__main__:Epoch 2 - Score: 0.4637  Scores: [0.5125900690163793, 0.44898869077026243, 0.4306684423419355, 0.45097661554321, 0.4698070546360336, 0.46920440119291223]\n","Epoch 2 - Save Best Score: 0.4637 Model\n","INFO:__main__:Epoch 2 - Save Best Score: 0.4637 Model\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: [3][0/220] Elapsed 0m 8s (remain 29m 13s) Loss: 0.1122(0.1122) Grad: 396449.0312  LR: 0.00001390  \n","Epoch: [3][20/220] Elapsed 2m 23s (remain 22m 35s) Loss: 0.0835(0.1092) Grad: 201918.0781  LR: 0.00001335  \n","Epoch: [3][40/220] Elapsed 4m 44s (remain 20m 42s) Loss: 0.1062(0.1003) Grad: 319521.4375  LR: 0.00001278  \n","Epoch: [3][60/220] Elapsed 6m 59s (remain 18m 12s) Loss: 0.0867(0.1030) Grad: 208847.2031  LR: 0.00001220  \n","Epoch: [3][80/220] Elapsed 9m 21s (remain 16m 3s) Loss: 0.1089(0.1021) Grad: 125172.6484  LR: 0.00001161  \n","Epoch: [3][100/220] Elapsed 11m 57s (remain 14m 5s) Loss: 0.0914(0.1020) Grad: 308527.8438  LR: 0.00001102  \n","Epoch: [3][120/220] Elapsed 14m 24s (remain 11m 46s) Loss: 0.0994(0.1024) Grad: 172766.5781  LR: 0.00001042  \n","Epoch: [3][140/220] Elapsed 16m 50s (remain 9m 26s) Loss: 0.0824(0.1016) Grad: 334769.8438  LR: 0.00000982  \n","Epoch: [3][160/220] Elapsed 19m 14s (remain 7m 3s) Loss: 0.1121(0.1016) Grad: 209150.0000  LR: 0.00000922  \n","Epoch: [3][180/220] Elapsed 21m 40s (remain 4m 40s) Loss: 0.0949(0.1009) Grad: 297023.8750  LR: 0.00000863  \n","Epoch: [3][200/220] Elapsed 24m 6s (remain 2m 16s) Loss: 0.1009(0.1010) Grad: 339671.1562  LR: 0.00000804  \n","Epoch: [3][219/220] Elapsed 26m 15s (remain 0m 0s) Loss: 0.0957(0.1006) Grad: 290723.7188  LR: 0.00000748  \n","EVAL: [0/25] Elapsed 0m 2s (remain 0m 49s) Loss: 0.0997(0.0997) \n","EVAL: [20/25] Elapsed 0m 40s (remain 0m 7s) Loss: 0.1106(0.1044) \n","EVAL: [24/25] Elapsed 0m 48s (remain 0m 0s) Loss: 0.0723(0.1055) \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 3 - avg_train_loss: 0.1006  avg_val_loss: 0.1055  time: 1624s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.1006  avg_val_loss: 0.1055  time: 1624s\n","Epoch 3 - Score: 0.4600  Scores: [0.5111377566619777, 0.45195401722603595, 0.4275765423989792, 0.4479826057385723, 0.4552988607438025, 0.4662361811528883]\n","INFO:__main__:Epoch 3 - Score: 0.4600  Scores: [0.5111377566619777, 0.45195401722603595, 0.4275765423989792, 0.4479826057385723, 0.4552988607438025, 0.4662361811528883]\n","Epoch 3 - Save Best Score: 0.4600 Model\n","INFO:__main__:Epoch 3 - Save Best Score: 0.4600 Model\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: [4][0/220] Elapsed 0m 7s (remain 29m 9s) Loss: 0.0776(0.0776) Grad: 148084.9375  LR: 0.00000746  \n","Epoch: [4][20/220] Elapsed 2m 36s (remain 24m 38s) Loss: 0.1231(0.0973) Grad: 668429.5625  LR: 0.00000688  \n","Epoch: [4][40/220] Elapsed 5m 5s (remain 22m 13s) Loss: 0.1101(0.0967) Grad: 178308.6562  LR: 0.00000632  \n","Epoch: [4][60/220] Elapsed 7m 25s (remain 19m 20s) Loss: 0.0753(0.0960) Grad: 171119.1250  LR: 0.00000577  \n","Epoch: [4][80/220] Elapsed 9m 57s (remain 17m 4s) Loss: 0.0905(0.0963) Grad: 403069.3750  LR: 0.00000523  \n","Epoch: [4][100/220] Elapsed 12m 34s (remain 14m 48s) Loss: 0.1081(0.0981) Grad: 407675.6250  LR: 0.00000472  \n","Epoch: [4][120/220] Elapsed 14m 59s (remain 12m 16s) Loss: 0.0688(0.0978) Grad: 279253.6875  LR: 0.00000422  \n","Epoch: [4][140/220] Elapsed 17m 19s (remain 9m 42s) Loss: 0.0845(0.0971) Grad: 169405.9375  LR: 0.00000374  \n","Epoch: [4][160/220] Elapsed 19m 44s (remain 7m 13s) Loss: 0.0917(0.0964) Grad: 219802.2969  LR: 0.00000329  \n","Epoch: [4][180/220] Elapsed 22m 8s (remain 4m 46s) Loss: 0.0789(0.0966) Grad: 289761.7812  LR: 0.00000286  \n","Epoch: [4][200/220] Elapsed 24m 42s (remain 2m 20s) Loss: 0.0875(0.0960) Grad: 271726.4375  LR: 0.00000245  \n","Epoch: [4][219/220] Elapsed 27m 6s (remain 0m 0s) Loss: 0.0832(0.0954) Grad: 426763.8125  LR: 0.00000209  \n","EVAL: [0/25] Elapsed 0m 2s (remain 0m 49s) Loss: 0.0997(0.0997) \n","EVAL: [20/25] Elapsed 0m 40s (remain 0m 7s) Loss: 0.1128(0.1044) \n","EVAL: [24/25] Elapsed 0m 48s (remain 0m 0s) Loss: 0.0727(0.1052) \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 4 - avg_train_loss: 0.0954  avg_val_loss: 0.1052  time: 1675s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.0954  avg_val_loss: 0.1052  time: 1675s\n","Epoch 4 - Score: 0.4593  Scores: [0.5023586219529032, 0.44953755537434414, 0.4352125498900522, 0.4479427456603446, 0.4567046803193001, 0.46427473575435163]\n","INFO:__main__:Epoch 4 - Score: 0.4593  Scores: [0.5023586219529032, 0.44953755537434414, 0.4352125498900522, 0.4479427456603446, 0.4567046803193001, 0.46427473575435163]\n","Epoch 4 - Save Best Score: 0.4593 Model\n","INFO:__main__:Epoch 4 - Save Best Score: 0.4593 Model\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: [5][0/220] Elapsed 0m 8s (remain 32m 9s) Loss: 0.1069(0.1069) Grad: 468775.8125  LR: 0.00000207  \n","Epoch: [5][20/220] Elapsed 2m 40s (remain 25m 21s) Loss: 0.1096(0.0935) Grad: 204140.5156  LR: 0.00000172  \n","Epoch: [5][40/220] Elapsed 5m 11s (remain 22m 41s) Loss: 0.0702(0.0929) Grad: 134425.2188  LR: 0.00000140  \n","Epoch: [5][60/220] Elapsed 7m 28s (remain 19m 29s) Loss: 0.0985(0.0912) Grad: 354787.7500  LR: 0.00000111  \n","Epoch: [5][80/220] Elapsed 9m 53s (remain 16m 58s) Loss: 0.1027(0.0924) Grad: 217982.0156  LR: 0.00000085  \n","Epoch: [5][100/220] Elapsed 12m 9s (remain 14m 19s) Loss: 0.0820(0.0929) Grad: 157386.9062  LR: 0.00000063  \n","Epoch: [5][120/220] Elapsed 14m 38s (remain 11m 58s) Loss: 0.0820(0.0934) Grad: 113860.1641  LR: 0.00000044  \n","Epoch: [5][140/220] Elapsed 16m 50s (remain 9m 26s) Loss: 0.1021(0.0936) Grad: 338506.1250  LR: 0.00000028  \n","Epoch: [5][160/220] Elapsed 19m 31s (remain 7m 9s) Loss: 0.1144(0.0936) Grad: 229821.4688  LR: 0.00000016  \n","Epoch: [5][180/220] Elapsed 21m 51s (remain 4m 42s) Loss: 0.1284(0.0925) Grad: 324687.0312  LR: 0.00000007  \n","Epoch: [5][200/220] Elapsed 24m 3s (remain 2m 16s) Loss: 0.1013(0.0924) Grad: 202845.7969  LR: 0.00000002  \n","Epoch: [5][219/220] Elapsed 26m 36s (remain 0m 0s) Loss: 0.0902(0.0921) Grad: 270097.6875  LR: 0.00000000  \n","EVAL: [0/25] Elapsed 0m 2s (remain 0m 49s) Loss: 0.1013(0.1013) \n","EVAL: [20/25] Elapsed 0m 40s (remain 0m 7s) Loss: 0.1092(0.1029) \n","EVAL: [24/25] Elapsed 0m 48s (remain 0m 0s) Loss: 0.0709(0.1038) \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 5 - avg_train_loss: 0.0921  avg_val_loss: 0.1038  time: 1645s\n","INFO:__main__:Epoch 5 - avg_train_loss: 0.0921  avg_val_loss: 0.1038  time: 1645s\n","Epoch 5 - Score: 0.4562  Scores: [0.501567258207493, 0.4458552241231133, 0.42571061414291056, 0.44884524091672245, 0.4527302411447491, 0.46237406168930095]\n","INFO:__main__:Epoch 5 - Score: 0.4562  Scores: [0.501567258207493, 0.4458552241231133, 0.42571061414291056, 0.44884524091672245, 0.4527302411447491, 0.46237406168930095]\n","Epoch 5 - Save Best Score: 0.4562 Model\n","INFO:__main__:Epoch 5 - Save Best Score: 0.4562 Model\n","========== fold: 1 result ==========\n","INFO:__main__:========== fold: 1 result ==========\n","Score: 0.4562  Scores: [0.501567258207493, 0.4458552241231133, 0.42571061414291056, 0.44884524091672245, 0.4527302411447491, 0.46237406168930095]\n","INFO:__main__:Score: 0.4562  Scores: [0.501567258207493, 0.4458552241231133, 0.42571061414291056, 0.44884524091672245, 0.4527302411447491, 0.46237406168930095]\n","========== fold: 2 training ==========\n","INFO:__main__:========== fold: 2 training ==========\n","DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 1024,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.23.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","INFO:__main__:DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 1024,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.23.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['mask_predictions.LayerNorm.weight', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.bias', 'mask_predictions.LayerNorm.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: [1][0/220] Elapsed 0m 4s (remain 15m 21s) Loss: 2.3669(2.3669) Grad: 712366.8750  LR: 0.00000040  \n","Epoch: [1][20/220] Elapsed 1m 19s (remain 12m 35s) Loss: 1.8091(2.2369) Grad: 770218.5625  LR: 0.00000840  \n","Epoch: [1][40/220] Elapsed 2m 33s (remain 11m 11s) Loss: 0.7511(1.8389) Grad: 737826.3125  LR: 0.00001640  \n","Epoch: [1][60/220] Elapsed 3m 49s (remain 9m 56s) Loss: 0.1238(1.3299) Grad: 207168.1719  LR: 0.00001999  \n","Epoch: [1][80/220] Elapsed 5m 4s (remain 8m 41s) Loss: 0.0955(1.0330) Grad: 198200.7656  LR: 0.00001996  \n","Epoch: [1][100/220] Elapsed 6m 12s (remain 7m 18s) Loss: 0.1204(0.8558) Grad: 311823.1562  LR: 0.00001988  \n","Epoch: [1][120/220] Elapsed 7m 34s (remain 6m 11s) Loss: 0.1273(0.7349) Grad: 127587.6797  LR: 0.00001978  \n","Epoch: [1][140/220] Elapsed 8m 48s (remain 4m 55s) Loss: 0.1580(0.6483) Grad: 238268.2031  LR: 0.00001963  \n","Epoch: [1][160/220] Elapsed 10m 2s (remain 3m 40s) Loss: 0.1255(0.5827) Grad: 269210.4375  LR: 0.00001945  \n","Epoch: [1][180/220] Elapsed 11m 18s (remain 2m 26s) Loss: 0.1270(0.5315) Grad: 119104.2344  LR: 0.00001924  \n","Epoch: [1][200/220] Elapsed 12m 43s (remain 1m 12s) Loss: 0.1355(0.4912) Grad: 289187.9062  LR: 0.00001900  \n","Epoch: [1][219/220] Elapsed 13m 55s (remain 0m 0s) Loss: 0.1458(0.4600) Grad: 142322.4531  LR: 0.00001873  \n","EVAL: [0/25] Elapsed 0m 2s (remain 1m 1s) Loss: 0.1077(0.1077) \n","EVAL: [20/25] Elapsed 0m 41s (remain 0m 7s) Loss: 0.1145(0.1128) \n","EVAL: [24/25] Elapsed 0m 48s (remain 0m 0s) Loss: 0.0990(0.1124) \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 1 - avg_train_loss: 0.4600  avg_val_loss: 0.1124  time: 884s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.4600  avg_val_loss: 0.1124  time: 884s\n","Epoch 1 - Score: 0.4758  Scores: [0.5056692774072958, 0.47156905013390843, 0.4500857553433663, 0.4641414821057917, 0.4830515349692131, 0.48003157430743465]\n","INFO:__main__:Epoch 1 - Score: 0.4758  Scores: [0.5056692774072958, 0.47156905013390843, 0.4500857553433663, 0.4641414821057917, 0.4830515349692131, 0.48003157430743465]\n","Epoch 1 - Save Best Score: 0.4758 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.4758 Model\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: [2][0/220] Elapsed 0m 8s (remain 29m 19s) Loss: 0.1199(0.1199) Grad: 358871.3750  LR: 0.00001872  \n","Epoch: [2][20/220] Elapsed 2m 31s (remain 23m 53s) Loss: 0.1099(0.1147) Grad: 176580.5000  LR: 0.00001841  \n","Epoch: [2][40/220] Elapsed 5m 3s (remain 22m 6s) Loss: 0.0885(0.1136) Grad: 156115.1406  LR: 0.00001807  \n","Epoch: [2][60/220] Elapsed 7m 32s (remain 19m 39s) Loss: 0.1044(0.1134) Grad: 72346.2109  LR: 0.00001771  \n","Epoch: [2][80/220] Elapsed 9m 57s (remain 17m 6s) Loss: 0.0907(0.1115) Grad: 156861.0469  LR: 0.00001731  \n","Epoch: [2][100/220] Elapsed 12m 32s (remain 14m 46s) Loss: 0.1170(0.1110) Grad: 203173.9375  LR: 0.00001689  \n","Epoch: [2][120/220] Elapsed 15m 5s (remain 12m 20s) Loss: 0.0929(0.1115) Grad: 211505.4219  LR: 0.00001644  \n","Epoch: [2][140/220] Elapsed 17m 28s (remain 9m 47s) Loss: 0.0930(0.1125) Grad: 258407.7188  LR: 0.00001597  \n","Epoch: [2][160/220] Elapsed 19m 53s (remain 7m 17s) Loss: 0.1577(0.1130) Grad: 244017.5000  LR: 0.00001548  \n","Epoch: [2][180/220] Elapsed 22m 11s (remain 4m 46s) Loss: 0.1332(0.1135) Grad: 433110.7812  LR: 0.00001497  \n","Epoch: [2][200/220] Elapsed 24m 38s (remain 2m 19s) Loss: 0.0823(0.1133) Grad: 155596.3125  LR: 0.00001445  \n","Epoch: [2][219/220] Elapsed 27m 2s (remain 0m 0s) Loss: 0.1641(0.1131) Grad: 227084.5938  LR: 0.00001393  \n","EVAL: [0/25] Elapsed 0m 2s (remain 1m 1s) Loss: 0.1192(0.1192) \n","EVAL: [20/25] Elapsed 0m 41s (remain 0m 7s) Loss: 0.1076(0.1231) \n","EVAL: [24/25] Elapsed 0m 48s (remain 0m 0s) Loss: 0.1037(0.1221) \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 2 - avg_train_loss: 0.1131  avg_val_loss: 0.1221  time: 1671s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.1131  avg_val_loss: 0.1221  time: 1671s\n","Epoch 2 - Score: 0.4954  Scores: [0.4942114620899301, 0.5183367392685605, 0.4437536861064868, 0.5169491431561687, 0.4826040950032743, 0.5164568334994128]\n","INFO:__main__:Epoch 2 - Score: 0.4954  Scores: [0.4942114620899301, 0.5183367392685605, 0.4437536861064868, 0.5169491431561687, 0.4826040950032743, 0.5164568334994128]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: [3][0/220] Elapsed 0m 8s (remain 29m 13s) Loss: 0.1053(0.1053) Grad: 382401.5938  LR: 0.00001390  \n","Epoch: [3][20/220] Elapsed 2m 30s (remain 23m 45s) Loss: 0.1200(0.1029) Grad: 215429.6406  LR: 0.00001335  \n","Epoch: [3][40/220] Elapsed 5m 1s (remain 21m 54s) Loss: 0.0991(0.1005) Grad: 277907.0938  LR: 0.00001278  \n","Epoch: [3][60/220] Elapsed 7m 38s (remain 19m 55s) Loss: 0.1097(0.1022) Grad: 203333.8594  LR: 0.00001220  \n","Epoch: [3][80/220] Elapsed 10m 9s (remain 17m 26s) Loss: 0.0977(0.1021) Grad: 133586.0000  LR: 0.00001161  \n","Epoch: [3][100/220] Elapsed 12m 28s (remain 14m 42s) Loss: 0.1211(0.1020) Grad: 265629.4062  LR: 0.00001102  \n","Epoch: [3][120/220] Elapsed 14m 44s (remain 12m 3s) Loss: 0.0825(0.1022) Grad: 151375.8125  LR: 0.00001042  \n","Epoch: [3][140/220] Elapsed 17m 19s (remain 9m 42s) Loss: 0.0938(0.1024) Grad: 462615.5312  LR: 0.00000982  \n","Epoch: [3][160/220] Elapsed 19m 42s (remain 7m 13s) Loss: 0.0908(0.1026) Grad: 181171.1406  LR: 0.00000922  \n","Epoch: [3][180/220] Elapsed 21m 54s (remain 4m 43s) Loss: 0.0827(0.1019) Grad: 280895.3438  LR: 0.00000863  \n","Epoch: [3][200/220] Elapsed 24m 13s (remain 2m 17s) Loss: 0.1101(0.1007) Grad: 185717.7656  LR: 0.00000804  \n","Epoch: [3][219/220] Elapsed 26m 29s (remain 0m 0s) Loss: 0.0704(0.1003) Grad: 299520.8125  LR: 0.00000748  \n","EVAL: [0/25] Elapsed 0m 2s (remain 1m 1s) Loss: 0.1059(0.1059) \n","EVAL: [20/25] Elapsed 0m 41s (remain 0m 7s) Loss: 0.1076(0.1056) \n","EVAL: [24/25] Elapsed 0m 48s (remain 0m 0s) Loss: 0.0960(0.1053) \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 3 - avg_train_loss: 0.1003  avg_val_loss: 0.1053  time: 1639s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.1003  avg_val_loss: 0.1053  time: 1639s\n","Epoch 3 - Score: 0.4601  Scores: [0.4799127151614115, 0.45907982203351166, 0.4358366356711857, 0.46227795553396156, 0.4724397508729071, 0.45090896832783833]\n","INFO:__main__:Epoch 3 - Score: 0.4601  Scores: [0.4799127151614115, 0.45907982203351166, 0.4358366356711857, 0.46227795553396156, 0.4724397508729071, 0.45090896832783833]\n","Epoch 3 - Save Best Score: 0.4601 Model\n","INFO:__main__:Epoch 3 - Save Best Score: 0.4601 Model\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: [4][0/220] Elapsed 0m 9s (remain 35m 19s) Loss: 0.1058(0.1058) Grad: 158564.3438  LR: 0.00000746  \n","Epoch: [4][20/220] Elapsed 2m 52s (remain 27m 13s) Loss: 0.0754(0.0953) Grad: 151743.3750  LR: 0.00000688  \n","Epoch: [4][40/220] Elapsed 5m 15s (remain 22m 56s) Loss: 0.0933(0.0990) Grad: 431332.1250  LR: 0.00000632  \n","Epoch: [4][60/220] Elapsed 7m 42s (remain 20m 4s) Loss: 0.0919(0.0991) Grad: 199746.4531  LR: 0.00000577  \n","Epoch: [4][80/220] Elapsed 10m 8s (remain 17m 23s) Loss: 0.0945(0.0992) Grad: 273772.0938  LR: 0.00000523  \n","Epoch: [4][100/220] Elapsed 12m 35s (remain 14m 50s) Loss: 0.0880(0.0998) Grad: 363165.2188  LR: 0.00000472  \n","Epoch: [4][120/220] Elapsed 14m 48s (remain 12m 6s) Loss: 0.0860(0.0987) Grad: 204284.8125  LR: 0.00000422  \n","Epoch: [4][140/220] Elapsed 16m 59s (remain 9m 31s) Loss: 0.0964(0.0983) Grad: 465497.0000  LR: 0.00000374  \n","Epoch: [4][160/220] Elapsed 19m 19s (remain 7m 4s) Loss: 0.0900(0.0973) Grad: 190889.3594  LR: 0.00000329  \n","Epoch: [4][180/220] Elapsed 21m 53s (remain 4m 43s) Loss: 0.1002(0.0965) Grad: 283073.6562  LR: 0.00000286  \n","Epoch: [4][200/220] Elapsed 24m 22s (remain 2m 18s) Loss: 0.0782(0.0963) Grad: 247214.0000  LR: 0.00000245  \n","Epoch: [4][219/220] Elapsed 26m 40s (remain 0m 0s) Loss: 0.0866(0.0961) Grad: 581323.8125  LR: 0.00000209  \n","EVAL: [0/25] Elapsed 0m 2s (remain 1m 1s) Loss: 0.1026(0.1026) \n","EVAL: [20/25] Elapsed 0m 41s (remain 0m 7s) Loss: 0.0982(0.1093) \n","EVAL: [24/25] Elapsed 0m 48s (remain 0m 0s) Loss: 0.0999(0.1079) \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 4 - avg_train_loss: 0.0961  avg_val_loss: 0.1079  time: 1649s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.0961  avg_val_loss: 0.1079  time: 1649s\n","Epoch 4 - Score: 0.4656  Scores: [0.4919926918788628, 0.4702437109666695, 0.4352584857041107, 0.4684299409354479, 0.4686851515749261, 0.4588651538971966]\n","INFO:__main__:Epoch 4 - Score: 0.4656  Scores: [0.4919926918788628, 0.4702437109666695, 0.4352584857041107, 0.4684299409354479, 0.4686851515749261, 0.4588651538971966]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: [5][0/220] Elapsed 0m 7s (remain 29m 11s) Loss: 0.0937(0.0937) Grad: 306306.5000  LR: 0.00000207  \n","Epoch: [5][20/220] Elapsed 2m 41s (remain 25m 29s) Loss: 0.1207(0.0917) Grad: 356671.5625  LR: 0.00000172  \n","Epoch: [5][40/220] Elapsed 5m 5s (remain 22m 13s) Loss: 0.1223(0.0924) Grad: 269373.7812  LR: 0.00000140  \n","Epoch: [5][60/220] Elapsed 7m 28s (remain 19m 29s) Loss: 0.1031(0.0920) Grad: 388696.4062  LR: 0.00000111  \n","Epoch: [5][80/220] Elapsed 9m 49s (remain 16m 52s) Loss: 0.1173(0.0925) Grad: 453958.9062  LR: 0.00000085  \n","Epoch: [5][100/220] Elapsed 12m 3s (remain 14m 12s) Loss: 0.1190(0.0922) Grad: 249220.9375  LR: 0.00000063  \n","Epoch: [5][120/220] Elapsed 14m 32s (remain 11m 53s) Loss: 0.0591(0.0915) Grad: 195836.0000  LR: 0.00000044  \n","Epoch: [5][140/220] Elapsed 17m 2s (remain 9m 32s) Loss: 0.0850(0.0913) Grad: 442013.7500  LR: 0.00000028  \n","Epoch: [5][160/220] Elapsed 19m 40s (remain 7m 12s) Loss: 0.1045(0.0919) Grad: 183040.1719  LR: 0.00000016  \n","Epoch: [5][180/220] Elapsed 22m 7s (remain 4m 45s) Loss: 0.1043(0.0923) Grad: 350417.7500  LR: 0.00000007  \n","Epoch: [5][200/220] Elapsed 24m 29s (remain 2m 18s) Loss: 0.0784(0.0926) Grad: 217882.2188  LR: 0.00000002  \n","Epoch: [5][219/220] Elapsed 26m 46s (remain 0m 0s) Loss: 0.0905(0.0931) Grad: 162581.8594  LR: 0.00000000  \n","EVAL: [0/25] Elapsed 0m 2s (remain 1m 0s) Loss: 0.1014(0.1014) \n","EVAL: [20/25] Elapsed 0m 41s (remain 0m 7s) Loss: 0.1013(0.1048) \n","EVAL: [24/25] Elapsed 0m 48s (remain 0m 0s) Loss: 0.0973(0.1040) \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 5 - avg_train_loss: 0.0931  avg_val_loss: 0.1040  time: 1656s\n","INFO:__main__:Epoch 5 - avg_train_loss: 0.0931  avg_val_loss: 0.1040  time: 1656s\n","Epoch 5 - Score: 0.4573  Scores: [0.4738823153079992, 0.45814768946783085, 0.43429212475457796, 0.46085858813054964, 0.4667310251345095, 0.4501193441252715]\n","INFO:__main__:Epoch 5 - Score: 0.4573  Scores: [0.4738823153079992, 0.45814768946783085, 0.43429212475457796, 0.46085858813054964, 0.4667310251345095, 0.4501193441252715]\n","Epoch 5 - Save Best Score: 0.4573 Model\n","INFO:__main__:Epoch 5 - Save Best Score: 0.4573 Model\n","========== fold: 2 result ==========\n","INFO:__main__:========== fold: 2 result ==========\n","Score: 0.4573  Scores: [0.4738823153079992, 0.45814768946783085, 0.43429212475457796, 0.46085858813054964, 0.4667310251345095, 0.4501193441252715]\n","INFO:__main__:Score: 0.4573  Scores: [0.4738823153079992, 0.45814768946783085, 0.43429212475457796, 0.46085858813054964, 0.4667310251345095, 0.4501193441252715]\n","========== fold: 3 training ==========\n","INFO:__main__:========== fold: 3 training ==========\n","DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 1024,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.23.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","INFO:__main__:DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 1024,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.23.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['mask_predictions.LayerNorm.weight', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.bias', 'mask_predictions.LayerNorm.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: [1][0/220] Elapsed 0m 4s (remain 14m 41s) Loss: 2.7591(2.7591) Grad: 681825.1875  LR: 0.00000040  \n","Epoch: [1][20/220] Elapsed 1m 19s (remain 12m 32s) Loss: 2.2864(2.5305) Grad: 711072.2500  LR: 0.00000840  \n","Epoch: [1][40/220] Elapsed 2m 37s (remain 11m 28s) Loss: 1.2460(2.1206) Grad: 779829.8125  LR: 0.00001640  \n","Epoch: [1][60/220] Elapsed 3m 52s (remain 10m 6s) Loss: 0.1821(1.5716) Grad: 199070.4062  LR: 0.00001999  \n","Epoch: [1][80/220] Elapsed 5m 5s (remain 8m 43s) Loss: 0.1350(1.2246) Grad: 195050.3281  LR: 0.00001996  \n","Epoch: [1][100/220] Elapsed 6m 24s (remain 7m 32s) Loss: 0.1793(1.0090) Grad: 178549.3125  LR: 0.00001988  \n","Epoch: [1][120/220] Elapsed 7m 44s (remain 6m 19s) Loss: 0.1196(0.8613) Grad: 122320.6406  LR: 0.00001978  \n","Epoch: [1][140/220] Elapsed 8m 56s (remain 5m 0s) Loss: 0.1207(0.7559) Grad: 297703.2500  LR: 0.00001963  \n","Epoch: [1][160/220] Elapsed 10m 9s (remain 3m 43s) Loss: 0.0972(0.6760) Grad: 175355.7656  LR: 0.00001945  \n","Epoch: [1][180/220] Elapsed 11m 21s (remain 2m 26s) Loss: 0.1191(0.6139) Grad: 245740.5938  LR: 0.00001924  \n","Epoch: [1][200/220] Elapsed 12m 41s (remain 1m 11s) Loss: 0.0992(0.5648) Grad: 131759.2031  LR: 0.00001900  \n","Epoch: [1][219/220] Elapsed 13m 41s (remain 0m 0s) Loss: 0.1105(0.5262) Grad: 219674.2344  LR: 0.00001873  \n","EVAL: [0/25] Elapsed 0m 1s (remain 0m 46s) Loss: 0.0997(0.0997) \n","EVAL: [20/25] Elapsed 0m 44s (remain 0m 8s) Loss: 0.1300(0.1067) \n","EVAL: [24/25] Elapsed 0m 51s (remain 0m 0s) Loss: 0.1030(0.1085) \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 1 - avg_train_loss: 0.5262  avg_val_loss: 0.1085  time: 874s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.5262  avg_val_loss: 0.1085  time: 874s\n","Epoch 1 - Score: 0.4668  Scores: [0.5068478495571274, 0.45579321619114016, 0.4532088652006552, 0.46268740469518943, 0.4672952883568196, 0.4549876929779393]\n","INFO:__main__:Epoch 1 - Score: 0.4668  Scores: [0.5068478495571274, 0.45579321619114016, 0.4532088652006552, 0.46268740469518943, 0.4672952883568196, 0.4549876929779393]\n","Epoch 1 - Save Best Score: 0.4668 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.4668 Model\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: [2][0/220] Elapsed 0m 8s (remain 29m 22s) Loss: 0.1325(0.1325) Grad: 349527.8438  LR: 0.00001872  \n","Epoch: [2][20/220] Elapsed 2m 24s (remain 22m 47s) Loss: 0.0770(0.1010) Grad: 424084.0625  LR: 0.00001841  \n","Epoch: [2][40/220] Elapsed 4m 40s (remain 20m 25s) Loss: 0.0961(0.1066) Grad: 327394.0312  LR: 0.00001807  \n","Epoch: [2][60/220] Elapsed 7m 9s (remain 18m 39s) Loss: 0.1316(0.1073) Grad: 787380.0000  LR: 0.00001771  \n","Epoch: [2][80/220] Elapsed 9m 30s (remain 16m 19s) Loss: 0.1219(0.1073) Grad: 177680.1875  LR: 0.00001731  \n","Epoch: [2][100/220] Elapsed 11m 52s (remain 13m 59s) Loss: 0.1170(0.1078) Grad: 333305.5312  LR: 0.00001689  \n","Epoch: [2][120/220] Elapsed 14m 30s (remain 11m 51s) Loss: 0.1163(0.1083) Grad: 677425.7500  LR: 0.00001644  \n","Epoch: [2][140/220] Elapsed 16m 56s (remain 9m 29s) Loss: 0.1000(0.1097) Grad: 282666.2188  LR: 0.00001597  \n","Epoch: [2][160/220] Elapsed 19m 16s (remain 7m 3s) Loss: 0.1159(0.1090) Grad: 184686.7188  LR: 0.00001548  \n","Epoch: [2][180/220] Elapsed 21m 42s (remain 4m 40s) Loss: 0.1158(0.1099) Grad: 436813.0938  LR: 0.00001497  \n","Epoch: [2][200/220] Elapsed 24m 5s (remain 2m 16s) Loss: 0.1029(0.1081) Grad: 348008.8750  LR: 0.00001445  \n","Epoch: [2][219/220] Elapsed 26m 16s (remain 0m 0s) Loss: 0.1493(0.1084) Grad: 435049.4375  LR: 0.00001393  \n","EVAL: [0/25] Elapsed 0m 1s (remain 0m 45s) Loss: 0.0860(0.0860) \n","EVAL: [20/25] Elapsed 0m 44s (remain 0m 8s) Loss: 0.1338(0.1050) \n","EVAL: [24/25] Elapsed 0m 51s (remain 0m 0s) Loss: 0.1029(0.1064) \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 2 - avg_train_loss: 0.1084  avg_val_loss: 0.1064  time: 1629s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.1084  avg_val_loss: 0.1064  time: 1629s\n","Epoch 2 - Score: 0.4617  Scores: [0.4945925300484922, 0.45234077990972477, 0.4510022406053616, 0.4534772746473546, 0.4674084044360895, 0.4516590568991992]\n","INFO:__main__:Epoch 2 - Score: 0.4617  Scores: [0.4945925300484922, 0.45234077990972477, 0.4510022406053616, 0.4534772746473546, 0.4674084044360895, 0.4516590568991992]\n","Epoch 2 - Save Best Score: 0.4617 Model\n","INFO:__main__:Epoch 2 - Save Best Score: 0.4617 Model\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: [3][0/220] Elapsed 0m 8s (remain 29m 26s) Loss: 0.0982(0.0982) Grad: 268509.6562  LR: 0.00001390  \n","Epoch: [3][20/220] Elapsed 2m 32s (remain 24m 9s) Loss: 0.1164(0.1026) Grad: 168463.2344  LR: 0.00001335  \n","Epoch: [3][40/220] Elapsed 4m 58s (remain 21m 43s) Loss: 0.0977(0.1000) Grad: 612966.3750  LR: 0.00001278  \n","Epoch: [3][60/220] Elapsed 7m 28s (remain 19m 30s) Loss: 0.0782(0.1020) Grad: 303707.0000  LR: 0.00001220  \n","Epoch: [3][80/220] Elapsed 9m 56s (remain 17m 3s) Loss: 0.0828(0.1018) Grad: 342956.8750  LR: 0.00001161  \n","Epoch: [3][100/220] Elapsed 12m 19s (remain 14m 31s) Loss: 0.0881(0.1028) Grad: 566776.1250  LR: 0.00001102  \n","Epoch: [3][120/220] Elapsed 14m 33s (remain 11m 55s) Loss: 0.0752(0.1029) Grad: 425206.5938  LR: 0.00001042  \n","Epoch: [3][140/220] Elapsed 16m 51s (remain 9m 26s) Loss: 0.1216(0.1026) Grad: 310485.7188  LR: 0.00000982  \n","Epoch: [3][160/220] Elapsed 19m 33s (remain 7m 9s) Loss: 0.0899(0.1027) Grad: 160753.0156  LR: 0.00000922  \n","Epoch: [3][180/220] Elapsed 21m 49s (remain 4m 42s) Loss: 0.1190(0.1023) Grad: 269948.3438  LR: 0.00000863  \n","Epoch: [3][200/220] Elapsed 24m 1s (remain 2m 16s) Loss: 0.0898(0.1023) Grad: 147414.3906  LR: 0.00000804  \n","Epoch: [3][219/220] Elapsed 26m 19s (remain 0m 0s) Loss: 0.1036(0.1021) Grad: 259980.2344  LR: 0.00000748  \n","EVAL: [0/25] Elapsed 0m 1s (remain 0m 45s) Loss: 0.0974(0.0974) \n","EVAL: [20/25] Elapsed 0m 44s (remain 0m 8s) Loss: 0.1087(0.1054) \n","EVAL: [24/25] Elapsed 0m 51s (remain 0m 0s) Loss: 0.0918(0.1056) \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 3 - avg_train_loss: 0.1021  avg_val_loss: 0.1056  time: 1632s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.1021  avg_val_loss: 0.1056  time: 1632s\n","Epoch 3 - Score: 0.4601  Scores: [0.4936936958187571, 0.4459178276526492, 0.42451440070967783, 0.46227377938618347, 0.475431922892444, 0.4589362419619713]\n","INFO:__main__:Epoch 3 - Score: 0.4601  Scores: [0.4936936958187571, 0.4459178276526492, 0.42451440070967783, 0.46227377938618347, 0.475431922892444, 0.4589362419619713]\n","Epoch 3 - Save Best Score: 0.4601 Model\n","INFO:__main__:Epoch 3 - Save Best Score: 0.4601 Model\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: [4][0/220] Elapsed 0m 4s (remain 15m 25s) Loss: 0.1145(0.1145) Grad: 520235.8125  LR: 0.00000746  \n","Epoch: [4][20/220] Elapsed 2m 25s (remain 22m 59s) Loss: 0.1140(0.0947) Grad: 323600.7812  LR: 0.00000688  \n","Epoch: [4][40/220] Elapsed 4m 52s (remain 21m 14s) Loss: 0.0922(0.0965) Grad: 159551.1719  LR: 0.00000632  \n","Epoch: [4][60/220] Elapsed 7m 21s (remain 19m 10s) Loss: 0.0920(0.0968) Grad: 263615.7188  LR: 0.00000577  \n","Epoch: [4][80/220] Elapsed 9m 49s (remain 16m 51s) Loss: 0.0689(0.0964) Grad: 324052.9375  LR: 0.00000523  \n","Epoch: [4][100/220] Elapsed 12m 25s (remain 14m 38s) Loss: 0.0772(0.0976) Grad: 184994.4375  LR: 0.00000472  \n","Epoch: [4][120/220] Elapsed 14m 57s (remain 12m 14s) Loss: 0.0888(0.0976) Grad: 261774.9844  LR: 0.00000422  \n","Epoch: [4][140/220] Elapsed 17m 18s (remain 9m 41s) Loss: 0.0857(0.0966) Grad: 262060.9531  LR: 0.00000374  \n","Epoch: [4][160/220] Elapsed 19m 54s (remain 7m 17s) Loss: 0.1290(0.0964) Grad: 166937.7344  LR: 0.00000329  \n","Epoch: [4][180/220] Elapsed 22m 18s (remain 4m 48s) Loss: 0.0739(0.0960) Grad: 182210.3125  LR: 0.00000286  \n","Epoch: [4][200/220] Elapsed 24m 38s (remain 2m 19s) Loss: 0.0899(0.0957) Grad: 251660.8750  LR: 0.00000245  \n","Epoch: [4][219/220] Elapsed 26m 50s (remain 0m 0s) Loss: 0.1285(0.0953) Grad: 538659.1875  LR: 0.00000209  \n","EVAL: [0/25] Elapsed 0m 1s (remain 0m 46s) Loss: 0.0945(0.0945) \n","EVAL: [20/25] Elapsed 0m 44s (remain 0m 8s) Loss: 0.1127(0.1015) \n","EVAL: [24/25] Elapsed 0m 51s (remain 0m 0s) Loss: 0.0902(0.1015) \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 4 - avg_train_loss: 0.0953  avg_val_loss: 0.1015  time: 1663s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.0953  avg_val_loss: 0.1015  time: 1663s\n","Epoch 4 - Score: 0.4508  Scores: [0.49065586103877507, 0.4534687355606532, 0.4137061277124799, 0.451127405737466, 0.45205649838951517, 0.44407479374599895]\n","INFO:__main__:Epoch 4 - Score: 0.4508  Scores: [0.49065586103877507, 0.4534687355606532, 0.4137061277124799, 0.451127405737466, 0.45205649838951517, 0.44407479374599895]\n","Epoch 4 - Save Best Score: 0.4508 Model\n","INFO:__main__:Epoch 4 - Save Best Score: 0.4508 Model\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: [5][0/220] Elapsed 0m 6s (remain 23m 56s) Loss: 0.0683(0.0683) Grad: 133566.5938  LR: 0.00000207  \n","Epoch: [5][20/220] Elapsed 2m 20s (remain 22m 12s) Loss: 0.0959(0.0894) Grad: 320171.0000  LR: 0.00000172  \n","Epoch: [5][40/220] Elapsed 4m 49s (remain 21m 3s) Loss: 0.1108(0.0923) Grad: 183977.4062  LR: 0.00000140  \n","Epoch: [5][60/220] Elapsed 7m 7s (remain 18m 34s) Loss: 0.0802(0.0920) Grad: 134577.9219  LR: 0.00000111  \n","Epoch: [5][80/220] Elapsed 9m 28s (remain 16m 15s) Loss: 0.0785(0.0919) Grad: 206221.9062  LR: 0.00000085  \n","Epoch: [5][100/220] Elapsed 12m 2s (remain 14m 11s) Loss: 0.1042(0.0916) Grad: 180635.3750  LR: 0.00000063  \n","Epoch: [5][120/220] Elapsed 14m 26s (remain 11m 49s) Loss: 0.0746(0.0915) Grad: 303330.5000  LR: 0.00000044  \n","Epoch: [5][140/220] Elapsed 16m 54s (remain 9m 28s) Loss: 0.0797(0.0918) Grad: 176865.1406  LR: 0.00000028  \n","Epoch: [5][160/220] Elapsed 19m 18s (remain 7m 4s) Loss: 0.0869(0.0924) Grad: 286572.4062  LR: 0.00000016  \n","Epoch: [5][180/220] Elapsed 21m 49s (remain 4m 42s) Loss: 0.0774(0.0916) Grad: 205094.8906  LR: 0.00000007  \n","Epoch: [5][200/220] Elapsed 24m 14s (remain 2m 17s) Loss: 0.0848(0.0917) Grad: 203408.0312  LR: 0.00000002  \n","Epoch: [5][219/220] Elapsed 26m 17s (remain 0m 0s) Loss: 0.1202(0.0921) Grad: 335081.0000  LR: 0.00000000  \n","EVAL: [0/25] Elapsed 0m 1s (remain 0m 45s) Loss: 0.0884(0.0884) \n","EVAL: [20/25] Elapsed 0m 44s (remain 0m 8s) Loss: 0.1137(0.0999) \n","EVAL: [24/25] Elapsed 0m 51s (remain 0m 0s) Loss: 0.0956(0.1004) \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 5 - avg_train_loss: 0.0921  avg_val_loss: 0.1004  time: 1630s\n","INFO:__main__:Epoch 5 - avg_train_loss: 0.0921  avg_val_loss: 0.1004  time: 1630s\n","Epoch 5 - Score: 0.4484  Scores: [0.4878350237089945, 0.44605727528913386, 0.41539172760831894, 0.4487571901004273, 0.45202962472155916, 0.4402272161689062]\n","INFO:__main__:Epoch 5 - Score: 0.4484  Scores: [0.4878350237089945, 0.44605727528913386, 0.41539172760831894, 0.4487571901004273, 0.45202962472155916, 0.4402272161689062]\n","Epoch 5 - Save Best Score: 0.4484 Model\n","INFO:__main__:Epoch 5 - Save Best Score: 0.4484 Model\n","========== fold: 3 result ==========\n","INFO:__main__:========== fold: 3 result ==========\n","Score: 0.4484  Scores: [0.4878350237089945, 0.44605727528913386, 0.41539172760831894, 0.4487571901004273, 0.45202962472155916, 0.4402272161689062]\n","INFO:__main__:Score: 0.4484  Scores: [0.4878350237089945, 0.44605727528913386, 0.41539172760831894, 0.4487571901004273, 0.45202962472155916, 0.4402272161689062]\n","========== fold: 4 training ==========\n","INFO:__main__:========== fold: 4 training ==========\n","DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 1024,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.23.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","INFO:__main__:DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 1024,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.23.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['mask_predictions.LayerNorm.weight', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.bias', 'mask_predictions.LayerNorm.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: [1][0/220] Elapsed 0m 3s (remain 12m 15s) Loss: 2.7759(2.7759) Grad: 717046.5000  LR: 0.00000040  \n","Epoch: [1][20/220] Elapsed 1m 17s (remain 12m 14s) Loss: 2.4173(2.6055) Grad: 715282.0625  LR: 0.00000840  \n","Epoch: [1][40/220] Elapsed 2m 36s (remain 11m 22s) Loss: 0.8941(2.1916) Grad: 704431.7500  LR: 0.00001640  \n","Epoch: [1][60/220] Elapsed 3m 57s (remain 10m 19s) Loss: 0.3106(1.5881) Grad: inf  LR: 0.00001999  \n","Epoch: [1][80/220] Elapsed 5m 15s (remain 9m 0s) Loss: 0.1867(1.2339) Grad: 275874.3438  LR: 0.00001996  \n","Epoch: [1][100/220] Elapsed 6m 23s (remain 7m 32s) Loss: 0.1666(1.0201) Grad: 177674.2031  LR: 0.00001988  \n","Epoch: [1][120/220] Elapsed 7m 38s (remain 6m 15s) Loss: 0.1256(0.8718) Grad: 68304.5312  LR: 0.00001978  \n","Epoch: [1][140/220] Elapsed 8m 50s (remain 4m 57s) Loss: 0.0829(0.7657) Grad: 80867.4922  LR: 0.00001963  \n","Epoch: [1][160/220] Elapsed 10m 8s (remain 3m 43s) Loss: 0.1010(0.6867) Grad: 51742.5938  LR: 0.00001945  \n","Epoch: [1][180/220] Elapsed 11m 24s (remain 2m 27s) Loss: 0.1121(0.6226) Grad: 103399.1797  LR: 0.00001924  \n","Epoch: [1][200/220] Elapsed 12m 36s (remain 1m 11s) Loss: 0.1172(0.5713) Grad: 71371.7500  LR: 0.00001900  \n","Epoch: [1][219/220] Elapsed 13m 48s (remain 0m 0s) Loss: 0.1100(0.5318) Grad: 85748.1406  LR: 0.00001873  \n","EVAL: [0/25] Elapsed 0m 2s (remain 1m 1s) Loss: 0.1305(0.1305) \n","EVAL: [20/25] Elapsed 0m 43s (remain 0m 8s) Loss: 0.0957(0.1157) \n","EVAL: [24/25] Elapsed 0m 51s (remain 0m 0s) Loss: 0.1138(0.1171) \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 1 - avg_train_loss: 0.5318  avg_val_loss: 0.1171  time: 880s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.5318  avg_val_loss: 0.1171  time: 880s\n","Epoch 1 - Score: 0.4854  Scores: [0.5216617522986787, 0.5088806963518241, 0.4405385015549949, 0.4658878819031377, 0.5052108004516728, 0.470456829513346]\n","INFO:__main__:Epoch 1 - Score: 0.4854  Scores: [0.5216617522986787, 0.5088806963518241, 0.4405385015549949, 0.4658878819031377, 0.5052108004516728, 0.470456829513346]\n","Epoch 1 - Save Best Score: 0.4854 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.4854 Model\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: [2][0/220] Elapsed 0m 7s (remain 29m 5s) Loss: 0.1496(0.1496) Grad: 797531.7500  LR: 0.00001872  \n","Epoch: [2][20/220] Elapsed 2m 27s (remain 23m 16s) Loss: 0.1555(0.1219) Grad: 668872.8125  LR: 0.00001841  \n","Epoch: [2][40/220] Elapsed 4m 45s (remain 20m 44s) Loss: 0.1142(0.1134) Grad: 496585.8125  LR: 0.00001807  \n","Epoch: [2][60/220] Elapsed 7m 3s (remain 18m 23s) Loss: 0.0902(0.1096) Grad: 349474.8438  LR: 0.00001771  \n","Epoch: [2][80/220] Elapsed 9m 29s (remain 16m 17s) Loss: 0.1259(0.1098) Grad: 230916.0469  LR: 0.00001731  \n","Epoch: [2][100/220] Elapsed 11m 48s (remain 13m 55s) Loss: 0.1160(0.1090) Grad: 753955.5000  LR: 0.00001689  \n","Epoch: [2][120/220] Elapsed 14m 18s (remain 11m 42s) Loss: 0.0979(0.1087) Grad: 200171.7812  LR: 0.00001644  \n","Epoch: [2][140/220] Elapsed 16m 39s (remain 9m 20s) Loss: 0.0891(0.1083) Grad: 471510.9062  LR: 0.00001597  \n","Epoch: [2][160/220] Elapsed 19m 17s (remain 7m 4s) Loss: 0.1225(0.1080) Grad: 340426.9375  LR: 0.00001548  \n","Epoch: [2][180/220] Elapsed 21m 48s (remain 4m 41s) Loss: 0.1530(0.1089) Grad: 947559.9375  LR: 0.00001497  \n","Epoch: [2][200/220] Elapsed 24m 14s (remain 2m 17s) Loss: 0.1479(0.1095) Grad: 336376.9375  LR: 0.00001445  \n","Epoch: [2][219/220] Elapsed 26m 25s (remain 0m 0s) Loss: 0.0801(0.1092) Grad: 162109.0938  LR: 0.00001393  \n","EVAL: [0/25] Elapsed 0m 2s (remain 1m 0s) Loss: 0.1391(0.1391) \n","EVAL: [20/25] Elapsed 0m 42s (remain 0m 8s) Loss: 0.0873(0.1133) \n","EVAL: [24/25] Elapsed 0m 50s (remain 0m 0s) Loss: 0.1072(0.1139) \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 2 - avg_train_loss: 0.1092  avg_val_loss: 0.1139  time: 1637s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.1092  avg_val_loss: 0.1139  time: 1637s\n","Epoch 2 - Score: 0.4789  Scores: [0.5223147276399202, 0.4939914631489525, 0.4355436398120247, 0.47121782150777175, 0.4903447801331019, 0.46021890239024565]\n","INFO:__main__:Epoch 2 - Score: 0.4789  Scores: [0.5223147276399202, 0.4939914631489525, 0.4355436398120247, 0.47121782150777175, 0.4903447801331019, 0.46021890239024565]\n","Epoch 2 - Save Best Score: 0.4789 Model\n","INFO:__main__:Epoch 2 - Save Best Score: 0.4789 Model\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: [3][0/220] Elapsed 0m 7s (remain 29m 9s) Loss: 0.1197(0.1197) Grad: 227725.2812  LR: 0.00001390  \n","Epoch: [3][20/220] Elapsed 2m 35s (remain 24m 37s) Loss: 0.1135(0.0964) Grad: 246856.4688  LR: 0.00001335  \n","Epoch: [3][40/220] Elapsed 5m 8s (remain 22m 25s) Loss: 0.0950(0.0967) Grad: 169284.4688  LR: 0.00001278  \n","Epoch: [3][60/220] Elapsed 7m 46s (remain 20m 15s) Loss: 0.0924(0.0985) Grad: 229431.3750  LR: 0.00001220  \n","Epoch: [3][80/220] Elapsed 10m 12s (remain 17m 31s) Loss: 0.0912(0.0989) Grad: 434852.6250  LR: 0.00001161  \n","Epoch: [3][100/220] Elapsed 12m 40s (remain 14m 55s) Loss: 0.0859(0.0995) Grad: 528583.4375  LR: 0.00001102  \n","Epoch: [3][120/220] Elapsed 15m 5s (remain 12m 21s) Loss: 0.0945(0.0997) Grad: 457973.0938  LR: 0.00001042  \n","Epoch: [3][140/220] Elapsed 17m 14s (remain 9m 39s) Loss: 0.0843(0.1002) Grad: 144539.6406  LR: 0.00000982  \n","Epoch: [3][160/220] Elapsed 19m 31s (remain 7m 9s) Loss: 0.0940(0.1004) Grad: 234171.1406  LR: 0.00000922  \n","Epoch: [3][180/220] Elapsed 21m 46s (remain 4m 41s) Loss: 0.1068(0.1000) Grad: 304559.0625  LR: 0.00000863  \n","Epoch: [3][200/220] Elapsed 24m 6s (remain 2m 16s) Loss: 0.0836(0.1002) Grad: 351788.5625  LR: 0.00000804  \n","Epoch: [3][219/220] Elapsed 26m 12s (remain 0m 0s) Loss: 0.0779(0.1000) Grad: 372101.0938  LR: 0.00000748  \n","EVAL: [0/25] Elapsed 0m 2s (remain 1m 0s) Loss: 0.1372(0.1372) \n","EVAL: [20/25] Elapsed 0m 43s (remain 0m 8s) Loss: 0.0886(0.1125) \n","EVAL: [24/25] Elapsed 0m 51s (remain 0m 0s) Loss: 0.1208(0.1133) \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 3 - avg_train_loss: 0.1000  avg_val_loss: 0.1133  time: 1625s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.1000  avg_val_loss: 0.1133  time: 1625s\n","Epoch 3 - Score: 0.4786  Scores: [0.5002382525353187, 0.4651686173978121, 0.4785185162097883, 0.4663444640709761, 0.5004386571617918, 0.460880159268766]\n","INFO:__main__:Epoch 3 - Score: 0.4786  Scores: [0.5002382525353187, 0.4651686173978121, 0.4785185162097883, 0.4663444640709761, 0.5004386571617918, 0.460880159268766]\n","Epoch 3 - Save Best Score: 0.4786 Model\n","INFO:__main__:Epoch 3 - Save Best Score: 0.4786 Model\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: [4][0/220] Elapsed 0m 4s (remain 15m 11s) Loss: 0.0869(0.0869) Grad: 241647.0781  LR: 0.00000746  \n","Epoch: [4][20/220] Elapsed 2m 26s (remain 23m 11s) Loss: 0.1060(0.0941) Grad: 232800.1250  LR: 0.00000688  \n","Epoch: [4][40/220] Elapsed 4m 50s (remain 21m 8s) Loss: 0.0900(0.0930) Grad: 160302.2188  LR: 0.00000632  \n","Epoch: [4][60/220] Elapsed 6m 57s (remain 18m 7s) Loss: 0.0922(0.0931) Grad: 382751.9375  LR: 0.00000577  \n","Epoch: [4][80/220] Elapsed 9m 33s (remain 16m 24s) Loss: 0.1264(0.0930) Grad: 554057.8750  LR: 0.00000523  \n","Epoch: [4][100/220] Elapsed 12m 3s (remain 14m 12s) Loss: 0.0863(0.0936) Grad: 235074.4375  LR: 0.00000472  \n","Epoch: [4][120/220] Elapsed 14m 31s (remain 11m 52s) Loss: 0.0932(0.0938) Grad: 279131.8125  LR: 0.00000422  \n","Epoch: [4][140/220] Elapsed 16m 55s (remain 9m 29s) Loss: 0.1275(0.0956) Grad: 310446.5312  LR: 0.00000374  \n","Epoch: [4][160/220] Elapsed 19m 27s (remain 7m 7s) Loss: 0.0990(0.0953) Grad: 173112.7812  LR: 0.00000329  \n","Epoch: [4][180/220] Elapsed 21m 47s (remain 4m 41s) Loss: 0.1395(0.0956) Grad: 646797.8750  LR: 0.00000286  \n","Epoch: [4][200/220] Elapsed 24m 18s (remain 2m 17s) Loss: 0.0772(0.0957) Grad: 156543.2344  LR: 0.00000245  \n","Epoch: [4][219/220] Elapsed 26m 34s (remain 0m 0s) Loss: 0.0793(0.0955) Grad: 309622.4375  LR: 0.00000209  \n","EVAL: [0/25] Elapsed 0m 2s (remain 1m 0s) Loss: 0.1313(0.1313) \n","EVAL: [20/25] Elapsed 0m 43s (remain 0m 8s) Loss: 0.0829(0.1045) \n","EVAL: [24/25] Elapsed 0m 51s (remain 0m 0s) Loss: 0.1122(0.1054) \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 4 - avg_train_loss: 0.0955  avg_val_loss: 0.1054  time: 1646s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.0955  avg_val_loss: 0.1054  time: 1646s\n","Epoch 4 - Score: 0.4608  Scores: [0.493076607490837, 0.4488421338209009, 0.43303683142549615, 0.451011321812114, 0.4844491946496761, 0.45433933157868556]\n","INFO:__main__:Epoch 4 - Score: 0.4608  Scores: [0.493076607490837, 0.4488421338209009, 0.43303683142549615, 0.451011321812114, 0.4844491946496761, 0.45433933157868556]\n","Epoch 4 - Save Best Score: 0.4608 Model\n","INFO:__main__:Epoch 4 - Save Best Score: 0.4608 Model\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: [5][0/220] Elapsed 0m 8s (remain 29m 17s) Loss: 0.0900(0.0900) Grad: 427775.3438  LR: 0.00000207  \n","Epoch: [5][20/220] Elapsed 2m 40s (remain 25m 16s) Loss: 0.0868(0.0926) Grad: 330432.1250  LR: 0.00000172  \n","Epoch: [5][40/220] Elapsed 5m 15s (remain 22m 55s) Loss: 0.0689(0.0884) Grad: 177621.3438  LR: 0.00000140  \n","Epoch: [5][60/220] Elapsed 7m 43s (remain 20m 8s) Loss: 0.0922(0.0905) Grad: 253683.7969  LR: 0.00000111  \n","Epoch: [5][80/220] Elapsed 10m 12s (remain 17m 31s) Loss: 0.0845(0.0908) Grad: 184596.1250  LR: 0.00000085  \n","Epoch: [5][100/220] Elapsed 12m 34s (remain 14m 48s) Loss: 0.0788(0.0927) Grad: 164626.5000  LR: 0.00000063  \n","Epoch: [5][120/220] Elapsed 14m 51s (remain 12m 9s) Loss: 0.1273(0.0927) Grad: 201237.4688  LR: 0.00000044  \n","Epoch: [5][140/220] Elapsed 17m 14s (remain 9m 39s) Loss: 0.0636(0.0926) Grad: 149674.0625  LR: 0.00000028  \n","Epoch: [5][160/220] Elapsed 19m 21s (remain 7m 5s) Loss: 0.0951(0.0925) Grad: 216052.3125  LR: 0.00000016  \n","Epoch: [5][180/220] Elapsed 21m 50s (remain 4m 42s) Loss: 0.0968(0.0928) Grad: 193301.7031  LR: 0.00000007  \n","Epoch: [5][200/220] Elapsed 24m 5s (remain 2m 16s) Loss: 0.0917(0.0922) Grad: 222861.2500  LR: 0.00000002  \n","Epoch: [5][219/220] Elapsed 26m 13s (remain 0m 0s) Loss: 0.0967(0.0926) Grad: 311566.5938  LR: 0.00000000  \n","EVAL: [0/25] Elapsed 0m 2s (remain 1m 1s) Loss: 0.1293(0.1293) \n","EVAL: [20/25] Elapsed 0m 43s (remain 0m 8s) Loss: 0.0827(0.1031) \n","EVAL: [24/25] Elapsed 0m 51s (remain 0m 0s) Loss: 0.1118(0.1042) \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 5 - avg_train_loss: 0.0926  avg_val_loss: 0.1042  time: 1625s\n","INFO:__main__:Epoch 5 - avg_train_loss: 0.0926  avg_val_loss: 0.1042  time: 1625s\n","Epoch 5 - Score: 0.4578  Scores: [0.49010613546386383, 0.44760372227505996, 0.4252520012849762, 0.4488296208160833, 0.4831494791770671, 0.45201538252144197]\n","INFO:__main__:Epoch 5 - Score: 0.4578  Scores: [0.49010613546386383, 0.44760372227505996, 0.4252520012849762, 0.4488296208160833, 0.4831494791770671, 0.45201538252144197]\n","Epoch 5 - Save Best Score: 0.4578 Model\n","INFO:__main__:Epoch 5 - Save Best Score: 0.4578 Model\n","========== fold: 4 result ==========\n","INFO:__main__:========== fold: 4 result ==========\n","Score: 0.4578  Scores: [0.49010613546386383, 0.44760372227505996, 0.4252520012849762, 0.4488296208160833, 0.4831494791770671, 0.45201538252144197]\n","INFO:__main__:Score: 0.4578  Scores: [0.49010613546386383, 0.44760372227505996, 0.4252520012849762, 0.4488296208160833, 0.4831494791770671, 0.45201538252144197]\n","========== fold: 5 training ==========\n","INFO:__main__:========== fold: 5 training ==========\n","DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 1024,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.23.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","INFO:__main__:DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 1024,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.23.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['mask_predictions.LayerNorm.weight', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.bias', 'mask_predictions.LayerNorm.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: [1][0/220] Elapsed 0m 4s (remain 15m 26s) Loss: 2.4037(2.4037) Grad: 724939.1250  LR: 0.00000040  \n","Epoch: [1][20/220] Elapsed 1m 23s (remain 13m 15s) Loss: 1.8985(2.2893) Grad: 712637.6875  LR: 0.00000840  \n","Epoch: [1][40/220] Elapsed 2m 41s (remain 11m 45s) Loss: 0.7945(1.8517) Grad: 619717.2500  LR: 0.00001640  \n","Epoch: [1][60/220] Elapsed 3m 59s (remain 10m 23s) Loss: 0.1170(1.3158) Grad: 218859.1406  LR: 0.00001999  \n","Epoch: [1][80/220] Elapsed 5m 15s (remain 9m 1s) Loss: 0.1360(1.0261) Grad: 142286.1094  LR: 0.00001996  \n","Epoch: [1][100/220] Elapsed 6m 34s (remain 7m 45s) Loss: 0.0744(0.8477) Grad: 121917.6562  LR: 0.00001988  \n","Epoch: [1][120/220] Elapsed 7m 49s (remain 6m 24s) Loss: 0.2612(0.7306) Grad: 578143.6250  LR: 0.00001978  \n","Epoch: [1][140/220] Elapsed 9m 4s (remain 5m 5s) Loss: 0.1214(0.6448) Grad: 309900.2188  LR: 0.00001963  \n","Epoch: [1][160/220] Elapsed 10m 17s (remain 3m 46s) Loss: 0.0955(0.5818) Grad: 137375.6406  LR: 0.00001945  \n","Epoch: [1][180/220] Elapsed 11m 29s (remain 2m 28s) Loss: 0.1000(0.5300) Grad: 137124.2969  LR: 0.00001924  \n","Epoch: [1][200/220] Elapsed 12m 46s (remain 1m 12s) Loss: 0.1179(0.4890) Grad: 251994.0156  LR: 0.00001900  \n","Epoch: [1][219/220] Elapsed 13m 50s (remain 0m 0s) Loss: 0.1137(0.4561) Grad: 106474.0078  LR: 0.00001873  \n","EVAL: [0/25] Elapsed 0m 1s (remain 0m 44s) Loss: 0.1096(0.1096) \n","EVAL: [20/25] Elapsed 0m 41s (remain 0m 7s) Loss: 0.1108(0.1046) \n","EVAL: [24/25] Elapsed 0m 48s (remain 0m 0s) Loss: 0.1101(0.1070) \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 1 - avg_train_loss: 0.4561  avg_val_loss: 0.1070  time: 879s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.4561  avg_val_loss: 0.1070  time: 879s\n","Epoch 1 - Score: 0.4624  Scores: [0.4988369099022051, 0.45051364776351005, 0.3925576341206901, 0.47143622984219535, 0.46047110592889856, 0.5002922982686846]\n","INFO:__main__:Epoch 1 - Score: 0.4624  Scores: [0.4988369099022051, 0.45051364776351005, 0.3925576341206901, 0.47143622984219535, 0.46047110592889856, 0.5002922982686846]\n","Epoch 1 - Save Best Score: 0.4624 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.4624 Model\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: [2][0/220] Elapsed 0m 8s (remain 29m 14s) Loss: 0.1048(0.1048) Grad: 336998.9062  LR: 0.00001872  \n","Epoch: [2][20/220] Elapsed 2m 22s (remain 22m 27s) Loss: 0.0961(0.1083) Grad: 193814.9062  LR: 0.00001841  \n","Epoch: [2][40/220] Elapsed 4m 45s (remain 20m 47s) Loss: 0.1163(0.1085) Grad: 409958.4375  LR: 0.00001807  \n","Epoch: [2][60/220] Elapsed 7m 11s (remain 18m 45s) Loss: 0.1069(0.1121) Grad: 202951.0312  LR: 0.00001771  \n","Epoch: [2][80/220] Elapsed 9m 18s (remain 15m 59s) Loss: 0.1032(0.1109) Grad: 289341.9062  LR: 0.00001731  \n","Epoch: [2][100/220] Elapsed 12m 2s (remain 14m 10s) Loss: 0.1268(0.1105) Grad: 424667.0000  LR: 0.00001689  \n","Epoch: [2][120/220] Elapsed 14m 30s (remain 11m 52s) Loss: 0.1052(0.1103) Grad: 442870.5938  LR: 0.00001644  \n","Epoch: [2][140/220] Elapsed 16m 58s (remain 9m 30s) Loss: 0.1343(0.1112) Grad: 547950.8750  LR: 0.00001597  \n","Epoch: [2][160/220] Elapsed 19m 29s (remain 7m 8s) Loss: 0.0865(0.1104) Grad: 178694.4688  LR: 0.00001548  \n","Epoch: [2][180/220] Elapsed 21m 58s (remain 4m 44s) Loss: 0.0902(0.1105) Grad: 243714.1250  LR: 0.00001497  \n","Epoch: [2][200/220] Elapsed 24m 28s (remain 2m 18s) Loss: 0.1161(0.1104) Grad: 251272.8750  LR: 0.00001445  \n","Epoch: [2][219/220] Elapsed 26m 47s (remain 0m 0s) Loss: 0.1018(0.1096) Grad: 488852.8438  LR: 0.00001393  \n","EVAL: [0/25] Elapsed 0m 1s (remain 0m 44s) Loss: 0.1056(0.1056) \n","EVAL: [20/25] Elapsed 0m 41s (remain 0m 7s) Loss: 0.1134(0.0987) \n","EVAL: [24/25] Elapsed 0m 48s (remain 0m 0s) Loss: 0.0952(0.1012) \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 2 - avg_train_loss: 0.1096  avg_val_loss: 0.1012  time: 1657s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.1096  avg_val_loss: 0.1012  time: 1657s\n","Epoch 2 - Score: 0.4500  Scores: [0.48117801738027177, 0.4479833042036545, 0.3986754352425062, 0.4577786032964771, 0.4582413741741138, 0.45612161875258517]\n","INFO:__main__:Epoch 2 - Score: 0.4500  Scores: [0.48117801738027177, 0.4479833042036545, 0.3986754352425062, 0.4577786032964771, 0.4582413741741138, 0.45612161875258517]\n","Epoch 2 - Save Best Score: 0.4500 Model\n","INFO:__main__:Epoch 2 - Save Best Score: 0.4500 Model\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: [3][0/220] Elapsed 0m 10s (remain 37m 39s) Loss: 0.0969(0.0969) Grad: 274238.3438  LR: 0.00001390  \n","Epoch: [3][20/220] Elapsed 2m 35s (remain 24m 33s) Loss: 0.1279(0.0974) Grad: 449902.0312  LR: 0.00001335  \n","Epoch: [3][40/220] Elapsed 4m 57s (remain 21m 39s) Loss: 0.1204(0.1002) Grad: 207223.8594  LR: 0.00001278  \n","Epoch: [3][60/220] Elapsed 7m 21s (remain 19m 10s) Loss: 0.1042(0.1026) Grad: 441478.3750  LR: 0.00001220  \n","Epoch: [3][80/220] Elapsed 9m 51s (remain 16m 54s) Loss: 0.0849(0.1034) Grad: 373022.0938  LR: 0.00001161  \n","Epoch: [3][100/220] Elapsed 12m 20s (remain 14m 32s) Loss: 0.1502(0.1054) Grad: 513851.8750  LR: 0.00001102  \n","Epoch: [3][120/220] Elapsed 14m 53s (remain 12m 10s) Loss: 0.0967(0.1057) Grad: 602106.1875  LR: 0.00001042  \n","Epoch: [3][140/220] Elapsed 17m 26s (remain 9m 46s) Loss: 0.1416(0.1055) Grad: 278071.7812  LR: 0.00000982  \n","Epoch: [3][160/220] Elapsed 19m 54s (remain 7m 17s) Loss: 0.1136(0.1043) Grad: 203213.2344  LR: 0.00000922  \n","Epoch: [3][180/220] Elapsed 22m 33s (remain 4m 51s) Loss: 0.0861(0.1042) Grad: 382589.7188  LR: 0.00000863  \n","Epoch: [3][200/220] Elapsed 24m 37s (remain 2m 19s) Loss: 0.1001(0.1038) Grad: 199263.9844  LR: 0.00000804  \n","Epoch: [3][219/220] Elapsed 26m 51s (remain 0m 0s) Loss: 0.1061(0.1031) Grad: 273779.2500  LR: 0.00000748  \n","EVAL: [0/25] Elapsed 0m 1s (remain 0m 44s) Loss: 0.0964(0.0964) \n","EVAL: [20/25] Elapsed 0m 41s (remain 0m 7s) Loss: 0.1063(0.0954) \n","EVAL: [24/25] Elapsed 0m 48s (remain 0m 0s) Loss: 0.0982(0.0990) \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 3 - avg_train_loss: 0.1031  avg_val_loss: 0.0990  time: 1661s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.1031  avg_val_loss: 0.0990  time: 1661s\n","Epoch 3 - Score: 0.4449  Scores: [0.4824632837935781, 0.4469656920367056, 0.3834899257651294, 0.4589438812016062, 0.44640527896725635, 0.4511904456518813]\n","INFO:__main__:Epoch 3 - Score: 0.4449  Scores: [0.4824632837935781, 0.4469656920367056, 0.3834899257651294, 0.4589438812016062, 0.44640527896725635, 0.4511904456518813]\n","Epoch 3 - Save Best Score: 0.4449 Model\n","INFO:__main__:Epoch 3 - Save Best Score: 0.4449 Model\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: [4][0/220] Elapsed 0m 4s (remain 17m 41s) Loss: 0.1265(0.1265) Grad: 282534.7188  LR: 0.00000746  \n","Epoch: [4][20/220] Elapsed 2m 18s (remain 21m 50s) Loss: 0.0953(0.0976) Grad: 330046.1875  LR: 0.00000688  \n","Epoch: [4][40/220] Elapsed 4m 31s (remain 19m 44s) Loss: 0.0693(0.0960) Grad: 169058.6094  LR: 0.00000632  \n","Epoch: [4][60/220] Elapsed 6m 56s (remain 18m 4s) Loss: 0.1065(0.0967) Grad: 162880.6250  LR: 0.00000577  \n","Epoch: [4][80/220] Elapsed 9m 31s (remain 16m 20s) Loss: 0.0920(0.0969) Grad: 317326.2812  LR: 0.00000523  \n","Epoch: [4][100/220] Elapsed 11m 55s (remain 14m 2s) Loss: 0.1011(0.0973) Grad: 284702.5000  LR: 0.00000472  \n","Epoch: [4][120/220] Elapsed 14m 4s (remain 11m 30s) Loss: 0.0949(0.0970) Grad: 162177.1562  LR: 0.00000422  \n","Epoch: [4][140/220] Elapsed 16m 35s (remain 9m 17s) Loss: 0.1310(0.0972) Grad: 247167.3594  LR: 0.00000374  \n","Epoch: [4][160/220] Elapsed 19m 7s (remain 7m 0s) Loss: 0.0601(0.0969) Grad: 250016.6562  LR: 0.00000329  \n","Epoch: [4][180/220] Elapsed 21m 34s (remain 4m 38s) Loss: 0.0790(0.0967) Grad: 168572.1406  LR: 0.00000286  \n","Epoch: [4][200/220] Elapsed 23m 59s (remain 2m 16s) Loss: 0.0907(0.0967) Grad: 277391.4062  LR: 0.00000245  \n","Epoch: [4][219/220] Elapsed 26m 26s (remain 0m 0s) Loss: 0.1105(0.0968) Grad: 188678.8125  LR: 0.00000209  \n","EVAL: [0/25] Elapsed 0m 1s (remain 0m 44s) Loss: 0.0911(0.0911) \n","EVAL: [20/25] Elapsed 0m 41s (remain 0m 7s) Loss: 0.1017(0.0961) \n","EVAL: [24/25] Elapsed 0m 48s (remain 0m 0s) Loss: 0.1145(0.1011) \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 4 - avg_train_loss: 0.0968  avg_val_loss: 0.1011  time: 1636s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.0968  avg_val_loss: 0.1011  time: 1636s\n","Epoch 4 - Score: 0.4500  Scores: [0.48299126476069676, 0.46073832202454407, 0.3947899594398969, 0.4618230424195575, 0.457260897670484, 0.4426126479253879]\n","INFO:__main__:Epoch 4 - Score: 0.4500  Scores: [0.48299126476069676, 0.46073832202454407, 0.3947899594398969, 0.4618230424195575, 0.457260897670484, 0.4426126479253879]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: [5][0/220] Elapsed 0m 6s (remain 25m 13s) Loss: 0.0993(0.0993) Grad: 185577.4219  LR: 0.00000207  \n","Epoch: [5][20/220] Elapsed 2m 40s (remain 25m 18s) Loss: 0.1058(0.0960) Grad: 171969.9531  LR: 0.00000172  \n","Epoch: [5][40/220] Elapsed 5m 0s (remain 21m 53s) Loss: 0.1197(0.0970) Grad: 214975.9062  LR: 0.00000140  \n","Epoch: [5][60/220] Elapsed 7m 29s (remain 19m 30s) Loss: 0.0749(0.0951) Grad: 213368.3750  LR: 0.00000111  \n","Epoch: [5][80/220] Elapsed 9m 47s (remain 16m 48s) Loss: 0.0769(0.0930) Grad: 243031.9531  LR: 0.00000085  \n","Epoch: [5][100/220] Elapsed 12m 10s (remain 14m 20s) Loss: 0.1157(0.0927) Grad: 565419.2500  LR: 0.00000063  \n","Epoch: [5][120/220] Elapsed 14m 43s (remain 12m 2s) Loss: 0.0840(0.0929) Grad: 278309.8438  LR: 0.00000044  \n","Epoch: [5][140/220] Elapsed 17m 12s (remain 9m 38s) Loss: 0.1370(0.0933) Grad: 229206.4531  LR: 0.00000028  \n","Epoch: [5][160/220] Elapsed 19m 45s (remain 7m 14s) Loss: 0.1157(0.0932) Grad: 219904.9375  LR: 0.00000016  \n","Epoch: [5][180/220] Elapsed 22m 20s (remain 4m 48s) Loss: 0.0832(0.0928) Grad: 195132.9219  LR: 0.00000007  \n","Epoch: [5][200/220] Elapsed 24m 42s (remain 2m 20s) Loss: 0.1212(0.0928) Grad: 527999.5625  LR: 0.00000002  \n","Epoch: [5][219/220] Elapsed 27m 1s (remain 0m 0s) Loss: 0.0834(0.0924) Grad: 236313.6250  LR: 0.00000000  \n","EVAL: [0/25] Elapsed 0m 1s (remain 0m 45s) Loss: 0.0940(0.0940) \n","EVAL: [20/25] Elapsed 0m 41s (remain 0m 7s) Loss: 0.1018(0.0938) \n","EVAL: [24/25] Elapsed 0m 48s (remain 0m 0s) Loss: 0.1055(0.0985) \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 5 - avg_train_loss: 0.0924  avg_val_loss: 0.0985  time: 1670s\n","INFO:__main__:Epoch 5 - avg_train_loss: 0.0924  avg_val_loss: 0.0985  time: 1670s\n","Epoch 5 - Score: 0.4439  Scores: [0.480505143091209, 0.4454076872342181, 0.3889686614424755, 0.45921584946366684, 0.4475034751513537, 0.4415991083673478]\n","INFO:__main__:Epoch 5 - Score: 0.4439  Scores: [0.480505143091209, 0.4454076872342181, 0.3889686614424755, 0.45921584946366684, 0.4475034751513537, 0.4415991083673478]\n","Epoch 5 - Save Best Score: 0.4439 Model\n","INFO:__main__:Epoch 5 - Save Best Score: 0.4439 Model\n","========== fold: 5 result ==========\n","INFO:__main__:========== fold: 5 result ==========\n","Score: 0.4439  Scores: [0.480505143091209, 0.4454076872342181, 0.3889686614424755, 0.45921584946366684, 0.4475034751513537, 0.4415991083673478]\n","INFO:__main__:Score: 0.4439  Scores: [0.480505143091209, 0.4454076872342181, 0.3889686614424755, 0.45921584946366684, 0.4475034751513537, 0.4415991083673478]\n","========== fold: 6 training ==========\n","INFO:__main__:========== fold: 6 training ==========\n","DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 1024,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.23.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","INFO:__main__:DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 1024,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.23.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['mask_predictions.LayerNorm.weight', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.bias', 'mask_predictions.LayerNorm.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: [1][0/220] Elapsed 0m 3s (remain 13m 59s) Loss: 2.7268(2.7268) Grad: 718594.8125  LR: 0.00000040  \n","Epoch: [1][20/220] Elapsed 1m 20s (remain 12m 39s) Loss: 1.9954(2.4708) Grad: 707551.1875  LR: 0.00000840  \n","Epoch: [1][40/220] Elapsed 2m 34s (remain 11m 13s) Loss: 0.8868(2.0447) Grad: 709820.4375  LR: 0.00001640  \n","Epoch: [1][60/220] Elapsed 3m 49s (remain 9m 57s) Loss: 0.1631(1.4794) Grad: 478576.6250  LR: 0.00001999  \n","Epoch: [1][80/220] Elapsed 4m 53s (remain 8m 24s) Loss: 0.0956(1.1485) Grad: 233739.1094  LR: 0.00001996  \n","Epoch: [1][100/220] Elapsed 6m 9s (remain 7m 15s) Loss: 0.1395(0.9469) Grad: 287729.7188  LR: 0.00001988  \n","Epoch: [1][120/220] Elapsed 7m 20s (remain 6m 0s) Loss: 0.1052(0.8100) Grad: 210965.8438  LR: 0.00001978  \n","Epoch: [1][140/220] Elapsed 8m 32s (remain 4m 47s) Loss: 0.1418(0.7142) Grad: 400226.6250  LR: 0.00001963  \n","Epoch: [1][160/220] Elapsed 9m 53s (remain 3m 37s) Loss: 0.1445(0.6399) Grad: 189396.0312  LR: 0.00001945  \n","Epoch: [1][180/220] Elapsed 11m 9s (remain 2m 24s) Loss: 0.1384(0.5825) Grad: 232419.0781  LR: 0.00001924  \n","Epoch: [1][200/220] Elapsed 12m 21s (remain 1m 10s) Loss: 0.0980(0.5364) Grad: 238583.2812  LR: 0.00001900  \n","Epoch: [1][219/220] Elapsed 13m 34s (remain 0m 0s) Loss: 0.1692(0.4997) Grad: 474922.4062  LR: 0.00001873  \n","EVAL: [0/25] Elapsed 0m 2s (remain 1m 0s) Loss: 0.1046(0.1046) \n","EVAL: [20/25] Elapsed 0m 39s (remain 0m 7s) Loss: 0.1297(0.1182) \n","EVAL: [24/25] Elapsed 0m 47s (remain 0m 0s) Loss: 0.0540(0.1172) \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 1 - avg_train_loss: 0.4997  avg_val_loss: 0.1172  time: 862s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.4997  avg_val_loss: 0.1172  time: 862s\n","Epoch 1 - Score: 0.4859  Scores: [0.522931263808408, 0.4717986778761046, 0.45467577195332776, 0.5071938968627154, 0.46889421309477275, 0.4901523360126974]\n","INFO:__main__:Epoch 1 - Score: 0.4859  Scores: [0.522931263808408, 0.4717986778761046, 0.45467577195332776, 0.5071938968627154, 0.46889421309477275, 0.4901523360126974]\n","Epoch 1 - Save Best Score: 0.4859 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.4859 Model\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: [2][0/220] Elapsed 0m 6s (remain 24m 52s) Loss: 0.1031(0.1031) Grad: 651577.1250  LR: 0.00001872  \n","Epoch: [2][20/220] Elapsed 2m 21s (remain 22m 17s) Loss: 0.1693(0.1249) Grad: 467394.3125  LR: 0.00001841  \n","Epoch: [2][40/220] Elapsed 4m 42s (remain 20m 32s) Loss: 0.0846(0.1148) Grad: 107302.5547  LR: 0.00001807  \n","Epoch: [2][60/220] Elapsed 7m 13s (remain 18m 50s) Loss: 0.1503(0.1131) Grad: 259877.3281  LR: 0.00001771  \n","Epoch: [2][80/220] Elapsed 9m 45s (remain 16m 45s) Loss: 0.1568(0.1149) Grad: 275304.2188  LR: 0.00001731  \n","Epoch: [2][100/220] Elapsed 12m 10s (remain 14m 20s) Loss: 0.1283(0.1147) Grad: 191556.3125  LR: 0.00001689  \n","Epoch: [2][120/220] Elapsed 14m 18s (remain 11m 42s) Loss: 0.1009(0.1144) Grad: 381584.7812  LR: 0.00001644  \n","Epoch: [2][140/220] Elapsed 16m 45s (remain 9m 23s) Loss: 0.0968(0.1135) Grad: 119946.6484  LR: 0.00001597  \n","Epoch: [2][160/220] Elapsed 19m 18s (remain 7m 4s) Loss: 0.1102(0.1126) Grad: 107008.6328  LR: 0.00001548  \n","Epoch: [2][180/220] Elapsed 21m 39s (remain 4m 40s) Loss: 0.1105(0.1117) Grad: 268890.6562  LR: 0.00001497  \n","Epoch: [2][200/220] Elapsed 23m 51s (remain 2m 15s) Loss: 0.1107(0.1111) Grad: 148409.6094  LR: 0.00001445  \n","Epoch: [2][219/220] Elapsed 26m 27s (remain 0m 0s) Loss: 0.1157(0.1115) Grad: 222253.3594  LR: 0.00001393  \n","EVAL: [0/25] Elapsed 0m 2s (remain 1m 0s) Loss: 0.1071(0.1071) \n","EVAL: [20/25] Elapsed 0m 39s (remain 0m 7s) Loss: 0.1559(0.1294) \n","EVAL: [24/25] Elapsed 0m 47s (remain 0m 0s) Loss: 0.0972(0.1297) \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 2 - avg_train_loss: 0.1115  avg_val_loss: 0.1297  time: 1636s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.1115  avg_val_loss: 0.1297  time: 1636s\n","Epoch 2 - Score: 0.5109  Scores: [0.49408010658987594, 0.5127993917429989, 0.5052280419710873, 0.4939642815644786, 0.4925805973792519, 0.5666474651106223]\n","INFO:__main__:Epoch 2 - Score: 0.5109  Scores: [0.49408010658987594, 0.5127993917429989, 0.5052280419710873, 0.4939642815644786, 0.4925805973792519, 0.5666474651106223]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: [3][0/220] Elapsed 0m 5s (remain 18m 21s) Loss: 0.1191(0.1191) Grad: 381357.8750  LR: 0.00001390  \n","Epoch: [3][20/220] Elapsed 2m 32s (remain 24m 7s) Loss: 0.0723(0.1046) Grad: 187102.6094  LR: 0.00001335  \n","Epoch: [3][40/220] Elapsed 5m 5s (remain 22m 15s) Loss: 0.0793(0.1013) Grad: 145949.5781  LR: 0.00001278  \n","Epoch: [3][60/220] Elapsed 7m 32s (remain 19m 39s) Loss: 0.1052(0.0997) Grad: 227143.3906  LR: 0.00001220  \n","Epoch: [3][80/220] Elapsed 10m 6s (remain 17m 20s) Loss: 0.1019(0.0993) Grad: 190483.7969  LR: 0.00001161  \n","Epoch: [3][100/220] Elapsed 12m 36s (remain 14m 51s) Loss: 0.1008(0.0982) Grad: 288242.5312  LR: 0.00001102  \n","Epoch: [3][120/220] Elapsed 15m 6s (remain 12m 21s) Loss: 0.0851(0.0987) Grad: 414723.6250  LR: 0.00001042  \n","Epoch: [3][140/220] Elapsed 17m 35s (remain 9m 51s) Loss: 0.1306(0.0991) Grad: 686426.8750  LR: 0.00000982  \n","Epoch: [3][160/220] Elapsed 19m 58s (remain 7m 19s) Loss: 0.1174(0.0984) Grad: 307964.9062  LR: 0.00000922  \n","Epoch: [3][180/220] Elapsed 22m 18s (remain 4m 48s) Loss: 0.1110(0.0984) Grad: 386092.5938  LR: 0.00000863  \n","Epoch: [3][200/220] Elapsed 24m 53s (remain 2m 21s) Loss: 0.0990(0.0989) Grad: 486496.5312  LR: 0.00000804  \n","Epoch: [3][219/220] Elapsed 27m 13s (remain 0m 0s) Loss: 0.1063(0.0990) Grad: 311975.0938  LR: 0.00000748  \n","EVAL: [0/25] Elapsed 0m 2s (remain 1m 0s) Loss: 0.0957(0.0957) \n","EVAL: [20/25] Elapsed 0m 39s (remain 0m 7s) Loss: 0.1305(0.1095) \n","EVAL: [24/25] Elapsed 0m 47s (remain 0m 0s) Loss: 0.0697(0.1096) \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 3 - avg_train_loss: 0.0990  avg_val_loss: 0.1096  time: 1682s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.0990  avg_val_loss: 0.1096  time: 1682s\n","Epoch 3 - Score: 0.4696  Scores: [0.489742809358958, 0.4700823763265707, 0.44318863894328797, 0.47325244691737384, 0.4746358299365764, 0.4664441370902844]\n","INFO:__main__:Epoch 3 - Score: 0.4696  Scores: [0.489742809358958, 0.4700823763265707, 0.44318863894328797, 0.47325244691737384, 0.4746358299365764, 0.4664441370902844]\n","Epoch 3 - Save Best Score: 0.4696 Model\n","INFO:__main__:Epoch 3 - Save Best Score: 0.4696 Model\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: [4][0/220] Elapsed 0m 8s (remain 29m 12s) Loss: 0.1078(0.1078) Grad: 224292.5469  LR: 0.00000746  \n","Epoch: [4][20/220] Elapsed 2m 27s (remain 23m 16s) Loss: 0.1223(0.0968) Grad: 336999.3750  LR: 0.00000688  \n","Epoch: [4][40/220] Elapsed 4m 51s (remain 21m 12s) Loss: 0.1090(0.0960) Grad: 205469.1094  LR: 0.00000632  \n","Epoch: [4][60/220] Elapsed 7m 15s (remain 18m 56s) Loss: 0.1238(0.0944) Grad: 470226.0000  LR: 0.00000577  \n","Epoch: [4][80/220] Elapsed 9m 32s (remain 16m 21s) Loss: 0.1068(0.0941) Grad: 155277.9844  LR: 0.00000523  \n","Epoch: [4][100/220] Elapsed 12m 5s (remain 14m 14s) Loss: 0.1029(0.0943) Grad: 165092.3438  LR: 0.00000472  \n","Epoch: [4][120/220] Elapsed 14m 38s (remain 11m 58s) Loss: 0.0838(0.0939) Grad: 235109.2188  LR: 0.00000422  \n","Epoch: [4][140/220] Elapsed 17m 1s (remain 9m 32s) Loss: 0.1193(0.0953) Grad: 423668.6562  LR: 0.00000374  \n","Epoch: [4][160/220] Elapsed 19m 28s (remain 7m 8s) Loss: 0.1163(0.0951) Grad: 270681.6562  LR: 0.00000329  \n","Epoch: [4][180/220] Elapsed 21m 41s (remain 4m 40s) Loss: 0.0677(0.0950) Grad: 163577.1250  LR: 0.00000286  \n","Epoch: [4][200/220] Elapsed 23m 55s (remain 2m 15s) Loss: 0.0990(0.0950) Grad: 336324.9688  LR: 0.00000245  \n","Epoch: [4][219/220] Elapsed 26m 12s (remain 0m 0s) Loss: 0.0854(0.0948) Grad: 304044.4688  LR: 0.00000209  \n","EVAL: [0/25] Elapsed 0m 2s (remain 1m 1s) Loss: 0.0998(0.0998) \n","EVAL: [20/25] Elapsed 0m 39s (remain 0m 7s) Loss: 0.1270(0.1077) \n","EVAL: [24/25] Elapsed 0m 47s (remain 0m 0s) Loss: 0.0650(0.1076) \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 4 - avg_train_loss: 0.0948  avg_val_loss: 0.1076  time: 1621s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.0948  avg_val_loss: 0.1076  time: 1621s\n","Epoch 4 - Score: 0.4652  Scores: [0.4900341530734862, 0.459254358112029, 0.441454854737155, 0.47192486905859465, 0.46698625894806767, 0.4615268566878983]\n","INFO:__main__:Epoch 4 - Score: 0.4652  Scores: [0.4900341530734862, 0.459254358112029, 0.441454854737155, 0.47192486905859465, 0.46698625894806767, 0.4615268566878983]\n","Epoch 4 - Save Best Score: 0.4652 Model\n","INFO:__main__:Epoch 4 - Save Best Score: 0.4652 Model\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: [5][0/220] Elapsed 0m 6s (remain 22m 11s) Loss: 0.0741(0.0741) Grad: 143815.9688  LR: 0.00000207  \n","Epoch: [5][20/220] Elapsed 2m 42s (remain 25m 39s) Loss: 0.0976(0.0880) Grad: 190528.0781  LR: 0.00000172  \n","Epoch: [5][40/220] Elapsed 5m 8s (remain 22m 26s) Loss: 0.1053(0.0903) Grad: 329112.5938  LR: 0.00000140  \n","Epoch: [5][60/220] Elapsed 7m 32s (remain 19m 40s) Loss: 0.1190(0.0904) Grad: 327868.4375  LR: 0.00000111  \n","Epoch: [5][80/220] Elapsed 10m 3s (remain 17m 15s) Loss: 0.0966(0.0904) Grad: 274711.7812  LR: 0.00000085  \n","Epoch: [5][100/220] Elapsed 12m 35s (remain 14m 49s) Loss: 0.0854(0.0906) Grad: 238994.7344  LR: 0.00000063  \n","Epoch: [5][120/220] Elapsed 15m 0s (remain 12m 17s) Loss: 0.0807(0.0916) Grad: 264866.7500  LR: 0.00000044  \n","Epoch: [5][140/220] Elapsed 17m 28s (remain 9m 47s) Loss: 0.1064(0.0909) Grad: 497601.0938  LR: 0.00000028  \n","Epoch: [5][160/220] Elapsed 20m 2s (remain 7m 20s) Loss: 0.1170(0.0919) Grad: 210970.0625  LR: 0.00000016  \n","Epoch: [5][180/220] Elapsed 22m 21s (remain 4m 49s) Loss: 0.0903(0.0921) Grad: 226359.5156  LR: 0.00000007  \n","Epoch: [5][200/220] Elapsed 24m 49s (remain 2m 20s) Loss: 0.0788(0.0918) Grad: 195456.0156  LR: 0.00000002  \n","Epoch: [5][219/220] Elapsed 26m 59s (remain 0m 0s) Loss: 0.1048(0.0919) Grad: 193905.7656  LR: 0.00000000  \n","EVAL: [0/25] Elapsed 0m 2s (remain 1m 0s) Loss: 0.0991(0.0991) \n","EVAL: [20/25] Elapsed 0m 39s (remain 0m 7s) Loss: 0.1266(0.1079) \n","EVAL: [24/25] Elapsed 0m 47s (remain 0m 0s) Loss: 0.0658(0.1079) \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 5 - avg_train_loss: 0.0919  avg_val_loss: 0.1079  time: 1668s\n","INFO:__main__:Epoch 5 - avg_train_loss: 0.0919  avg_val_loss: 0.1079  time: 1668s\n","Epoch 5 - Score: 0.4657  Scores: [0.48949699866878393, 0.460149489863108, 0.441073492248049, 0.4735801014074922, 0.46845407957797736, 0.461531262818778]\n","INFO:__main__:Epoch 5 - Score: 0.4657  Scores: [0.48949699866878393, 0.460149489863108, 0.441073492248049, 0.4735801014074922, 0.46845407957797736, 0.461531262818778]\n","========== fold: 6 result ==========\n","INFO:__main__:========== fold: 6 result ==========\n","Score: 0.4652  Scores: [0.4900341530734862, 0.459254358112029, 0.441454854737155, 0.47192486905859465, 0.46698625894806767, 0.4615268566878983]\n","INFO:__main__:Score: 0.4652  Scores: [0.4900341530734862, 0.459254358112029, 0.441454854737155, 0.47192486905859465, 0.46698625894806767, 0.4615268566878983]\n","========== fold: 7 training ==========\n","INFO:__main__:========== fold: 7 training ==========\n","DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 1024,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.23.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","INFO:__main__:DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 1024,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.23.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['mask_predictions.LayerNorm.weight', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.bias', 'mask_predictions.LayerNorm.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: [1][0/220] Elapsed 0m 4s (remain 15m 17s) Loss: 2.5586(2.5586) Grad: 688907.6250  LR: 0.00000040  \n","Epoch: [1][20/220] Elapsed 1m 19s (remain 12m 28s) Loss: 2.2388(2.6244) Grad: 681672.0625  LR: 0.00000840  \n","Epoch: [1][40/220] Elapsed 2m 33s (remain 11m 9s) Loss: 0.8575(2.1232) Grad: 721128.5625  LR: 0.00001640  \n","Epoch: [1][60/220] Elapsed 3m 49s (remain 9m 58s) Loss: 0.1605(1.5243) Grad: 217032.7500  LR: 0.00001999  \n","Epoch: [1][80/220] Elapsed 5m 9s (remain 8m 50s) Loss: 0.1055(1.1845) Grad: 152447.1562  LR: 0.00001996  \n","Epoch: [1][100/220] Elapsed 6m 28s (remain 7m 37s) Loss: 0.1440(0.9763) Grad: 272048.9688  LR: 0.00001988  \n","Epoch: [1][120/220] Elapsed 7m 45s (remain 6m 20s) Loss: 0.1146(0.8355) Grad: 146840.0156  LR: 0.00001978  \n","Epoch: [1][140/220] Elapsed 8m 53s (remain 4m 59s) Loss: 0.0929(0.7339) Grad: 191747.9688  LR: 0.00001963  \n","Epoch: [1][160/220] Elapsed 10m 15s (remain 3m 45s) Loss: 0.1195(0.6560) Grad: 132416.5469  LR: 0.00001945  \n","Epoch: [1][180/220] Elapsed 11m 31s (remain 2m 29s) Loss: 0.1857(0.5961) Grad: 404092.4062  LR: 0.00001924  \n","Epoch: [1][200/220] Elapsed 12m 49s (remain 1m 12s) Loss: 0.1052(0.5483) Grad: 118354.7500  LR: 0.00001900  \n","Epoch: [1][219/220] Elapsed 14m 2s (remain 0m 0s) Loss: 0.0684(0.5110) Grad: 167427.6406  LR: 0.00001873  \n","EVAL: [0/25] Elapsed 0m 1s (remain 0m 42s) Loss: 0.1264(0.1264) \n","EVAL: [20/25] Elapsed 0m 42s (remain 0m 8s) Loss: 0.1193(0.1110) \n","EVAL: [24/25] Elapsed 0m 47s (remain 0m 0s) Loss: 0.0656(0.1096) \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 1 - avg_train_loss: 0.5110  avg_val_loss: 0.1096  time: 890s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.5110  avg_val_loss: 0.1096  time: 890s\n","Epoch 1 - Score: 0.4699  Scores: [0.4891416176176761, 0.45060274283496377, 0.44127170758973616, 0.4652685433147161, 0.4841555882591909, 0.48915793973650146]\n","INFO:__main__:Epoch 1 - Score: 0.4699  Scores: [0.4891416176176761, 0.45060274283496377, 0.44127170758973616, 0.4652685433147161, 0.4841555882591909, 0.48915793973650146]\n","Epoch 1 - Save Best Score: 0.4699 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.4699 Model\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: [2][0/220] Elapsed 0m 7s (remain 28m 55s) Loss: 0.1107(0.1107) Grad: inf  LR: 0.00001872  \n","Epoch: [2][20/220] Elapsed 2m 30s (remain 23m 49s) Loss: 0.1482(0.1538) Grad: 265839.6562  LR: 0.00001841  \n","Epoch: [2][40/220] Elapsed 5m 2s (remain 22m 1s) Loss: 0.1130(0.1353) Grad: 142122.2500  LR: 0.00001807  \n","Epoch: [2][60/220] Elapsed 7m 29s (remain 19m 30s) Loss: 0.1110(0.1273) Grad: 119596.9688  LR: 0.00001771  \n","Epoch: [2][80/220] Elapsed 9m 46s (remain 16m 46s) Loss: 0.0964(0.1223) Grad: 127057.5938  LR: 0.00001731  \n","Epoch: [2][100/220] Elapsed 12m 14s (remain 14m 25s) Loss: 0.1473(0.1201) Grad: 229376.2031  LR: 0.00001689  \n","Epoch: [2][120/220] Elapsed 14m 48s (remain 12m 6s) Loss: 0.1166(0.1193) Grad: 176010.5469  LR: 0.00001644  \n","Epoch: [2][140/220] Elapsed 17m 13s (remain 9m 39s) Loss: 0.0988(0.1176) Grad: 125555.0781  LR: 0.00001597  \n","Epoch: [2][160/220] Elapsed 19m 35s (remain 7m 10s) Loss: 0.0962(0.1158) Grad: 164470.7188  LR: 0.00001548  \n","Epoch: [2][180/220] Elapsed 22m 4s (remain 4m 45s) Loss: 0.1041(0.1155) Grad: 124681.3203  LR: 0.00001497  \n","Epoch: [2][200/220] Elapsed 24m 24s (remain 2m 18s) Loss: 0.0815(0.1142) Grad: 128438.3125  LR: 0.00001445  \n","Epoch: [2][219/220] Elapsed 26m 39s (remain 0m 0s) Loss: 0.1021(0.1144) Grad: 79459.1094  LR: 0.00001393  \n","EVAL: [0/25] Elapsed 0m 1s (remain 0m 42s) Loss: 0.1336(0.1336) \n","EVAL: [20/25] Elapsed 0m 42s (remain 0m 8s) Loss: 0.1062(0.1032) \n","EVAL: [24/25] Elapsed 0m 47s (remain 0m 0s) Loss: 0.0575(0.1013) \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 2 - avg_train_loss: 0.1144  avg_val_loss: 0.1013  time: 1648s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.1144  avg_val_loss: 0.1013  time: 1648s\n","Epoch 2 - Score: 0.4506  Scores: [0.4913624377407623, 0.43161601549278744, 0.40238462875180037, 0.45079373956777286, 0.4606204398678114, 0.4666583301767775]\n","INFO:__main__:Epoch 2 - Score: 0.4506  Scores: [0.4913624377407623, 0.43161601549278744, 0.40238462875180037, 0.45079373956777286, 0.4606204398678114, 0.4666583301767775]\n","Epoch 2 - Save Best Score: 0.4506 Model\n","INFO:__main__:Epoch 2 - Save Best Score: 0.4506 Model\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: [3][0/220] Elapsed 0m 8s (remain 29m 13s) Loss: 0.1043(0.1043) Grad: 268046.1875  LR: 0.00001390  \n","Epoch: [3][20/220] Elapsed 2m 30s (remain 23m 50s) Loss: 0.0756(0.1040) Grad: 161231.1406  LR: 0.00001335  \n","Epoch: [3][40/220] Elapsed 4m 51s (remain 21m 12s) Loss: 0.1122(0.1014) Grad: 536805.3125  LR: 0.00001278  \n","Epoch: [3][60/220] Elapsed 7m 24s (remain 19m 19s) Loss: 0.1384(0.1019) Grad: 412848.9688  LR: 0.00001220  \n","Epoch: [3][80/220] Elapsed 9m 54s (remain 16m 59s) Loss: 0.1010(0.1014) Grad: 276650.1250  LR: 0.00001161  \n","Epoch: [3][100/220] Elapsed 12m 11s (remain 14m 21s) Loss: 0.1156(0.1012) Grad: 212897.5938  LR: 0.00001102  \n","Epoch: [3][120/220] Elapsed 14m 23s (remain 11m 46s) Loss: 0.1195(0.1013) Grad: 313616.4688  LR: 0.00001042  \n","Epoch: [3][140/220] Elapsed 16m 57s (remain 9m 29s) Loss: 0.0950(0.1012) Grad: 236310.3281  LR: 0.00000982  \n","Epoch: [3][160/220] Elapsed 19m 18s (remain 7m 4s) Loss: 0.1236(0.1013) Grad: 592946.3125  LR: 0.00000922  \n","Epoch: [3][180/220] Elapsed 21m 46s (remain 4m 41s) Loss: 0.1019(0.1005) Grad: 198640.9844  LR: 0.00000863  \n","Epoch: [3][200/220] Elapsed 24m 5s (remain 2m 16s) Loss: 0.1328(0.1002) Grad: 452081.2812  LR: 0.00000804  \n","Epoch: [3][219/220] Elapsed 26m 22s (remain 0m 0s) Loss: 0.1147(0.1004) Grad: 297569.3125  LR: 0.00000748  \n","EVAL: [0/25] Elapsed 0m 1s (remain 0m 42s) Loss: 0.1157(0.1157) \n","EVAL: [20/25] Elapsed 0m 42s (remain 0m 8s) Loss: 0.1171(0.1019) \n","EVAL: [24/25] Elapsed 0m 47s (remain 0m 0s) Loss: 0.0627(0.1006) \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 3 - avg_train_loss: 0.1004  avg_val_loss: 0.1006  time: 1631s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.1004  avg_val_loss: 0.1006  time: 1631s\n","Epoch 3 - Score: 0.4497  Scores: [0.47039397360745344, 0.4393918404858306, 0.41847502049416196, 0.4497427977716475, 0.457726167205888, 0.462583347746991]\n","INFO:__main__:Epoch 3 - Score: 0.4497  Scores: [0.47039397360745344, 0.4393918404858306, 0.41847502049416196, 0.4497427977716475, 0.457726167205888, 0.462583347746991]\n","Epoch 3 - Save Best Score: 0.4497 Model\n","INFO:__main__:Epoch 3 - Save Best Score: 0.4497 Model\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: [4][0/220] Elapsed 0m 5s (remain 18m 40s) Loss: 0.0661(0.0661) Grad: 209376.3281  LR: 0.00000746  \n","Epoch: [4][20/220] Elapsed 2m 29s (remain 23m 39s) Loss: 0.0805(0.0947) Grad: 154889.5469  LR: 0.00000688  \n","Epoch: [4][40/220] Elapsed 4m 54s (remain 21m 25s) Loss: 0.1042(0.0967) Grad: 254498.0781  LR: 0.00000632  \n","Epoch: [4][60/220] Elapsed 7m 15s (remain 18m 54s) Loss: 0.0690(0.0982) Grad: 136757.0625  LR: 0.00000577  \n","Epoch: [4][80/220] Elapsed 9m 40s (remain 16m 36s) Loss: 0.1007(0.0970) Grad: 250606.6250  LR: 0.00000523  \n","Epoch: [4][100/220] Elapsed 12m 12s (remain 14m 22s) Loss: 0.0779(0.0957) Grad: 256733.7031  LR: 0.00000472  \n","Epoch: [4][120/220] Elapsed 14m 41s (remain 12m 0s) Loss: 0.1103(0.0961) Grad: 154328.5625  LR: 0.00000422  \n","Epoch: [4][140/220] Elapsed 17m 13s (remain 9m 39s) Loss: 0.0938(0.0956) Grad: 507322.6562  LR: 0.00000374  \n","Epoch: [4][160/220] Elapsed 19m 35s (remain 7m 10s) Loss: 0.0710(0.0957) Grad: 187925.4844  LR: 0.00000329  \n","Epoch: [4][180/220] Elapsed 22m 9s (remain 4m 46s) Loss: 0.0838(0.0957) Grad: 428974.1562  LR: 0.00000286  \n","Epoch: [4][200/220] Elapsed 24m 35s (remain 2m 19s) Loss: 0.0996(0.0955) Grad: 492401.9062  LR: 0.00000245  \n","Epoch: [4][219/220] Elapsed 26m 53s (remain 0m 0s) Loss: 0.0740(0.0952) Grad: 213017.1875  LR: 0.00000209  \n","EVAL: [0/25] Elapsed 0m 1s (remain 0m 42s) Loss: 0.1183(0.1183) \n","EVAL: [20/25] Elapsed 0m 42s (remain 0m 8s) Loss: 0.1102(0.0998) \n","EVAL: [24/25] Elapsed 0m 47s (remain 0m 0s) Loss: 0.0618(0.0983) \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 4 - avg_train_loss: 0.0952  avg_val_loss: 0.0983  time: 1661s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.0952  avg_val_loss: 0.0983  time: 1661s\n","Epoch 4 - Score: 0.4441  Scores: [0.46469698317181335, 0.4248308072292609, 0.4110558726323508, 0.45154753837080736, 0.46029776556567287, 0.4521992721697107]\n","INFO:__main__:Epoch 4 - Score: 0.4441  Scores: [0.46469698317181335, 0.4248308072292609, 0.4110558726323508, 0.45154753837080736, 0.46029776556567287, 0.4521992721697107]\n","Epoch 4 - Save Best Score: 0.4441 Model\n","INFO:__main__:Epoch 4 - Save Best Score: 0.4441 Model\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: [5][0/220] Elapsed 0m 10s (remain 38m 50s) Loss: 0.1180(0.1180) Grad: 262437.5938  LR: 0.00000207  \n","Epoch: [5][20/220] Elapsed 2m 27s (remain 23m 17s) Loss: 0.0880(0.0894) Grad: 315177.3438  LR: 0.00000172  \n","Epoch: [5][40/220] Elapsed 4m 53s (remain 21m 22s) Loss: 0.0900(0.0889) Grad: 262641.2500  LR: 0.00000140  \n","Epoch: [5][60/220] Elapsed 7m 19s (remain 19m 5s) Loss: 0.0862(0.0881) Grad: 239280.2969  LR: 0.00000111  \n","Epoch: [5][80/220] Elapsed 9m 49s (remain 16m 51s) Loss: 0.0699(0.0901) Grad: 184323.9375  LR: 0.00000085  \n","Epoch: [5][100/220] Elapsed 12m 22s (remain 14m 34s) Loss: 0.1034(0.0906) Grad: 217452.0156  LR: 0.00000063  \n","Epoch: [5][120/220] Elapsed 14m 36s (remain 11m 57s) Loss: 0.0926(0.0913) Grad: 336970.1250  LR: 0.00000044  \n","Epoch: [5][140/220] Elapsed 17m 2s (remain 9m 32s) Loss: 0.0862(0.0922) Grad: 149565.4531  LR: 0.00000028  \n","Epoch: [5][160/220] Elapsed 19m 10s (remain 7m 1s) Loss: 0.0975(0.0919) Grad: 253885.7500  LR: 0.00000016  \n","Epoch: [5][180/220] Elapsed 21m 34s (remain 4m 38s) Loss: 0.1209(0.0921) Grad: 237233.7031  LR: 0.00000007  \n","Epoch: [5][200/220] Elapsed 24m 10s (remain 2m 17s) Loss: 0.0979(0.0920) Grad: 450947.6875  LR: 0.00000002  \n","Epoch: [5][219/220] Elapsed 26m 33s (remain 0m 0s) Loss: 0.0967(0.0919) Grad: 170009.6250  LR: 0.00000000  \n","EVAL: [0/25] Elapsed 0m 1s (remain 0m 42s) Loss: 0.1181(0.1181) \n","EVAL: [20/25] Elapsed 0m 42s (remain 0m 8s) Loss: 0.1106(0.0993) \n","EVAL: [24/25] Elapsed 0m 47s (remain 0m 0s) Loss: 0.0608(0.0978) \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 5 - avg_train_loss: 0.0919  avg_val_loss: 0.0978  time: 1642s\n","INFO:__main__:Epoch 5 - avg_train_loss: 0.0919  avg_val_loss: 0.0978  time: 1642s\n","Epoch 5 - Score: 0.4429  Scores: [0.4638495390466466, 0.42583404178616907, 0.40289520336626083, 0.44679214776873744, 0.4635618307766711, 0.454682114692066]\n","INFO:__main__:Epoch 5 - Score: 0.4429  Scores: [0.4638495390466466, 0.42583404178616907, 0.40289520336626083, 0.44679214776873744, 0.4635618307766711, 0.454682114692066]\n","Epoch 5 - Save Best Score: 0.4429 Model\n","INFO:__main__:Epoch 5 - Save Best Score: 0.4429 Model\n","========== fold: 7 result ==========\n","INFO:__main__:========== fold: 7 result ==========\n","Score: 0.4429  Scores: [0.4638495390466466, 0.42583404178616907, 0.40289520336626083, 0.44679214776873744, 0.4635618307766711, 0.454682114692066]\n","INFO:__main__:Score: 0.4429  Scores: [0.4638495390466466, 0.42583404178616907, 0.40289520336626083, 0.44679214776873744, 0.4635618307766711, 0.454682114692066]\n","========== fold: 8 training ==========\n","INFO:__main__:========== fold: 8 training ==========\n","DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 1024,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.23.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","INFO:__main__:DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 1024,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.23.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['mask_predictions.LayerNorm.weight', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.bias', 'mask_predictions.LayerNorm.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: [1][0/220] Elapsed 0m 4s (remain 15m 20s) Loss: 2.4486(2.4486) Grad: 697242.3125  LR: 0.00000040  \n","Epoch: [1][20/220] Elapsed 1m 17s (remain 12m 17s) Loss: 1.7929(2.2984) Grad: 700306.5000  LR: 0.00000840  \n","Epoch: [1][40/220] Elapsed 2m 32s (remain 11m 4s) Loss: 0.5295(1.8474) Grad: 354117.6250  LR: 0.00001640  \n","Epoch: [1][60/220] Elapsed 3m 43s (remain 9m 43s) Loss: 0.1586(1.3208) Grad: 119920.4609  LR: 0.00001999  \n","Epoch: [1][80/220] Elapsed 4m 54s (remain 8m 26s) Loss: 0.1516(1.0288) Grad: 61088.9922  LR: 0.00001996  \n","Epoch: [1][100/220] Elapsed 6m 6s (remain 7m 11s) Loss: 0.1617(0.8487) Grad: 70180.7891  LR: 0.00001988  \n","Epoch: [1][120/220] Elapsed 7m 20s (remain 6m 0s) Loss: 0.1500(0.7310) Grad: 83276.0781  LR: 0.00001978  \n","Epoch: [1][140/220] Elapsed 8m 38s (remain 4m 50s) Loss: 0.0980(0.6463) Grad: 38160.1055  LR: 0.00001963  \n","Epoch: [1][160/220] Elapsed 9m 49s (remain 3m 35s) Loss: 0.1149(0.5814) Grad: 43700.1289  LR: 0.00001945  \n","Epoch: [1][180/220] Elapsed 11m 2s (remain 2m 22s) Loss: 0.0833(0.5297) Grad: 31156.0840  LR: 0.00001924  \n","Epoch: [1][200/220] Elapsed 12m 16s (remain 1m 9s) Loss: 0.1297(0.4883) Grad: 52874.1289  LR: 0.00001900  \n","Epoch: [1][219/220] Elapsed 13m 26s (remain 0m 0s) Loss: 0.0943(0.4563) Grad: 23467.7129  LR: 0.00001873  \n","EVAL: [0/25] Elapsed 0m 2s (remain 0m 48s) Loss: 0.1008(0.1008) \n","EVAL: [20/25] Elapsed 0m 45s (remain 0m 8s) Loss: 0.1094(0.1103) \n","EVAL: [24/25] Elapsed 0m 51s (remain 0m 0s) Loss: 0.0746(0.1090) \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 1 - avg_train_loss: 0.4563  avg_val_loss: 0.1090  time: 858s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.4563  avg_val_loss: 0.1090  time: 858s\n","Epoch 1 - Score: 0.4677  Scores: [0.4861751268863857, 0.4616897388862549, 0.4201835343117372, 0.4737615906760349, 0.5024460486522927, 0.4619347330492952]\n","INFO:__main__:Epoch 1 - Score: 0.4677  Scores: [0.4861751268863857, 0.4616897388862549, 0.4201835343117372, 0.4737615906760349, 0.5024460486522927, 0.4619347330492952]\n","Epoch 1 - Save Best Score: 0.4677 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.4677 Model\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: [2][0/220] Elapsed 0m 7s (remain 29m 8s) Loss: 0.1068(0.1068) Grad: 269755.8750  LR: 0.00001872  \n","Epoch: [2][20/220] Elapsed 2m 23s (remain 22m 41s) Loss: 0.1306(0.1115) Grad: 305281.5938  LR: 0.00001841  \n","Epoch: [2][40/220] Elapsed 4m 43s (remain 20m 35s) Loss: 0.0939(0.1068) Grad: 346735.7500  LR: 0.00001807  \n","Epoch: [2][60/220] Elapsed 7m 10s (remain 18m 42s) Loss: 0.0717(0.1040) Grad: 321857.0000  LR: 0.00001771  \n","Epoch: [2][80/220] Elapsed 9m 39s (remain 16m 35s) Loss: 0.0923(0.1017) Grad: 305932.1562  LR: 0.00001731  \n","Epoch: [2][100/220] Elapsed 12m 6s (remain 14m 16s) Loss: 0.1184(0.1020) Grad: 301667.5938  LR: 0.00001689  \n","Epoch: [2][120/220] Elapsed 14m 31s (remain 11m 52s) Loss: 0.1201(0.1022) Grad: 234752.3125  LR: 0.00001644  \n","Epoch: [2][140/220] Elapsed 16m 53s (remain 9m 27s) Loss: 0.1052(0.1022) Grad: 294385.7812  LR: 0.00001597  \n","Epoch: [2][160/220] Elapsed 19m 33s (remain 7m 10s) Loss: 0.1195(0.1017) Grad: 289796.6250  LR: 0.00001548  \n","Epoch: [2][180/220] Elapsed 21m 55s (remain 4m 43s) Loss: 0.1038(0.1021) Grad: 382153.9062  LR: 0.00001497  \n","Epoch: [2][200/220] Elapsed 24m 9s (remain 2m 17s) Loss: 0.1041(0.1019) Grad: 156746.8906  LR: 0.00001445  \n","Epoch: [2][219/220] Elapsed 26m 18s (remain 0m 0s) Loss: 0.1055(0.1021) Grad: 423886.7500  LR: 0.00001393  \n","EVAL: [0/25] Elapsed 0m 2s (remain 0m 48s) Loss: 0.0923(0.0923) \n","EVAL: [20/25] Elapsed 0m 45s (remain 0m 8s) Loss: 0.1023(0.1066) \n","EVAL: [24/25] Elapsed 0m 51s (remain 0m 0s) Loss: 0.0664(0.1043) \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 2 - avg_train_loss: 0.1021  avg_val_loss: 0.1043  time: 1631s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.1021  avg_val_loss: 0.1043  time: 1631s\n","Epoch 2 - Score: 0.4575  Scores: [0.4754125455452462, 0.45521502725873103, 0.41397967969056165, 0.4775070366726595, 0.4758693365629206, 0.44688793657519954]\n","INFO:__main__:Epoch 2 - Score: 0.4575  Scores: [0.4754125455452462, 0.45521502725873103, 0.41397967969056165, 0.4775070366726595, 0.4758693365629206, 0.44688793657519954]\n","Epoch 2 - Save Best Score: 0.4575 Model\n","INFO:__main__:Epoch 2 - Save Best Score: 0.4575 Model\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: [3][0/220] Elapsed 0m 7s (remain 29m 10s) Loss: 0.0691(0.0691) Grad: 152138.4531  LR: 0.00001390  \n","Epoch: [3][20/220] Elapsed 2m 31s (remain 23m 51s) Loss: 0.0703(0.0946) Grad: 160622.1094  LR: 0.00001335  \n","Epoch: [3][40/220] Elapsed 4m 55s (remain 21m 30s) Loss: 0.0941(0.0953) Grad: 197094.5625  LR: 0.00001278  \n","Epoch: [3][60/220] Elapsed 7m 10s (remain 18m 42s) Loss: 0.0990(0.0965) Grad: 208205.3125  LR: 0.00001220  \n","Epoch: [3][80/220] Elapsed 9m 37s (remain 16m 31s) Loss: 0.0735(0.0970) Grad: 412646.8125  LR: 0.00001161  \n","Epoch: [3][100/220] Elapsed 11m 51s (remain 13m 58s) Loss: 0.1120(0.0976) Grad: 121568.4453  LR: 0.00001102  \n","Epoch: [3][120/220] Elapsed 14m 16s (remain 11m 40s) Loss: 0.0902(0.0979) Grad: 281912.4375  LR: 0.00001042  \n","Epoch: [3][140/220] Elapsed 16m 40s (remain 9m 20s) Loss: 0.0825(0.0982) Grad: 305046.6250  LR: 0.00000982  \n","Epoch: [3][160/220] Elapsed 19m 3s (remain 6m 58s) Loss: 0.0804(0.0980) Grad: 197429.2812  LR: 0.00000922  \n","Epoch: [3][180/220] Elapsed 21m 24s (remain 4m 36s) Loss: 0.1040(0.0982) Grad: 274805.8750  LR: 0.00000863  \n","Epoch: [3][200/220] Elapsed 23m 48s (remain 2m 15s) Loss: 0.1194(0.0982) Grad: 318860.0625  LR: 0.00000804  \n","Epoch: [3][219/220] Elapsed 26m 8s (remain 0m 0s) Loss: 0.1006(0.0976) Grad: 406011.1562  LR: 0.00000748  \n","EVAL: [0/25] Elapsed 0m 2s (remain 0m 49s) Loss: 0.0884(0.0884) \n","EVAL: [20/25] Elapsed 0m 45s (remain 0m 8s) Loss: 0.1049(0.1041) \n","EVAL: [24/25] Elapsed 0m 51s (remain 0m 0s) Loss: 0.0654(0.1025) \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 3 - avg_train_loss: 0.0976  avg_val_loss: 0.1025  time: 1621s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.0976  avg_val_loss: 0.1025  time: 1621s\n","Epoch 3 - Score: 0.4532  Scores: [0.47044555262180865, 0.44552173472648643, 0.4121181470976412, 0.4678041640255291, 0.47631962571957387, 0.4468749019702133]\n","INFO:__main__:Epoch 3 - Score: 0.4532  Scores: [0.47044555262180865, 0.44552173472648643, 0.4121181470976412, 0.4678041640255291, 0.47631962571957387, 0.4468749019702133]\n","Epoch 3 - Save Best Score: 0.4532 Model\n","INFO:__main__:Epoch 3 - Save Best Score: 0.4532 Model\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: [4][0/220] Elapsed 0m 8s (remain 29m 18s) Loss: 0.0983(0.0983) Grad: 198131.4062  LR: 0.00000746  \n","Epoch: [4][20/220] Elapsed 2m 40s (remain 25m 25s) Loss: 0.0761(0.0895) Grad: 215390.5312  LR: 0.00000688  \n","Epoch: [4][40/220] Elapsed 5m 4s (remain 22m 10s) Loss: 0.1157(0.0922) Grad: 168509.3281  LR: 0.00000632  \n","Epoch: [4][60/220] Elapsed 7m 17s (remain 18m 59s) Loss: 0.1115(0.0947) Grad: 232736.8438  LR: 0.00000577  \n","Epoch: [4][80/220] Elapsed 9m 42s (remain 16m 39s) Loss: 0.1402(0.0947) Grad: 250874.6719  LR: 0.00000523  \n","Epoch: [4][100/220] Elapsed 11m 53s (remain 14m 0s) Loss: 0.0686(0.0952) Grad: 119324.4453  LR: 0.00000472  \n","Epoch: [4][120/220] Elapsed 14m 22s (remain 11m 45s) Loss: 0.1000(0.0939) Grad: 175877.6875  LR: 0.00000422  \n","Epoch: [4][140/220] Elapsed 16m 46s (remain 9m 23s) Loss: 0.0983(0.0944) Grad: 187644.7031  LR: 0.00000374  \n","Epoch: [4][160/220] Elapsed 19m 2s (remain 6m 58s) Loss: 0.0814(0.0939) Grad: 229534.4219  LR: 0.00000329  \n","Epoch: [4][180/220] Elapsed 21m 33s (remain 4m 38s) Loss: 0.1111(0.0944) Grad: 144386.5938  LR: 0.00000286  \n","Epoch: [4][200/220] Elapsed 23m 48s (remain 2m 15s) Loss: 0.1015(0.0945) Grad: 156292.6406  LR: 0.00000245  \n","Epoch: [4][219/220] Elapsed 25m 59s (remain 0m 0s) Loss: 0.0916(0.0944) Grad: 132669.5000  LR: 0.00000209  \n","EVAL: [0/25] Elapsed 0m 2s (remain 0m 48s) Loss: 0.0921(0.0921) \n","EVAL: [20/25] Elapsed 0m 45s (remain 0m 8s) Loss: 0.1112(0.1053) \n","EVAL: [24/25] Elapsed 0m 51s (remain 0m 0s) Loss: 0.0763(0.1044) \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 4 - avg_train_loss: 0.0944  avg_val_loss: 0.1044  time: 1612s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.0944  avg_val_loss: 0.1044  time: 1612s\n","Epoch 4 - Score: 0.4573  Scores: [0.47418549505387586, 0.4522659074583925, 0.4121128361786067, 0.47423780483218186, 0.48347763623253387, 0.4472675203266781]\n","INFO:__main__:Epoch 4 - Score: 0.4573  Scores: [0.47418549505387586, 0.4522659074583925, 0.4121128361786067, 0.47423780483218186, 0.48347763623253387, 0.4472675203266781]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: [5][0/220] Elapsed 0m 8s (remain 32m 27s) Loss: 0.0743(0.0743) Grad: 146332.7188  LR: 0.00000207  \n","Epoch: [5][20/220] Elapsed 2m 33s (remain 24m 12s) Loss: 0.1155(0.0906) Grad: 463417.3125  LR: 0.00000172  \n","Epoch: [5][40/220] Elapsed 4m 51s (remain 21m 11s) Loss: 0.0963(0.0922) Grad: 306694.4375  LR: 0.00000140  \n","Epoch: [5][60/220] Elapsed 7m 12s (remain 18m 47s) Loss: 0.0878(0.0927) Grad: 204611.5938  LR: 0.00000111  \n","Epoch: [5][80/220] Elapsed 9m 23s (remain 16m 7s) Loss: 0.0692(0.0908) Grad: 198766.8906  LR: 0.00000085  \n","Epoch: [5][100/220] Elapsed 11m 47s (remain 13m 53s) Loss: 0.0975(0.0916) Grad: 288730.0312  LR: 0.00000063  \n","Epoch: [5][120/220] Elapsed 14m 10s (remain 11m 35s) Loss: 0.0836(0.0909) Grad: 252500.2812  LR: 0.00000044  \n","Epoch: [5][140/220] Elapsed 16m 40s (remain 9m 20s) Loss: 0.1015(0.0906) Grad: 289430.7188  LR: 0.00000028  \n","Epoch: [5][160/220] Elapsed 19m 13s (remain 7m 2s) Loss: 0.0814(0.0904) Grad: 178906.5938  LR: 0.00000016  \n","Epoch: [5][180/220] Elapsed 21m 37s (remain 4m 39s) Loss: 0.0587(0.0911) Grad: 224383.0312  LR: 0.00000007  \n","Epoch: [5][200/220] Elapsed 23m 57s (remain 2m 15s) Loss: 0.0815(0.0911) Grad: 145369.5781  LR: 0.00000002  \n","Epoch: [5][219/220] Elapsed 26m 18s (remain 0m 0s) Loss: 0.0811(0.0914) Grad: 101149.1328  LR: 0.00000000  \n","EVAL: [0/25] Elapsed 0m 2s (remain 0m 49s) Loss: 0.0868(0.0868) \n","EVAL: [20/25] Elapsed 0m 45s (remain 0m 8s) Loss: 0.1034(0.1019) \n","EVAL: [24/25] Elapsed 0m 51s (remain 0m 0s) Loss: 0.0690(0.1006) \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 5 - avg_train_loss: 0.0914  avg_val_loss: 0.1006  time: 1630s\n","INFO:__main__:Epoch 5 - avg_train_loss: 0.0914  avg_val_loss: 0.1006  time: 1630s\n","Epoch 5 - Score: 0.4489  Scores: [0.4684479339446366, 0.4453933763968846, 0.403552543194842, 0.4622039542036048, 0.4699696411992817, 0.44381058254796274]\n","INFO:__main__:Epoch 5 - Score: 0.4489  Scores: [0.4684479339446366, 0.4453933763968846, 0.403552543194842, 0.4622039542036048, 0.4699696411992817, 0.44381058254796274]\n","Epoch 5 - Save Best Score: 0.4489 Model\n","INFO:__main__:Epoch 5 - Save Best Score: 0.4489 Model\n","========== fold: 8 result ==========\n","INFO:__main__:========== fold: 8 result ==========\n","Score: 0.4489  Scores: [0.4684479339446366, 0.4453933763968846, 0.403552543194842, 0.4622039542036048, 0.4699696411992817, 0.44381058254796274]\n","INFO:__main__:Score: 0.4489  Scores: [0.4684479339446366, 0.4453933763968846, 0.403552543194842, 0.4622039542036048, 0.4699696411992817, 0.44381058254796274]\n","========== fold: 9 training ==========\n","INFO:__main__:========== fold: 9 training ==========\n","DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 1024,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.23.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","INFO:__main__:DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 1024,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.23.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['mask_predictions.LayerNorm.weight', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.bias', 'mask_predictions.LayerNorm.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: [1][0/219] Elapsed 0m 3s (remain 14m 17s) Loss: 2.5363(2.5363) Grad: 715204.1250  LR: 0.00000040  \n","Epoch: [1][20/219] Elapsed 1m 3s (remain 9m 56s) Loss: 2.3408(2.4854) Grad: 726033.4375  LR: 0.00000840  \n","Epoch: [1][40/219] Elapsed 2m 19s (remain 10m 4s) Loss: 1.0676(2.1090) Grad: 803407.6875  LR: 0.00001640  \n","Epoch: [1][60/219] Elapsed 3m 37s (remain 9m 23s) Loss: 0.1737(1.5184) Grad: 250193.5312  LR: 0.00001999  \n","Epoch: [1][80/219] Elapsed 4m 53s (remain 8m 19s) Loss: 0.1266(1.1814) Grad: 144909.6875  LR: 0.00001996  \n","Epoch: [1][100/219] Elapsed 6m 17s (remain 7m 20s) Loss: 0.1223(0.9705) Grad: 167850.7344  LR: 0.00001988  \n","Epoch: [1][120/219] Elapsed 7m 35s (remain 6m 8s) Loss: 0.1631(0.8309) Grad: 187202.0625  LR: 0.00001977  \n","Epoch: [1][140/219] Elapsed 8m 55s (remain 4m 56s) Loss: 0.1553(0.7309) Grad: 272895.5000  LR: 0.00001963  \n","Epoch: [1][160/219] Elapsed 9m 59s (remain 3m 36s) Loss: 0.1062(0.6542) Grad: 192193.5625  LR: 0.00001945  \n","Epoch: [1][180/219] Elapsed 11m 12s (remain 2m 21s) Loss: 0.1275(0.5939) Grad: 219371.5156  LR: 0.00001924  \n","Epoch: [1][200/219] Elapsed 12m 28s (remain 1m 6s) Loss: 0.0911(0.5468) Grad: 93444.2891  LR: 0.00001899  \n","Epoch: [1][218/219] Elapsed 13m 37s (remain 0m 0s) Loss: 0.0938(0.5106) Grad: 220143.2969  LR: 0.00001875  \n","EVAL: [0/25] Elapsed 0m 2s (remain 1m 1s) Loss: 0.1210(0.1210) \n","EVAL: [20/25] Elapsed 0m 41s (remain 0m 7s) Loss: 0.1256(0.1345) \n","EVAL: [24/25] Elapsed 0m 48s (remain 0m 0s) Loss: 0.1325(0.1376) \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 1 - avg_train_loss: 0.5106  avg_val_loss: 0.1376  time: 867s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.5106  avg_val_loss: 0.1376  time: 867s\n","Epoch 1 - Score: 0.5265  Scores: [0.5787930885632745, 0.5225247183449997, 0.436635101303751, 0.49595442521498084, 0.5602069816359282, 0.5645879279910492]\n","INFO:__main__:Epoch 1 - Score: 0.5265  Scores: [0.5787930885632745, 0.5225247183449997, 0.436635101303751, 0.49595442521498084, 0.5602069816359282, 0.5645879279910492]\n","Epoch 1 - Save Best Score: 0.5265 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.5265 Model\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [2][0/219] Elapsed 0m 8s (remain 29m 9s) Loss: 0.1034(0.1034) Grad: 414219.8125  LR: 0.00001873  \n","Epoch: [2][20/219] Elapsed 2m 23s (remain 22m 35s) Loss: 0.1675(0.1203) Grad: 526218.9375  LR: 0.00001842  \n","Epoch: [2][40/219] Elapsed 4m 56s (remain 21m 27s) Loss: 0.1058(0.1191) Grad: 510003.3750  LR: 0.00001809  \n","Epoch: [2][60/219] Elapsed 7m 33s (remain 19m 34s) Loss: 0.1399(0.1154) Grad: 543689.4375  LR: 0.00001772  \n","Epoch: [2][80/219] Elapsed 9m 54s (remain 16m 53s) Loss: 0.0995(0.1132) Grad: 393848.6562  LR: 0.00001733  \n","Epoch: [2][100/219] Elapsed 12m 17s (remain 14m 21s) Loss: 0.1010(0.1141) Grad: 283421.0938  LR: 0.00001691  \n","Epoch: [2][120/219] Elapsed 14m 38s (remain 11m 51s) Loss: 0.1449(0.1133) Grad: 282339.0312  LR: 0.00001646  \n","Epoch: [2][140/219] Elapsed 16m 53s (remain 9m 20s) Loss: 0.0933(0.1122) Grad: 361366.0938  LR: 0.00001599  \n","Epoch: [2][160/219] Elapsed 19m 15s (remain 6m 56s) Loss: 0.1188(0.1108) Grad: 214590.9219  LR: 0.00001550  \n","Epoch: [2][180/219] Elapsed 21m 39s (remain 4m 32s) Loss: 0.0983(0.1099) Grad: 246757.3125  LR: 0.00001499  \n","Epoch: [2][200/219] Elapsed 23m 55s (remain 2m 8s) Loss: 0.1035(0.1092) Grad: 406714.0938  LR: 0.00001446  \n","Epoch: [2][218/219] Elapsed 26m 13s (remain 0m 0s) Loss: 0.1028(0.1089) Grad: 368921.5625  LR: 0.00001398  \n","EVAL: [0/25] Elapsed 0m 2s (remain 1m 1s) Loss: 0.1018(0.1018) \n","EVAL: [20/25] Elapsed 0m 41s (remain 0m 7s) Loss: 0.1060(0.1157) \n","EVAL: [24/25] Elapsed 0m 48s (remain 0m 0s) Loss: 0.0646(0.1138) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.1089  avg_val_loss: 0.1138  time: 1623s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.1089  avg_val_loss: 0.1138  time: 1623s\n","Epoch 2 - Score: 0.4776  Scores: [0.5390038353647364, 0.4532272314516498, 0.4183989235899092, 0.49736107408849706, 0.5168549494459356, 0.44079778695333854]\n","INFO:__main__:Epoch 2 - Score: 0.4776  Scores: [0.5390038353647364, 0.4532272314516498, 0.4183989235899092, 0.49736107408849706, 0.5168549494459356, 0.44079778695333854]\n","Epoch 2 - Save Best Score: 0.4776 Model\n","INFO:__main__:Epoch 2 - Save Best Score: 0.4776 Model\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [3][0/219] Elapsed 0m 4s (remain 17m 11s) Loss: 0.1065(0.1065) Grad: 415884.9688  LR: 0.00001395  \n","Epoch: [3][20/219] Elapsed 2m 35s (remain 24m 27s) Loss: 0.0773(0.1080) Grad: 436777.6250  LR: 0.00001339  \n","Epoch: [3][40/219] Elapsed 5m 8s (remain 22m 18s) Loss: 0.1063(0.1041) Grad: 213125.1875  LR: 0.00001282  \n","Epoch: [3][60/219] Elapsed 7m 40s (remain 19m 51s) Loss: 0.0964(0.1029) Grad: 348447.0000  LR: 0.00001224  \n","Epoch: [3][80/219] Elapsed 10m 4s (remain 17m 9s) Loss: 0.0846(0.1019) Grad: 168888.3906  LR: 0.00001165  \n","Epoch: [3][100/219] Elapsed 12m 23s (remain 14m 29s) Loss: 0.1041(0.1013) Grad: 312381.4062  LR: 0.00001106  \n","Epoch: [3][120/219] Elapsed 14m 42s (remain 11m 54s) Loss: 0.1023(0.1005) Grad: 451902.8438  LR: 0.00001046  \n","Epoch: [3][140/219] Elapsed 16m 57s (remain 9m 22s) Loss: 0.1461(0.1006) Grad: 389784.2188  LR: 0.00000987  \n","Epoch: [3][160/219] Elapsed 19m 22s (remain 6m 58s) Loss: 0.1112(0.1007) Grad: 414435.8438  LR: 0.00000927  \n","Epoch: [3][180/219] Elapsed 21m 51s (remain 4m 35s) Loss: 0.0691(0.1009) Grad: 190467.2969  LR: 0.00000867  \n","Epoch: [3][200/219] Elapsed 24m 13s (remain 2m 10s) Loss: 0.1198(0.1009) Grad: 235592.1406  LR: 0.00000808  \n","Epoch: [3][218/219] Elapsed 26m 18s (remain 0m 0s) Loss: 0.0938(0.1005) Grad: 336843.6875  LR: 0.00000755  \n","EVAL: [0/25] Elapsed 0m 2s (remain 1m 1s) Loss: 0.0949(0.0949) \n","EVAL: [20/25] Elapsed 0m 41s (remain 0m 7s) Loss: 0.1070(0.1091) \n","EVAL: [24/25] Elapsed 0m 48s (remain 0m 0s) Loss: 0.0623(0.1078) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.1005  avg_val_loss: 0.1078  time: 1628s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.1005  avg_val_loss: 0.1078  time: 1628s\n","Epoch 3 - Score: 0.4647  Scores: [0.5173736171837129, 0.4492189402984685, 0.41701866588040726, 0.46622917449703294, 0.5102105125056644, 0.4284152740759222]\n","INFO:__main__:Epoch 3 - Score: 0.4647  Scores: [0.5173736171837129, 0.4492189402984685, 0.41701866588040726, 0.46622917449703294, 0.5102105125056644, 0.4284152740759222]\n","Epoch 3 - Save Best Score: 0.4647 Model\n","INFO:__main__:Epoch 3 - Save Best Score: 0.4647 Model\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [4][0/219] Elapsed 0m 9s (remain 33m 30s) Loss: 0.1079(0.1079) Grad: 190364.8906  LR: 0.00000753  \n","Epoch: [4][20/219] Elapsed 2m 22s (remain 22m 20s) Loss: 0.0934(0.0950) Grad: 235415.6094  LR: 0.00000695  \n","Epoch: [4][40/219] Elapsed 4m 43s (remain 20m 32s) Loss: 0.0806(0.0929) Grad: 175861.9844  LR: 0.00000639  \n","Epoch: [4][60/219] Elapsed 7m 11s (remain 18m 38s) Loss: 0.1213(0.0945) Grad: 534641.2500  LR: 0.00000583  \n","Epoch: [4][80/219] Elapsed 9m 39s (remain 16m 27s) Loss: 0.1183(0.0963) Grad: 307228.2500  LR: 0.00000530  \n","Epoch: [4][100/219] Elapsed 12m 6s (remain 14m 8s) Loss: 0.0993(0.0953) Grad: 213015.0312  LR: 0.00000478  \n","Epoch: [4][120/219] Elapsed 14m 26s (remain 11m 41s) Loss: 0.1136(0.0974) Grad: 307700.7500  LR: 0.00000428  \n","Epoch: [4][140/219] Elapsed 16m 55s (remain 9m 21s) Loss: 0.1156(0.0973) Grad: 371591.3125  LR: 0.00000380  \n","Epoch: [4][160/219] Elapsed 19m 14s (remain 6m 55s) Loss: 0.0551(0.0967) Grad: 311666.0000  LR: 0.00000334  \n","Epoch: [4][180/219] Elapsed 21m 24s (remain 4m 29s) Loss: 0.0943(0.0964) Grad: 391732.5000  LR: 0.00000290  \n","Epoch: [4][200/219] Elapsed 23m 58s (remain 2m 8s) Loss: 0.0781(0.0963) Grad: 133022.2500  LR: 0.00000249  \n","Epoch: [4][218/219] Elapsed 26m 14s (remain 0m 0s) Loss: 0.1119(0.0960) Grad: 485360.2812  LR: 0.00000215  \n","EVAL: [0/25] Elapsed 0m 2s (remain 1m 0s) Loss: 0.0908(0.0908) \n","EVAL: [20/25] Elapsed 0m 41s (remain 0m 7s) Loss: 0.1073(0.1063) \n","EVAL: [24/25] Elapsed 0m 48s (remain 0m 0s) Loss: 0.0668(0.1058) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.0960  avg_val_loss: 0.1058  time: 1624s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.0960  avg_val_loss: 0.1058  time: 1624s\n","Epoch 4 - Score: 0.4597  Scores: [0.5173550788874349, 0.4471438625274376, 0.40727531187181465, 0.46087489594109093, 0.5052399263709766, 0.42016884947872196]\n","INFO:__main__:Epoch 4 - Score: 0.4597  Scores: [0.5173550788874349, 0.4471438625274376, 0.40727531187181465, 0.46087489594109093, 0.5052399263709766, 0.42016884947872196]\n","Epoch 4 - Save Best Score: 0.4597 Model\n","INFO:__main__:Epoch 4 - Save Best Score: 0.4597 Model\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [5][0/219] Elapsed 0m 6s (remain 23m 21s) Loss: 0.0811(0.0811) Grad: 276018.5625  LR: 0.00000213  \n","Epoch: [5][20/219] Elapsed 2m 22s (remain 22m 28s) Loss: 0.0791(0.0869) Grad: 318587.7188  LR: 0.00000177  \n","Epoch: [5][40/219] Elapsed 4m 43s (remain 20m 31s) Loss: 0.0754(0.0907) Grad: 183783.1875  LR: 0.00000145  \n","Epoch: [5][60/219] Elapsed 7m 8s (remain 18m 28s) Loss: 0.0555(0.0905) Grad: 272922.2500  LR: 0.00000115  \n","Epoch: [5][80/219] Elapsed 9m 46s (remain 16m 38s) Loss: 0.0921(0.0916) Grad: 331408.9688  LR: 0.00000089  \n","Epoch: [5][100/219] Elapsed 12m 17s (remain 14m 21s) Loss: 0.0663(0.0914) Grad: 169164.6406  LR: 0.00000066  \n","Epoch: [5][120/219] Elapsed 14m 36s (remain 11m 50s) Loss: 0.0879(0.0920) Grad: 316610.7188  LR: 0.00000046  \n","Epoch: [5][140/219] Elapsed 17m 3s (remain 9m 26s) Loss: 0.1160(0.0917) Grad: 470716.4688  LR: 0.00000030  \n","Epoch: [5][160/219] Elapsed 19m 23s (remain 6m 59s) Loss: 0.1080(0.0925) Grad: 195222.1719  LR: 0.00000017  \n","Epoch: [5][180/219] Elapsed 21m 43s (remain 4m 33s) Loss: 0.1084(0.0927) Grad: 175594.6094  LR: 0.00000008  \n","Epoch: [5][200/219] Elapsed 24m 14s (remain 2m 10s) Loss: 0.0933(0.0930) Grad: 308844.3438  LR: 0.00000002  \n","Epoch: [5][218/219] Elapsed 26m 35s (remain 0m 0s) Loss: 0.0956(0.0926) Grad: 335114.1875  LR: 0.00000000  \n","EVAL: [0/25] Elapsed 0m 2s (remain 1m 1s) Loss: 0.0906(0.0906) \n","EVAL: [20/25] Elapsed 0m 41s (remain 0m 7s) Loss: 0.1096(0.1043) \n","EVAL: [24/25] Elapsed 0m 48s (remain 0m 0s) Loss: 0.0722(0.1049) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5 - avg_train_loss: 0.0926  avg_val_loss: 0.1049  time: 1645s\n","INFO:__main__:Epoch 5 - avg_train_loss: 0.0926  avg_val_loss: 0.1049  time: 1645s\n","Epoch 5 - Score: 0.4578  Scores: [0.5160498812833167, 0.4403666973715476, 0.407948479277586, 0.46074765153943603, 0.503319115464221, 0.41824758806450624]\n","INFO:__main__:Epoch 5 - Score: 0.4578  Scores: [0.5160498812833167, 0.4403666973715476, 0.407948479277586, 0.46074765153943603, 0.503319115464221, 0.41824758806450624]\n","Epoch 5 - Save Best Score: 0.4578 Model\n","INFO:__main__:Epoch 5 - Save Best Score: 0.4578 Model\n","========== fold: 9 result ==========\n","INFO:__main__:========== fold: 9 result ==========\n","Score: 0.4578  Scores: [0.5160498812833167, 0.4403666973715476, 0.407948479277586, 0.46074765153943603, 0.503319115464221, 0.41824758806450624]\n","INFO:__main__:Score: 0.4578  Scores: [0.5160498812833167, 0.4403666973715476, 0.407948479277586, 0.46074765153943603, 0.503319115464221, 0.41824758806450624]\n","========== CV ==========\n","INFO:__main__:========== CV ==========\n","Score: 0.4526  Scores: [0.48656278525974, 0.4452836067428861, 0.4159414580653684, 0.4527670709512733, 0.4690087343594997, 0.4463198876556127]\n","INFO:__main__:Score: 0.4526  Scores: [0.48656278525974, 0.4452836067428861, 0.4159414580653684, 0.4527670709512733, 0.4690087343594997, 0.4463198876556127]\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>[fold0] avg_train_loss</td><td>█▁▁▁▁</td></tr><tr><td>[fold0] avg_val_loss</td><td>█▅▃▄▁</td></tr><tr><td>[fold0] epoch</td><td>▁▃▅▆█</td></tr><tr><td>[fold0] loss</td><td>█▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>[fold0] lr</td><td>▃▅███████▇▇▇▇▇▆▆▆▅▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>[fold0] score</td><td>█▆▃▄▁</td></tr><tr><td>[fold1] avg_train_loss</td><td>█▁▁▁▁</td></tr><tr><td>[fold1] avg_val_loss</td><td>█▃▂▂▁</td></tr><tr><td>[fold1] epoch</td><td>▁▃▅▆█</td></tr><tr><td>[fold1] loss</td><td>█▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>[fold1] lr</td><td>▃▅███████▇▇▇▇▇▆▆▆▅▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>[fold1] score</td><td>█▃▂▂▁</td></tr><tr><td>[fold2] avg_train_loss</td><td>█▁▁▁▁</td></tr><tr><td>[fold2] avg_val_loss</td><td>▄█▁▂▁</td></tr><tr><td>[fold2] epoch</td><td>▁▃▅▆█</td></tr><tr><td>[fold2] loss</td><td>█▆▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>[fold2] lr</td><td>▃▅███████▇▇▇▇▇▆▆▆▅▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>[fold2] score</td><td>▄█▂▃▁</td></tr><tr><td>[fold3] avg_train_loss</td><td>█▁▁▁▁</td></tr><tr><td>[fold3] avg_val_loss</td><td>█▆▅▂▁</td></tr><tr><td>[fold3] epoch</td><td>▁▃▅▆█</td></tr><tr><td>[fold3] loss</td><td>█▆▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>[fold3] lr</td><td>▃▅███████▇▇▇▇▇▆▆▆▅▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>[fold3] score</td><td>█▆▅▂▁</td></tr><tr><td>[fold4] avg_train_loss</td><td>█▁▁▁▁</td></tr><tr><td>[fold4] avg_val_loss</td><td>█▆▆▂▁</td></tr><tr><td>[fold4] epoch</td><td>▁▃▅▆█</td></tr><tr><td>[fold4] loss</td><td>█▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>[fold4] lr</td><td>▃▅███████▇▇▇▇▇▆▆▆▅▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>[fold4] score</td><td>█▆▆▂▁</td></tr><tr><td>[fold5] avg_train_loss</td><td>█▁▁▁▁</td></tr><tr><td>[fold5] avg_val_loss</td><td>█▃▁▃▁</td></tr><tr><td>[fold5] epoch</td><td>▁▃▅▆█</td></tr><tr><td>[fold5] loss</td><td>█▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>[fold5] lr</td><td>▃▅███████▇▇▇▇▇▆▆▆▅▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>[fold5] score</td><td>█▃▁▃▁</td></tr><tr><td>[fold6] avg_train_loss</td><td>█▁▁▁▁</td></tr><tr><td>[fold6] avg_val_loss</td><td>▄█▂▁▁</td></tr><tr><td>[fold6] epoch</td><td>▁▃▅▆█</td></tr><tr><td>[fold6] loss</td><td>█▆▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>[fold6] lr</td><td>▃▅███████▇▇▇▇▇▆▆▆▅▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>[fold6] score</td><td>▄█▂▁▁</td></tr><tr><td>[fold7] avg_train_loss</td><td>█▁▁▁▁</td></tr><tr><td>[fold7] avg_val_loss</td><td>█▃▃▁▁</td></tr><tr><td>[fold7] epoch</td><td>▁▃▅▆█</td></tr><tr><td>[fold7] loss</td><td>█▆▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>[fold7] lr</td><td>▃▅███████▇▇▇▇▇▆▆▆▅▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>[fold7] score</td><td>█▃▃▁▁</td></tr><tr><td>[fold8] avg_train_loss</td><td>█▁▁▁▁</td></tr><tr><td>[fold8] avg_val_loss</td><td>█▄▃▄▁</td></tr><tr><td>[fold8] epoch</td><td>▁▃▅▆█</td></tr><tr><td>[fold8] loss</td><td>█▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>[fold8] lr</td><td>▃▅███████▇▇▇▇▇▆▆▆▅▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>[fold8] score</td><td>█▄▃▄▁</td></tr><tr><td>[fold9] avg_train_loss</td><td>█▁▁▁▁</td></tr><tr><td>[fold9] avg_val_loss</td><td>█▃▂▁▁</td></tr><tr><td>[fold9] epoch</td><td>▁▃▅▆█</td></tr><tr><td>[fold9] loss</td><td>█▆▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>[fold9] lr</td><td>▃▅███████▇▇▇▇▇▆▆▆▅▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>[fold9] score</td><td>█▃▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>[fold0] avg_train_loss</td><td>0.09456</td></tr><tr><td>[fold0] avg_val_loss</td><td>0.09942</td></tr><tr><td>[fold0] epoch</td><td>5</td></tr><tr><td>[fold0] loss</td><td>0.11104</td></tr><tr><td>[fold0] lr</td><td>0.0</td></tr><tr><td>[fold0] score</td><td>0.44595</td></tr><tr><td>[fold1] avg_train_loss</td><td>0.09209</td></tr><tr><td>[fold1] avg_val_loss</td><td>0.1038</td></tr><tr><td>[fold1] epoch</td><td>5</td></tr><tr><td>[fold1] loss</td><td>0.09024</td></tr><tr><td>[fold1] lr</td><td>0.0</td></tr><tr><td>[fold1] score</td><td>0.45618</td></tr><tr><td>[fold2] avg_train_loss</td><td>0.09312</td></tr><tr><td>[fold2] avg_val_loss</td><td>0.10404</td></tr><tr><td>[fold2] epoch</td><td>5</td></tr><tr><td>[fold2] loss</td><td>0.09047</td></tr><tr><td>[fold2] lr</td><td>0.0</td></tr><tr><td>[fold2] score</td><td>0.45734</td></tr><tr><td>[fold3] avg_train_loss</td><td>0.09208</td></tr><tr><td>[fold3] avg_val_loss</td><td>0.10043</td></tr><tr><td>[fold3] epoch</td><td>5</td></tr><tr><td>[fold3] loss</td><td>0.12019</td></tr><tr><td>[fold3] lr</td><td>0.0</td></tr><tr><td>[fold3] score</td><td>0.44838</td></tr><tr><td>[fold4] avg_train_loss</td><td>0.09261</td></tr><tr><td>[fold4] avg_val_loss</td><td>0.10417</td></tr><tr><td>[fold4] epoch</td><td>5</td></tr><tr><td>[fold4] loss</td><td>0.09673</td></tr><tr><td>[fold4] lr</td><td>0.0</td></tr><tr><td>[fold4] score</td><td>0.45783</td></tr><tr><td>[fold5] avg_train_loss</td><td>0.09245</td></tr><tr><td>[fold5] avg_val_loss</td><td>0.09846</td></tr><tr><td>[fold5] epoch</td><td>5</td></tr><tr><td>[fold5] loss</td><td>0.08344</td></tr><tr><td>[fold5] lr</td><td>0.0</td></tr><tr><td>[fold5] score</td><td>0.44387</td></tr><tr><td>[fold6] avg_train_loss</td><td>0.09192</td></tr><tr><td>[fold6] avg_val_loss</td><td>0.10786</td></tr><tr><td>[fold6] epoch</td><td>5</td></tr><tr><td>[fold6] loss</td><td>0.10482</td></tr><tr><td>[fold6] lr</td><td>0.0</td></tr><tr><td>[fold6] score</td><td>0.46571</td></tr><tr><td>[fold7] avg_train_loss</td><td>0.09194</td></tr><tr><td>[fold7] avg_val_loss</td><td>0.09775</td></tr><tr><td>[fold7] epoch</td><td>5</td></tr><tr><td>[fold7] loss</td><td>0.09673</td></tr><tr><td>[fold7] lr</td><td>0.0</td></tr><tr><td>[fold7] score</td><td>0.44294</td></tr><tr><td>[fold8] avg_train_loss</td><td>0.0914</td></tr><tr><td>[fold8] avg_val_loss</td><td>0.10064</td></tr><tr><td>[fold8] epoch</td><td>5</td></tr><tr><td>[fold8] loss</td><td>0.08105</td></tr><tr><td>[fold8] lr</td><td>0.0</td></tr><tr><td>[fold8] score</td><td>0.4489</td></tr><tr><td>[fold9] avg_train_loss</td><td>0.09258</td></tr><tr><td>[fold9] avg_val_loss</td><td>0.10489</td></tr><tr><td>[fold9] epoch</td><td>5</td></tr><tr><td>[fold9] loss</td><td>0.09561</td></tr><tr><td>[fold9] lr</td><td>0.0</td></tr><tr><td>[fold9] score</td><td>0.45778</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Synced <strong style=\"color:#cdcd00\">microsoft/deberta-v3-base</strong>: <a href=\"https://wandb.ai/bluehills/Feedback3-Public/runs/3gls29tj\" target=\"_blank\">https://wandb.ai/bluehills/Feedback3-Public/runs/3gls29tj</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20221101_103532-3gls29tj/logs</code>"]},"metadata":{}}],"source":["if __name__ == '__main__':\n","    \n","    def get_result(oof_df):\n","        labels = oof_df[CFG.target_cols].values\n","        preds = oof_df[[f\"pred_{c}\" for c in CFG.target_cols]].values\n","        score, scores = get_score(labels, preds)\n","        LOGGER.info(f'Score: {score:<.4f}  Scores: {scores}')\n","    \n","\n","    torch.distributed.init_process_group(backend=\"nccl\", )\n","    local_rank = int(os.environ[\"LOCAL_RANK\"])\n","    world_size = torch.distributed.get_world_size()\n","    device = \"cuda:%s\" % local_rank\n","\n","\n","    if CFG.train:\n","        oof_df = pd.DataFrame()\n","        for fold in range(CFG.n_fold):\n","            if fold in CFG.trn_fold:\n","                _oof_df = train_loop(train, fold, device, local_rank, world_size) # CPMP\n","                if local_rank == 0: # CPMP\n","                    oof_df = pd.concat([oof_df, _oof_df])\n","                    LOGGER.info(f\"========== fold: {fold} result ==========\")\n","                    get_result(_oof_df)\n","        if local_rank == 0: # CPMP\n","            oof_df = oof_df.reset_index(drop=True)\n","            LOGGER.info(f\"========== CV ==========\")\n","            get_result(oof_df)\n","            oof_df.to_pickle(OUTPUT_DIR+'oof_df.pkl')\n","        \n","    if CFG.wandb and local_rank == 0: # CPMP\n","        wandb.finish()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZscqGHdnPvuB"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","provenance":[],"authorship_tag":"ABX9TyO+K7NjZ4VmK29mIwWa0pxz"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"1586fa5f923f4ef38b93870397e5a694":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1bb086bfa59e4271b065b027776e3ec4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1df217ad69a1422bb07501d61b43b06b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e069fed4cee46b8a2348d6352a41974":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"34cef67bb97a47edab90ead015c6c96d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4095f253459b4e12a606069f747156bf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"44d04bba88674054bdd2351a43d1ffd3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9ff888daa1514741b33c65b39ffba3b8","max":2464616,"min":0,"orientation":"horizontal","style":"IPY_MODEL_552863caa19647678acc1e911df3b342","value":2464616}},"484fea0c5e1c40d78a9f54ef24c7199f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"49ed98230683453885bdbada339cb13e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"53c68ac5314d4722933f7052ce8f51c9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_be14b7c80ad54495bb6517dcf4590793","IPY_MODEL_c95be6dddca74a2bbe57f3b637c8dc42","IPY_MODEL_aa3d2c2d6494462b9cbde88bf5da9996"],"layout":"IPY_MODEL_49ed98230683453885bdbada339cb13e"}},"552863caa19647678acc1e911df3b342":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"578dde988c57499192b7c45bcad9edf3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5c3036c9f29c4f3199ab104e12b5956f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"64ccac65453542719f622e5d10fa7959":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"66ac4e1728a54a67864a751b3af53e3d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9902e05a45a4413a88dbd3499ab967de","placeholder":"​","style":"IPY_MODEL_1586fa5f923f4ef38b93870397e5a694","value":" 371M/371M [00:05&lt;00:00, 70.2MB/s]"}},"69f9be038ddc4763a4eabbf473383d58":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6ad45739ba8d40ff99e1a3dff93a37ae":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6da42264b48849abbf32e88de759ecf1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9db1e8eac0864f689c985cc921de387d","max":579,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4095f253459b4e12a606069f747156bf","value":579}},"77d3439d05de4b908e883d6a21a5e9e5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7afb0495ff2b412e9a2394cd1e69eed2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"860e502a3e884db3bea649ae3f231392":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_974d70ec38c945e5b75f97ecb83e846b","IPY_MODEL_ac0969d512704d2ca8d69563ef9718fc","IPY_MODEL_66ac4e1728a54a67864a751b3af53e3d"],"layout":"IPY_MODEL_d43b7ae66781497e9f142077d8404c67"}},"974d70ec38c945e5b75f97ecb83e846b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cf8cb528f47a41a3aa2888f90d26e549","placeholder":"​","style":"IPY_MODEL_7afb0495ff2b412e9a2394cd1e69eed2","value":"Downloading: 100%"}},"976f3c01ce0a4b62856d5fd98296bcb6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a31cb778feb843788db07c703e59ed40","IPY_MODEL_6da42264b48849abbf32e88de759ecf1","IPY_MODEL_f40acac3043747b48e494ebd6a8c5688"],"layout":"IPY_MODEL_1df217ad69a1422bb07501d61b43b06b"}},"9902e05a45a4413a88dbd3499ab967de":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9db1e8eac0864f689c985cc921de387d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9ff888daa1514741b33c65b39ffba3b8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a31cb778feb843788db07c703e59ed40":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1bb086bfa59e4271b065b027776e3ec4","placeholder":"​","style":"IPY_MODEL_6ad45739ba8d40ff99e1a3dff93a37ae","value":"Downloading: 100%"}},"a3d91b1d07f44001b090a62f2e35fa9e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a441a25be523482c917e48c0be50f610":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a7b945ea2cbf481c9f2ccaa9812ad9c0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_578dde988c57499192b7c45bcad9edf3","placeholder":"​","style":"IPY_MODEL_a441a25be523482c917e48c0be50f610","value":"Downloading: 100%"}},"a81ed695cb9142ffbc3252dca1640e87":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5c3036c9f29c4f3199ab104e12b5956f","placeholder":"​","style":"IPY_MODEL_2e069fed4cee46b8a2348d6352a41974","value":" 2.46M/2.46M [00:00&lt;00:00, 24.8MB/s]"}},"aa3d2c2d6494462b9cbde88bf5da9996":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_77d3439d05de4b908e883d6a21a5e9e5","placeholder":"​","style":"IPY_MODEL_64ccac65453542719f622e5d10fa7959","value":" 52.0/52.0 [00:00&lt;00:00, 2.08kB/s]"}},"ac0969d512704d2ca8d69563ef9718fc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_69f9be038ddc4763a4eabbf473383d58","max":371146213,"min":0,"orientation":"horizontal","style":"IPY_MODEL_484fea0c5e1c40d78a9f54ef24c7199f","value":371146213}},"ad6d12abc5d44712ad561c9f51f7cf9e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a7b945ea2cbf481c9f2ccaa9812ad9c0","IPY_MODEL_44d04bba88674054bdd2351a43d1ffd3","IPY_MODEL_a81ed695cb9142ffbc3252dca1640e87"],"layout":"IPY_MODEL_b42d846a49be40ed9cf3c9fcf4b29b90"}},"afa9acc3085d445e9d1d43eb86785d7d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b163927e4c994b8b8388ee2c94037a9a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b42d846a49be40ed9cf3c9fcf4b29b90":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"be14b7c80ad54495bb6517dcf4590793":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b163927e4c994b8b8388ee2c94037a9a","placeholder":"​","style":"IPY_MODEL_afa9acc3085d445e9d1d43eb86785d7d","value":"Downloading: 100%"}},"c95be6dddca74a2bbe57f3b637c8dc42":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a3d91b1d07f44001b090a62f2e35fa9e","max":52,"min":0,"orientation":"horizontal","style":"IPY_MODEL_34cef67bb97a47edab90ead015c6c96d","value":52}},"cf8cb528f47a41a3aa2888f90d26e549":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d43b7ae66781497e9f142077d8404c67":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ea3cbe06f8c1470b81567b7137156d64":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f40acac3043747b48e494ebd6a8c5688":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f4b7b59fa3d2451f8487250f5254dde4","placeholder":"​","style":"IPY_MODEL_ea3cbe06f8c1470b81567b7137156d64","value":" 579/579 [00:00&lt;00:00, 23.5kB/s]"}},"f4b7b59fa3d2451f8487250f5254dde4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}