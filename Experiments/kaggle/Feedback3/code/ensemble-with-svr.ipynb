{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8b487da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-05T06:59:49.136032Z",
     "iopub.status.busy": "2022-11-05T06:59:49.135248Z",
     "iopub.status.idle": "2022-11-05T07:00:21.998492Z",
     "shell.execute_reply": "2022-11-05T07:00:21.997300Z"
    },
    "papermill": {
     "duration": 32.882973,
     "end_time": "2022-11-05T07:00:22.000865",
     "exception": false,
     "start_time": "2022-11-05T06:59:49.117892",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizers.__version__: 0.12.1\n",
      "transformers.__version__: 4.21.2\n",
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Library\n",
    "# ====================================================\n",
    "import os\n",
    "import gc\n",
    "import re\n",
    "import ast\n",
    "import sys\n",
    "import copy\n",
    "import json\n",
    "import time\n",
    "import math \n",
    "import string\n",
    "import pickle\n",
    "import random\n",
    "import joblib\n",
    "import itertools\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from IPython. display import clear_output\n",
    "\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Parameter\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, SGD, AdamW\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "#os.system('pip install iterative-stratification==0.1.7')\n",
    "#from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "sys.path.append('../input/iterativestratification')\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "\n",
    "os.system('pip uninstall -y transformers')\n",
    "os.system('pip uninstall -y tokenizers')\n",
    "os.system('python -m pip install --no-index --find-links=../input/fb3-my-pip-wheels transformers')\n",
    "os.system('python -m pip install --no-index --find-links=../input/fb3-my-pip-wheels tokenizers')\n",
    "import tokenizers\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n",
    "from transformers import DataCollatorWithPadding\n",
    "%env TOKENIZERS_PARALLELISM=false\n",
    "\n",
    "clear_output()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"tokenizers.__version__: {tokenizers.__version__}\")\n",
    "print(f\"transformers.__version__: {transformers.__version__}\")\n",
    "print('device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba576910",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-05T07:00:22.015966Z",
     "iopub.status.busy": "2022-11-05T07:00:22.015484Z",
     "iopub.status.idle": "2022-11-05T07:00:22.020453Z",
     "shell.execute_reply": "2022-11-05T07:00:22.019444Z"
    },
    "papermill": {
     "duration": 0.014913,
     "end_time": "2022-11-05T07:00:22.022720",
     "exception": false,
     "start_time": "2022-11-05T07:00:22.007807",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "BASE_PATH = '/kaggle/input/feedback-prize-english-language-learning'\n",
    "SUBMISSION_PATH = os.path.join(BASE_PATH, 'sample_submission.csv')\n",
    "TRAIN_PATH = os.path.join(BASE_PATH, 'train.csv')\n",
    "TEST_PATH = os.path.join(BASE_PATH, 'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6252dbf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-05T07:00:22.037087Z",
     "iopub.status.busy": "2022-11-05T07:00:22.036827Z",
     "iopub.status.idle": "2022-11-05T07:00:22.045378Z",
     "shell.execute_reply": "2022-11-05T07:00:22.044409Z"
    },
    "papermill": {
     "duration": 0.018067,
     "end_time": "2022-11-05T07:00:22.047487",
     "exception": false,
     "start_time": "2022-11-05T07:00:22.029420",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Config(dict):\n",
    "    __getattr__ = dict.__getitem__\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "    \n",
    "    def init(self, kwargs):\n",
    "        super().init(kwargs)\n",
    "\n",
    "        for k, v in kwargs.items():\n",
    "            setattr(self, k, v)\n",
    "\n",
    "    def set(self, key, val):\n",
    "        self[key] = val\n",
    "        setattr(self, key, val)\n",
    "        \n",
    "def get_logger(filename='inference'):\n",
    "    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n",
    "    logger = getLogger(__name__)\n",
    "    logger.propagate = False\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=f\"{filename}.log\")\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "LOGGER = get_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c565f09d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-05T07:00:22.061905Z",
     "iopub.status.busy": "2022-11-05T07:00:22.061648Z",
     "iopub.status.idle": "2022-11-05T07:00:22.072827Z",
     "shell.execute_reply": "2022-11-05T07:00:22.072010Z"
    },
    "papermill": {
     "duration": 0.020536,
     "end_time": "2022-11-05T07:00:22.074764",
     "exception": false,
     "start_time": "2022-11-05T07:00:22.054228",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    '''\n",
    "    Sets the seed of the entire notebook so results are the same every time we run.\n",
    "    This is for REPRODUCIBILITY.\n",
    "    '''\n",
    "    random.seed(seed)\n",
    "    # Set a fixed value for the hash seed\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        # When running on the CuDNN backend, two further options must be set\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "seed_everything(seed=42)\n",
    "\n",
    "def mc_rmse(y_true, y_pred):\n",
    "    scores = []\n",
    "    ncols = y_true.shape[1]\n",
    "    \n",
    "    for n in range(ncols):\n",
    "        yn_true = y_true[:, n]\n",
    "        yn_pred = y_pred[:, n]\n",
    "        rmse_ = mean_squared_error(yn_true, yn_pred, squared=False)\n",
    "        scores.append(rmse_)\n",
    "    score = np.mean(scores) \n",
    "    return score, scores\n",
    "\n",
    "def get_result(cfg, oof_df):\n",
    "    labels = oof_df[cfg.target_cols].values\n",
    "    preds = oof_df[[f\"pred_{c}\" for c in cfg.target_cols]].values\n",
    "    score, scores = mc_rmse(labels, preds)\n",
    "    print(f'score: {score:<.6f}  scores: {scores}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb8638bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-05T07:00:22.089837Z",
     "iopub.status.busy": "2022-11-05T07:00:22.089048Z",
     "iopub.status.idle": "2022-11-05T07:00:22.098832Z",
     "shell.execute_reply": "2022-11-05T07:00:22.098003Z"
    },
    "papermill": {
     "duration": 0.019233,
     "end_time": "2022-11-05T07:00:22.100757",
     "exception": false,
     "start_time": "2022-11-05T07:00:22.081524",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Dataset\n",
    "# ====================================================\n",
    "def encode_text(cfg, text):\n",
    "    if cfg.pretrained:\n",
    "        inputs = cfg.tokenizer(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=cfg.max_len,\n",
    "            return_token_type_ids=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        inputs = {k:v.squeeze(0) for k,v in inputs.items()}\n",
    "    else:\n",
    "        inputs = cfg.tokenizer.encode_plus(\n",
    "            text, \n",
    "            return_tensors=None, \n",
    "            add_special_tokens=True, \n",
    "            #max_length=CFG.max_len,\n",
    "            #pad_to_max_length=True,\n",
    "            #truncation=True\n",
    "        )\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = torch.tensor(v, dtype=torch.long)\n",
    "    return inputs \n",
    "\n",
    "def preprocess(texts):\n",
    "    texts = (\n",
    "        texts\n",
    "        .str.replace(r'\\r\\n', '<newline>', regex=True)\n",
    "        .str.replace(r'\\n', '<newline>', regex=True)\n",
    "        .str.replace('<newline><newline>', '<newline>', regex=False)\n",
    "        .values \n",
    "    )\n",
    "    return texts\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, cfg, df):\n",
    "        self.cfg = cfg\n",
    "        if cfg.pretrained:\n",
    "            self.texts = df['full_text'].values\n",
    "        else:\n",
    "            self.texts = preprocess(df['full_text'])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        inputs = encode_text(self.cfg, self.texts[item])\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f91d7673",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-05T07:00:22.115399Z",
     "iopub.status.busy": "2022-11-05T07:00:22.114780Z",
     "iopub.status.idle": "2022-11-05T07:00:22.133909Z",
     "shell.execute_reply": "2022-11-05T07:00:22.133086Z"
    },
    "papermill": {
     "duration": 0.02858,
     "end_time": "2022-11-05T07:00:22.135806",
     "exception": false,
     "start_time": "2022-11-05T07:00:22.107226",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AttentionHead(nn.Module):\n",
    "    def __init__(self, in_features, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.middle_features = hidden_dim\n",
    "        self.W = nn.Linear(in_features, hidden_dim)\n",
    "        self.V = nn.Linear(hidden_dim, 1)\n",
    "        self.out_features = hidden_dim\n",
    "\n",
    "    def forward(self, features, *args):\n",
    "        att = torch.tanh(self.W(features))\n",
    "        score = self.V(att)\n",
    "        attention_weights = torch.softmax(score, dim=1)\n",
    "        context_vector = attention_weights * features\n",
    "        context_vector = torch.sum(context_vector, dim=1)\n",
    "\n",
    "        return context_vector\n",
    "    \n",
    "class WeightedLayerPooling(nn.Module):\n",
    "    def __init__(self, num_hidden_layers, layer_start: int = 9, layer_weights = None):\n",
    "        super(WeightedLayerPooling, self).__init__()\n",
    "        self.layer_start = layer_start\n",
    "        self.num_hidden_layers = num_hidden_layers\n",
    "        self.layer_weights = layer_weights if layer_weights is not None \\\n",
    "            else nn.Parameter(\n",
    "                torch.tensor([1] * (num_hidden_layers+1 - layer_start), dtype=torch.float))\n",
    "        \n",
    "    def forward(self, all_hidden_states):\n",
    "        all_layer_embedding = all_hidden_states[self.layer_start:, :, :, :]\n",
    "        weight_factor = self.layer_weights.unsqueeze(-1).unsqueeze(-1).unsqueeze(-1).expand(all_layer_embedding.size())\n",
    "        weighted_average = (weight_factor*all_layer_embedding).sum(dim=0) / self.layer_weights.sum()\n",
    "        return weighted_average\n",
    "    \n",
    "class FB3Model(nn.Module):\n",
    "    def __init__(self, cfg, config_path=None, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg \n",
    "        if config_path is None:\n",
    "            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n",
    "            # Turn off dropouts.\n",
    "            self.config.hidden_dropout = 0.\n",
    "            self.config.hidden_dropout_prob = 0.\n",
    "            self.config.attention_dropout = 0.\n",
    "            self.config.attention_probs_dropout_prob = 0.\n",
    "            #LOGGER.info(self.config)\n",
    "        else:\n",
    "            self.config = torch.load(config_path)\n",
    "        \n",
    "        if pretrained:\n",
    "            self.deberta_v3 = AutoModel.from_pretrained(cfg.model, config=self.config)\n",
    "        else:\n",
    "            self.deberta_v3 = AutoModel.from_config(self.config)\n",
    "\n",
    "        if self.cfg.reinit_last_layer:\n",
    "            # Re-init last layer of deberta.\n",
    "            for module in self.deberta_v3.encoder.layer[-1:].modules():\n",
    "                self._init_weights(module)\n",
    "        self.deberta_v3.gradient_checkpointing_enable()\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            #nn.init.xavier_uniform_(module.weight.data, gain=1.0)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "\n",
    "class WMPoolModel(FB3Model):\n",
    "    def __init__(self, cfg, config_path=None, pretrained=False):\n",
    "        super().__init__(cfg, config_path=config_path, pretrained=pretrained)\n",
    "\n",
    "        # Poolings.\n",
    "        self.wpool_head = WeightedLayerPooling(self.config.num_hidden_layers, layer_start=12)\n",
    "\n",
    "        self.fc_out = nn.Linear(self.config.hidden_size, cfg.num_target)\n",
    "        self._init_weights(self.fc_out)\n",
    "        \n",
    "        self.layer_norm = nn.LayerNorm(self.config.hidden_size)\n",
    "        self.qa_output = torch.nn.Linear(self.config.hidden_size, 2)\n",
    "        self.attention_head = AttentionHead(self.config.hidden_size*4, self.config.hidden_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        pt_out = self.deberta_v3(**x)\n",
    "        all_hidden_states = torch.stack(pt_out.hidden_states)\n",
    "        # Weighted pooling of last n layers.\n",
    "        logits = self.wpool_head(all_hidden_states)[:, 0] # Bx768\n",
    "        y_hat = self.fc_out(logits)\n",
    "        return y_hat\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae592fa4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-05T07:00:22.151209Z",
     "iopub.status.busy": "2022-11-05T07:00:22.150672Z",
     "iopub.status.idle": "2022-11-05T07:00:22.157603Z",
     "shell.execute_reply": "2022-11-05T07:00:22.156515Z"
    },
    "papermill": {
     "duration": 0.017272,
     "end_time": "2022-11-05T07:00:22.159543",
     "exception": false,
     "start_time": "2022-11-05T07:00:22.142271",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_config(input_path, inference_weight=1):\n",
    "    # Load CFG class.\n",
    "    cfg = Config(**json.load(open(os.path.join(input_path, 'CFG.json'), 'r')))\n",
    "    cfg.path = input_path\n",
    "    cfg.config_path = os.path.join(cfg.path, 'config.pth')\n",
    "    # Load tokenizer.\n",
    "    tokenizer = AutoTokenizer.from_pretrained(os.path.join(cfg.path, 'tokenizer'))\n",
    "    cfg.tokenizer = tokenizer\n",
    "    \n",
    "    cfg.inference_weight = inference_weight\n",
    "    return cfg\n",
    "\n",
    "\n",
    "def load_model(cfg, fold, **model_kwargs):\n",
    "    # Load torch model.\n",
    "    model = WMPoolModel(cfg, config_path=cfg.config_path, pretrained=False, **model_kwargs)\n",
    "    state = torch.load(\n",
    "        os.path.join(cfg.path, f\"{cfg.model.replace('/', '-')}_fold{fold}_best.pth\"),\n",
    "        map_location=torch.device('cpu'))\n",
    "    model.load_state_dict(state['model'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5197d51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-05T07:00:22.174410Z",
     "iopub.status.busy": "2022-11-05T07:00:22.173717Z",
     "iopub.status.idle": "2022-11-05T07:00:22.191241Z",
     "shell.execute_reply": "2022-11-05T07:00:22.190422Z"
    },
    "papermill": {
     "duration": 0.027088,
     "end_time": "2022-11-05T07:00:22.193238",
     "exception": false,
     "start_time": "2022-11-05T07:00:22.166150",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output.last_hidden_state.detach().cpu()\n",
    "    input_mask_expanded = (\n",
    "        attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    )\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(\n",
    "        input_mask_expanded.sum(1), min=1e-9\n",
    "    )\n",
    "\n",
    "def inference_fn(test_loader, model, device):\n",
    "    preds = []\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    #tk0 = tqdm(test_loader, total=len(test_loader))\n",
    "    for inputs in test_loader:\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(inputs)\n",
    "        preds.append(y_preds.to('cpu').numpy())\n",
    "    predictions = np.concatenate(preds)\n",
    "    return predictions\n",
    "\n",
    "class Inferencer:\n",
    "    def __init__(self, input_path=None, cfg=None, inference_weight=1):\n",
    "        if cfg == None:\n",
    "            self.cfg = load_config(input_path, inference_weight)\n",
    "        else:\n",
    "            self.cfg = cfg\n",
    "    \n",
    "    def predict(self, test_loader, device, stat_fn=np.mean):\n",
    "        preds = []\n",
    "        start = time.time()\n",
    "        print('#'*10, cfg.path, '#'*10)\n",
    "        for fold in self.cfg.trn_fold:\n",
    "            print(f'Predicting fold {fold}...')\n",
    "            model = load_model(self.cfg, fold)\n",
    "            pred = inference_fn(test_loader, model, device)\n",
    "            preds.append(pred)\n",
    "            del model, pred; gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "        end = time.time() - start\n",
    "        print('#'*10, f'ETA: {end:.2f}s', '#'*10, '\\n')\n",
    "        \n",
    "        self.preds = stat_fn(preds, axis=0) \n",
    "        self.preds = np.clip(self.preds, 1, 5)\n",
    "        return self.preds\n",
    "    \n",
    "    def get_oof_result(self):\n",
    "        return get_result(pd.read_pickle(os.path.join(cfg.path, 'oof_df.pkl')))\n",
    "    \n",
    "    def get_text_embedding(self, data_loader, device, fold=None): \n",
    "        # pretrained=True: not fine-tuned models.\n",
    "        if not self.cfg.pretrained:\n",
    "            model = load_model(self.cfg, fold, pool=self.cfg.pool_head)            \n",
    "        else:\n",
    "            model = AutoModel.from_pretrained(self.cfg.model)\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "            \n",
    "        fold_emb = []\n",
    "        for inputs in data_loader:\n",
    "            for k, v in inputs.items():\n",
    "                inputs[k] = v.to(device)\n",
    "            if not self.cfg.pretrained:\n",
    "                with torch.no_grad():\n",
    "                    emb = model.feature(**inputs)\n",
    "            else:\n",
    "                input_ids = inputs['input_ids'].to(device)\n",
    "                attention_mask = inputs['attention_mask'].to(device)\n",
    "                token_type_ids = inputs['token_type_ids'].to(device)\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    output = model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "                emb = mean_pooling(output, attention_mask.detach().cpu())\n",
    "                emb = F.normalize(emb, p=2, dim=1)\n",
    "                emb = emb.squeeze(0)\n",
    "            fold_emb.extend(emb.detach().cpu().numpy())\n",
    "            del emb; gc.collect(); torch.cuda.empty_cache();\n",
    "            #print(torch.cuda.memory_allocated() /1024/1024)\n",
    "            \n",
    "        fold_emb = np.array(fold_emb)\n",
    "        return fold_emb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429956bd",
   "metadata": {
    "papermill": {
     "duration": 0.006283,
     "end_time": "2022-11-05T07:00:22.206099",
     "exception": false,
     "start_time": "2022-11-05T07:00:22.199816",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# svr + pretrained embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b11c7eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-05T07:00:22.220917Z",
     "iopub.status.busy": "2022-11-05T07:00:22.220666Z",
     "iopub.status.idle": "2022-11-05T07:00:22.234276Z",
     "shell.execute_reply": "2022-11-05T07:00:22.233326Z"
    },
    "papermill": {
     "duration": 0.023292,
     "end_time": "2022-11-05T07:00:22.236316",
     "exception": false,
     "start_time": "2022-11-05T07:00:22.213024",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "##################################################\n",
    "deberta_base = Config(\n",
    "    model='../input/huggingface-deberta-variants/deberta-base/deberta-base',\n",
    "    file_name='microsoft_deberta_base_768',\n",
    "    pretrained=True, inference_weight=1, max_len=640) #\n",
    "deberta_large = Config(\n",
    "    model='../input/huggingface-deberta-variants/deberta-large/deberta-large', \n",
    "    file_name='microsoft_deberta_large_1024',\n",
    "    pretrained=True, inference_weight=1, max_len=640) #\n",
    "deberta_xlarge = Config(\n",
    "    model='../input/huggingface-deberta-variants/deberta-xlarge/deberta-xlarge', \n",
    "    file_name='microsoft_deberta_xlarge_1024',\n",
    "    pretrained=True, inference_weight=1, max_len=640)\n",
    "deberta_v2_xlarge = Config(\n",
    "    model='../input/bert-shopping-mall/deberta-v2-xlarge', \n",
    "    file_name='microsoft_deberta_v2_xlarge_1536',\n",
    "    pretrained=True, inference_weight=1, max_len=640)\n",
    "deberta_v2_xxlarge = Config(\n",
    "    model='../input/bert-shopping-mall/deberta-v2-xxlarge', \n",
    "    file_name='microsoft_deberta_v2_xxlarge_1536',\n",
    "    pretrained=True, inference_weight=1, max_len=640)\n",
    "\n",
    "deberta_v3_base = Config(\n",
    "    model='../input/bert-shopping-mall/deberta-v3-base',\n",
    "    file_name='microsoft_deberta_v3_base_768',\n",
    "    pretrained=True, inference_weight=1, max_len=640) #\n",
    "deberta_v3_large = Config(\n",
    "    model='../input/bert-shopping-mall/deberta-v3-large', \n",
    "    file_name='microsoft_deberta_v3_large_1024',\n",
    "    pretrained=True, inference_weight=1, max_len=640) # \n",
    "\n",
    "deberta_large_mnli = Config(\n",
    "    model='../input/huggingface-deberta-variants/deberta-large-mnli/deberta-large-mnli',\n",
    "    file_name='microsoft_deberta_large_mnli_1024',\n",
    "    pretrained=True, inference_weight=1, max_len=640) # \n",
    "\n",
    "gpt2 = Config(\n",
    "    model='../input/hugging-face-gpt2/gpt2',\n",
    "    file_name='gpt2_768',\n",
    "    pretrained=True, inference_weight=1, max_len=512) #\n",
    "\n",
    "roberta_base = Config(\n",
    "    model='../input/transformers/roberta-base', \n",
    "    file_name='roberta_base_768',\n",
    "    pretrained=True, inference_weight=1, max_len=512) #\n",
    "roberta_large = Config(\n",
    "    model='../input/transformers/roberta-large',\n",
    "    file_name='roberta_large_1024',\n",
    "    pretrained=True, inference_weight=1, max_len=512) # \n",
    "\n",
    "xlnet_base = Config(\n",
    "    model='../input/transformers/xlnet-base-cased',\n",
    "    file_name='xlnet_base_cased_768',\n",
    "    pretrained=True, inference_weight=1, max_len=640) #\n",
    "xlnet_large = Config(\n",
    "    model='../input/transformers/xlnet-large-cased', \n",
    "    file_name='xlnet_large_cased_1024',\n",
    "    pretrained=True, inference_weight=1, max_len=640) #\n",
    "\n",
    "bart_base = Config(\n",
    "    model='../input/transformers/facebook-bart-base',\n",
    "    file_name='facebook_bart_base_768',\n",
    "    pretrained=True, inference_weight=1, max_len=640)\n",
    "bart_large = Config(\n",
    "    model='../input/transformers/facebook-bart-large',\n",
    "    file_name='facebook_bart_large_1024',\n",
    "    pretrained=True, inference_weight=1, max_len=640)\n",
    "bart_lage_mnli = Config(\n",
    "    model='../input/facebook-bart-large-mnli',\n",
    "    file_name='facebook_bart_large_mnli_1024',\n",
    "    pretrained=True, inference_weight=1, max_len=640)\n",
    "\n",
    "bert_base_uncased = Config(\n",
    "    model='../input/transformers/bert-base-uncased/',\n",
    "    file_name='bert_base_uncased_768',\n",
    "    pretrained=True, inference_weight=1, max_len=512)\n",
    "bert_large_uncased = Config(\n",
    "    model='../input/transformers/bert-large-uncased',\n",
    "    file_name='bert_large_uncased_1024',\n",
    "    pretrained=True, inference_weight=1, max_len=512)\n",
    "\n",
    "muppet_roberta_large = Config(\n",
    "    model='../input/muppet-roberta-large',\n",
    "    file_name='facebook_muppet_roberta_large_1024',\n",
    "    pretrained=True, inference_weight=1, max_len=512)\n",
    "\n",
    "funnel_small = Config(\n",
    "    model='../input/transformers/funnel-transformer-small',\n",
    "    file_name='funnel_transformer_small_768',\n",
    "    pretrained=True, inference_weight=1, max_len=640)\n",
    "funnel_large = Config(\n",
    "    model='../input/transformers/funnel-transformer-large',\n",
    "    file_name='funnel_transformer_large_1024',\n",
    "    pretrained=True, inference_weight=1, max_len=640)\n",
    "\n",
    "##################################################\n",
    "\n",
    "target_cols = ['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02143fb6",
   "metadata": {
    "papermill": {
     "duration": 0.006471,
     "end_time": "2022-11-05T07:00:22.249703",
     "exception": false,
     "start_time": "2022-11-05T07:00:22.243232",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## load embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c918c79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-05T07:00:22.263788Z",
     "iopub.status.busy": "2022-11-05T07:00:22.263535Z",
     "iopub.status.idle": "2022-11-05T07:00:25.830298Z",
     "shell.execute_reply": "2022-11-05T07:00:25.829366Z"
    },
    "papermill": {
     "duration": 3.576201,
     "end_time": "2022-11-05T07:00:25.832465",
     "exception": false,
     "start_time": "2022-11-05T07:00:22.256264",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "from joblib import dump, load\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.linear_model import RidgeCV, Ridge, Lasso\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "if str(device) == 'cpu':\n",
    "    from sklearn.svm import SVR\n",
    "else:\n",
    "    from cuml.svm import SVR\n",
    "    import cuml\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d931388",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-05T07:00:25.848087Z",
     "iopub.status.busy": "2022-11-05T07:00:25.847798Z",
     "iopub.status.idle": "2022-11-05T07:00:26.044591Z",
     "shell.execute_reply": "2022-11-05T07:00:26.043616Z"
    },
    "papermill": {
     "duration": 0.207088,
     "end_time": "2022-11-05T07:00:26.046968",
     "exception": false,
     "start_time": "2022-11-05T07:00:25.839880",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(TRAIN_PATH)\n",
    "test = pd.read_csv(TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f2e812d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-05T07:00:26.063610Z",
     "iopub.status.busy": "2022-11-05T07:00:26.062083Z",
     "iopub.status.idle": "2022-11-05T07:00:26.209354Z",
     "shell.execute_reply": "2022-11-05T07:00:26.208511Z"
    },
    "papermill": {
     "duration": 0.157481,
     "end_time": "2022-11-05T07:00:26.211694",
     "exception": false,
     "start_time": "2022-11-05T07:00:26.054213",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../input/iterativestratification')\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "svr_folds = 15\n",
    "\n",
    "skf = MultilabelStratifiedKFold(n_splits=svr_folds, shuffle=True, random_state=42)\n",
    "for i,(train_index, val_index) in enumerate(skf.split(train,train[target_cols])):\n",
    "    train.loc[val_index,'fold'] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb74eac6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-05T07:00:26.226872Z",
     "iopub.status.busy": "2022-11-05T07:00:26.226591Z",
     "iopub.status.idle": "2022-11-05T07:00:26.242102Z",
     "shell.execute_reply": "2022-11-05T07:00:26.241263Z"
    },
    "papermill": {
     "duration": 0.025556,
     "end_time": "2022-11-05T07:00:26.244213",
     "exception": false,
     "start_time": "2022-11-05T07:00:26.218657",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from glob import glob \n",
    "\n",
    "def get_text_embedding(cfg, dfs):\n",
    "    cfg.tokenizer = AutoTokenizer.from_pretrained(cfg.model)\n",
    "    infer_ = Inferencer(cfg=cfg, inference_weight=cfg.inference_weight)\n",
    "    if cfg.model == 'gpt2':\n",
    "        cfg.tokenizer.pad_token = cfg.tokenizer.eos_token\n",
    "    text_embs = []\n",
    "    for df in dfs:\n",
    "        dataset = TestDataset(cfg, df)\n",
    "        loader = DataLoader(\n",
    "            dataset,\n",
    "            batch_size=4,\n",
    "            shuffle=False)\n",
    "\n",
    "        # Text embedding for SVM\n",
    "        test_text_emb = []\n",
    "        if not cfg.pretrained:\n",
    "            for fold in infer_.cfg.trn_fold:\n",
    "                test_text_emb.append(infer_.get_text_embedding(loader, device, fold))\n",
    "            text_emb = np.mean(text_emb, axis=0)\n",
    "        else:\n",
    "            text_emb = infer_.get_text_embedding(loader, device)\n",
    "        text_embs.append(text_emb)\n",
    "        del dataset, loader; gc.collect(); torch.cuda.empty_cache();\n",
    "    del infer_; gc.collect(); torch.cuda.empty_cache();\n",
    "    return text_embs\n",
    "\n",
    "def learner_cv(features, learner, folds=15, save=False, verbose=False):\n",
    "    scores = []\n",
    "    for fold in range(folds):\n",
    "        dftr_ = train[train['fold']!=fold]\n",
    "        dfev_ = train[train['fold']==fold]\n",
    "\n",
    "        tr_text_feats = features[list(dftr_.index),:]\n",
    "        ev_text_feats = features[list(dfev_.index),:]\n",
    "\n",
    "        # clf = MultiOutputRegressor(SVR(C=2.0))\n",
    "        clf = MultiOutputRegressor(learner)\n",
    "        clf.fit(tr_text_feats, dftr_[target_cols].values)\n",
    "        ev_preds = clf.predict(ev_text_feats)\n",
    "\n",
    "        score,_ = mc_rmse(dfev_[target_cols].values, ev_preds)\n",
    "        scores.append(score)\n",
    "\n",
    "        if verbose:\n",
    "            print('#'*25)\n",
    "            print('### Fold',fold+1)\n",
    "            print(\"Score: {}\".format(score))\n",
    "        if save:\n",
    "            dump(clf, f'svr_{fold}.model')\n",
    "\n",
    "    # print('#'*25)\n",
    "    # print('Overall CV =', np.mean(scores))\n",
    "    return np.mean(scores)\n",
    "\n",
    "def get_learner_score(models_cfg, learner, folds=5, save=False, verbose=False):\n",
    "    for i, model_cfg in enumerate(models_cfg):\n",
    "        model_name = model_cfg.model.split('/')[-1].replace('-', '_')\n",
    "        models_cfg[i].model_name = model_name\n",
    "        model_file = f'../input/fb3embeddings/train_text_emb_{model_cfg.file_name}.npy'\n",
    "        if 'embedding' in model_cfg:\n",
    "            continue\n",
    "        with open(model_file, 'rb') as f:\n",
    "            models_cfg[i].embedding = np.load(f)   \n",
    "    embeddings = np.concatenate([model_cfg.embedding for model_cfg in models_cfg], axis=1)\n",
    "    svr_score = learner_cv(embeddings, learner, folds=folds, save=save, verbose=verbose)\n",
    "    print('\\n')\n",
    "    print(f'model_set={[m.model_name for m in models_cfg]};   score={svr_score}')\n",
    "    return svr_score, models_cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112340f7",
   "metadata": {
    "papermill": {
     "duration": 0.00669,
     "end_time": "2022-11-05T07:00:26.257566",
     "exception": false,
     "start_time": "2022-11-05T07:00:26.250876",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## models selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b9a0178",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-05T07:00:26.272600Z",
     "iopub.status.busy": "2022-11-05T07:00:26.272324Z",
     "iopub.status.idle": "2022-11-05T07:00:26.276280Z",
     "shell.execute_reply": "2022-11-05T07:00:26.275364Z"
    },
    "papermill": {
     "duration": 0.013592,
     "end_time": "2022-11-05T07:00:26.278274",
     "exception": false,
     "start_time": "2022-11-05T07:00:26.264682",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model_selection = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "404772c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-05T07:00:26.293427Z",
     "iopub.status.busy": "2022-11-05T07:00:26.293143Z",
     "iopub.status.idle": "2022-11-05T07:00:26.298003Z",
     "shell.execute_reply": "2022-11-05T07:00:26.296856Z"
    },
    "papermill": {
     "duration": 0.014444,
     "end_time": "2022-11-05T07:00:26.299811",
     "exception": false,
     "start_time": "2022-11-05T07:00:26.285367",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if model_selection:\n",
    "#     for i, first_model in enumerate(tqdm(pretrained_models_cfg[1:])):\n",
    "#         features = [first_model]\n",
    "#         prev_score,_ = get_learner_score(features)\n",
    "#         cur_score = 0\n",
    "        \n",
    "#         while True:\n",
    "#             models = [feat.model for feat in features]\n",
    "#             if len(models) == len(pretrained_models_cfg):\n",
    "#                 break\n",
    "                \n",
    "#             scores_and_cfgs = [get_learner_score(features + [feat], folds=15, save=False) for feat in pretrained_models_cfg if feat.model not in models]\n",
    "#             scores = [s for s,c in scores_and_cfgs]\n",
    "#             cur_features = [c for s,c in scores_and_cfgs]\n",
    "            \n",
    "#             cur_score = np.min(scores)\n",
    "#             cur_best_feature = cur_features[np.argmin(scores)][-1]\n",
    "#             features.append(cur_best_feature)\n",
    "            \n",
    "#             if prev_score < cur_score:\n",
    "#                 break\n",
    "#             prev_score = cur_score\n",
    "\n",
    "#             del scores_and_cfgs, scores, cur_best_feature, cur_features; gc.collect(); torch.cuda.empty_cache();\n",
    "        \n",
    "#         LOGGER.info(f'Interation {i+1}:')\n",
    "#         LOGGER.info(f'model_set={[c.model_name for c in features]} \\nbest_score={cur_score}')\n",
    "#         LOGGER.info('#'*50)\n",
    "#         LOGGER.info('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc8fdcc",
   "metadata": {
    "papermill": {
     "duration": 0.006556,
     "end_time": "2022-11-05T07:00:26.313207",
     "exception": false,
     "start_time": "2022-11-05T07:00:26.306651",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab82928c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-05T07:00:26.328129Z",
     "iopub.status.busy": "2022-11-05T07:00:26.327409Z",
     "iopub.status.idle": "2022-11-05T07:00:26.332319Z",
     "shell.execute_reply": "2022-11-05T07:00:26.331540Z"
    },
    "papermill": {
     "duration": 0.014259,
     "end_time": "2022-11-05T07:00:26.334224",
     "exception": false,
     "start_time": "2022-11-05T07:00:26.319965",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pretrained_models_cfg = [\n",
    "    deberta_large_mnli,\n",
    "    #gpt2,\n",
    "    roberta_base,\n",
    "    roberta_large,\n",
    "    xlnet_base, \n",
    "    xlnet_large,\n",
    "    deberta_base, \n",
    "    deberta_large, \n",
    "    deberta_xlarge,\n",
    "    deberta_v2_xlarge, \n",
    "    deberta_v2_xxlarge,\n",
    "    deberta_v3_base, \n",
    "    deberta_v3_large,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f8b35b2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-05T07:00:26.349585Z",
     "iopub.status.busy": "2022-11-05T07:00:26.348720Z",
     "iopub.status.idle": "2022-11-05T07:01:51.671569Z",
     "shell.execute_reply": "2022-11-05T07:01:51.670041Z"
    },
    "papermill": {
     "duration": 85.332647,
     "end_time": "2022-11-05T07:01:51.673771",
     "exception": false,
     "start_time": "2022-11-05T07:00:26.341124",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "### Fold 1\n",
      "Score: 0.46036991672104327\n",
      "#########################\n",
      "### Fold 2\n",
      "Score: 0.4461142351611702\n",
      "#########################\n",
      "### Fold 3\n",
      "Score: 0.4483841221822375\n",
      "#########################\n",
      "### Fold 4\n",
      "Score: 0.4568929046034717\n",
      "#########################\n",
      "### Fold 5\n",
      "Score: 0.44665398575332343\n",
      "#########################\n",
      "### Fold 6\n",
      "Score: 0.45275467273950154\n",
      "#########################\n",
      "### Fold 7\n",
      "Score: 0.43822989587095157\n",
      "#########################\n",
      "### Fold 8\n",
      "Score: 0.43293964881454805\n",
      "#########################\n",
      "### Fold 9\n",
      "Score: 0.45818536836483276\n",
      "#########################\n",
      "### Fold 10\n",
      "Score: 0.45667026984938164\n",
      "#########################\n",
      "### Fold 11\n",
      "Score: 0.44427934861003954\n",
      "#########################\n",
      "### Fold 12\n",
      "Score: 0.44977603527807614\n",
      "#########################\n",
      "### Fold 13\n",
      "Score: 0.44303583629441784\n",
      "#########################\n",
      "### Fold 14\n",
      "Score: 0.45850549197320206\n",
      "#########################\n",
      "### Fold 15\n",
      "Score: 0.4565811447434837\n",
      "\n",
      "\n",
      "model_set=['deberta_large_mnli', 'roberta_base', 'roberta_large', 'xlnet_base_cased', 'xlnet_large_cased', 'deberta_base', 'deberta_large', 'deberta_xlarge', 'deberta_v2_xlarge', 'deberta_v2_xxlarge', 'deberta_v3_base', 'deberta_v3_large'];   score=0.4499581917973121\n"
     ]
    }
   ],
   "source": [
    "# learner = Ridge(alpha=2.0)\n",
    "learner = SVR(C=2.0)\n",
    "svr_score, models_cfg = get_learner_score(pretrained_models_cfg, learner, folds=svr_folds, save=True, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8266e38",
   "metadata": {
    "papermill": {
     "duration": 0.057364,
     "end_time": "2022-11-05T07:01:53.650021",
     "exception": false,
     "start_time": "2022-11-05T07:01:53.592657",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b8069352",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-05T07:01:54.187321Z",
     "iopub.status.busy": "2022-11-05T07:01:54.186755Z",
     "iopub.status.idle": "2022-11-05T07:05:39.635720Z",
     "shell.execute_reply": "2022-11-05T07:05:39.634588Z"
    },
    "papermill": {
     "duration": 225.940779,
     "end_time": "2022-11-05T07:05:39.638643",
     "exception": false,
     "start_time": "2022-11-05T07:01:53.697864",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe8b55a77d434246b1777d1b45e521f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../input/huggingface-deberta-variants/deberta-large-mnli/deberta-large-mnli were not used when initializing DebertaModel: ['config', 'classifier.weight', 'classifier.bias', 'pooler.dense.weight', 'pooler.dense.bias']\n",
      "- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../input/huggingface-deberta-variants/deberta-large-mnli/deberta-large-mnli loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../input/transformers/roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../input/transformers/roberta-base loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../input/transformers/roberta-large were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../input/transformers/roberta-large loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../input/transformers/xlnet-base-cased were not used when initializing XLNetModel: ['lm_loss.bias', 'lm_loss.weight']\n",
      "- This IS expected if you are initializing XLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../input/transformers/xlnet-base-cased loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../input/transformers/xlnet-large-cased were not used when initializing XLNetModel: ['lm_loss.bias', 'lm_loss.weight']\n",
      "- This IS expected if you are initializing XLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../input/transformers/xlnet-large-cased loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../input/huggingface-deberta-variants/deberta-base/deberta-base were not used when initializing DebertaModel: ['lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'config', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.bias']\n",
      "- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../input/huggingface-deberta-variants/deberta-base/deberta-base loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../input/huggingface-deberta-variants/deberta-large/deberta-large were not used when initializing DebertaModel: ['lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'config', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.bias']\n",
      "- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../input/huggingface-deberta-variants/deberta-large/deberta-large loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../input/huggingface-deberta-variants/deberta-xlarge/deberta-xlarge were not used when initializing DebertaModel: ['lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.bias']\n",
      "- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../input/huggingface-deberta-variants/deberta-xlarge/deberta-xlarge loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at ../input/bert-shopping-mall/deberta-v2-xlarge were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.bias']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../input/bert-shopping-mall/deberta-v2-xlarge loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at ../input/bert-shopping-mall/deberta-v2-xxlarge were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.bias']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../input/bert-shopping-mall/deberta-v2-xxlarge loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at ../input/bert-shopping-mall/deberta-v3-base were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.LayerNorm.bias', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.bias']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../input/bert-shopping-mall/deberta-v3-base loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at ../input/bert-shopping-mall/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.LayerNorm.bias', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.bias']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../input/bert-shopping-mall/deberta-v3-large loaded.\n"
     ]
    }
   ],
   "source": [
    "all_test_text_emb = []\n",
    "for cfg in tqdm(pretrained_models_cfg):\n",
    "    test_text_emb = get_text_embedding(cfg, [test])[0]\n",
    "    all_test_text_emb.append(test_text_emb)\n",
    "    \n",
    "    del test_text_emb; gc.collect(); torch.cuda.empty_cache();\n",
    "    print(f'{cfg.model} loaded.')\n",
    "    \n",
    "gc.collect(); torch.cuda.empty_cache();\n",
    "\n",
    "final_test_text_emb = np.concatenate(all_test_text_emb, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa97320b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-05T07:05:39.660735Z",
     "iopub.status.busy": "2022-11-05T07:05:39.659854Z",
     "iopub.status.idle": "2022-11-05T07:06:47.617208Z",
     "shell.execute_reply": "2022-11-05T07:06:47.615850Z"
    },
    "papermill": {
     "duration": 67.970859,
     "end_time": "2022-11-05T07:06:47.620226",
     "exception": false,
     "start_time": "2022-11-05T07:05:39.649367",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "844525c31b88485aab467a21787e5926",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[2.9248888, 2.792115 , 3.1469035, 2.9696906, 2.6993976, 2.646963 ],\n",
       "       [2.7048204, 2.4654028, 2.738452 , 2.3113449, 2.043009 , 2.6602888],\n",
       "       [3.6800659, 3.4587038, 3.5982437, 3.6568944, 3.4008143, 3.3531375]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "def svr_inference_fn(model_path, te_text_feats):\n",
    "    model = load(model_path)\n",
    "    preds = model.predict(te_text_feats)\n",
    "    return preds\n",
    "\n",
    "predictions = []\n",
    "svr_model_paths = glob.glob('./*.model')\n",
    "for model_path in tqdm(svr_model_paths):\n",
    "    #model_path = os.path.join('../input/fb3-svr-train/', model_path)\n",
    "    preds = svr_inference_fn(model_path, final_test_text_emb)\n",
    "    predictions.append(preds)\n",
    "svr_predictions = np.mean(predictions, axis=0)\n",
    "svr_predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b59f54",
   "metadata": {
    "papermill": {
     "duration": 0.009932,
     "end_time": "2022-11-05T07:06:47.641232",
     "exception": false,
     "start_time": "2022-11-05T07:06:47.631300",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd86521b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-05T06:16:01.717783Z",
     "iopub.status.busy": "2022-11-05T06:16:01.717240Z",
     "iopub.status.idle": "2022-11-05T06:16:01.737870Z",
     "shell.execute_reply": "2022-11-05T06:16:01.736820Z",
     "shell.execute_reply.started": "2022-11-05T06:16:01.717669Z"
    },
    "papermill": {
     "duration": 0.009779,
     "end_time": "2022-11-05T07:06:47.660473",
     "exception": false,
     "start_time": "2022-11-05T07:06:47.650694",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# fine-tuned models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b8668729",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-05T07:06:47.682880Z",
     "iopub.status.busy": "2022-11-05T07:06:47.681942Z",
     "iopub.status.idle": "2022-11-05T07:06:48.291449Z",
     "shell.execute_reply": "2022-11-05T07:06:48.290441Z"
    },
    "papermill": {
     "duration": 0.623777,
     "end_time": "2022-11-05T07:06:48.293844",
     "exception": false,
     "start_time": "2022-11-05T07:06:47.670067",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "v21_CFG = load_config('../input/fb3models/v21/', inference_weight=1)\n",
    "v21_CFG.version = '21'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(os.path.join(v21_CFG.path, 'tokenizer'))\n",
    "v21_CFG.tokenizer = tokenizer\n",
    "v21_CFG.pretrained = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f74e7eb7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-05T07:06:48.317933Z",
     "iopub.status.busy": "2022-11-05T07:06:48.317627Z",
     "iopub.status.idle": "2022-11-05T07:06:48.342374Z",
     "shell.execute_reply": "2022-11-05T07:06:48.341332Z"
    },
    "papermill": {
     "duration": 0.039731,
     "end_time": "2022-11-05T07:06:48.344337",
     "exception": false,
     "start_time": "2022-11-05T07:06:48.304606",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv(TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "29aab1e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-05T07:06:48.366207Z",
     "iopub.status.busy": "2022-11-05T07:06:48.364812Z",
     "iopub.status.idle": "2022-11-05T07:07:31.041568Z",
     "shell.execute_reply": "2022-11-05T07:07:31.040517Z"
    },
    "papermill": {
     "duration": 42.691012,
     "end_time": "2022-11-05T07:07:31.045161",
     "exception": false,
     "start_time": "2022-11-05T07:06:48.354149",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25e1fbe343c74396b239b6244b2adc00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## ../input/fb3models/v21/ ##########\n",
      "Predicting fold 0...\n",
      "Predicting fold 1...\n",
      "Predicting fold 2...\n",
      "Predicting fold 3...\n",
      "########## ETA: 42.60s ########## \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2.9639993, 2.809734 , 3.1962726, 3.038265 , 2.7567317, 2.6906934],\n",
       "       [2.783099 , 2.4626253, 2.754807 , 2.4375708, 2.2829118, 2.6027486],\n",
       "       [3.4688654, 3.2758214, 3.4783115, 3.4387808, 3.399209 , 3.2090838]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fine_tuned_models_cfg = [v21_CFG]\n",
    "\n",
    "fine_tuned_predictions = []\n",
    "total_weight = 0\n",
    "for cfg in tqdm(fine_tuned_models_cfg):\n",
    "    # infer_ = Inferencer(setup['path'], setup['inference_weight'])\n",
    "    infer_ = Inferencer(cfg=cfg, inference_weight=cfg.inference_weight)\n",
    "    \n",
    "    test_dataset = TestDataset(cfg, test)\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=3,\n",
    "        shuffle=False,\n",
    "        collate_fn=DataCollatorWithPadding(tokenizer=cfg.tokenizer, padding='longest'),\n",
    "        num_workers=1, \n",
    "        pin_memory=True, \n",
    "        drop_last=False)\n",
    "    prediction = infer_.predict(test_loader, device) * cfg.inference_weight\n",
    "    \n",
    "    fine_tuned_predictions.append(prediction)\n",
    "    total_weight += cfg.inference_weight\n",
    "    \n",
    "    del infer_, test_dataset, test_loader, prediction; gc.collect; torch.cuda.empty_cache();\n",
    "    \n",
    "final_fine_tuned_predictions = np.sum(fine_tuned_predictions, axis=0)/total_weight    \n",
    "final_fine_tuned_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fef01d9",
   "metadata": {
    "papermill": {
     "duration": 0.010153,
     "end_time": "2022-11-05T07:07:31.065901",
     "exception": false,
     "start_time": "2022-11-05T07:07:31.055748",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "335a02cd",
   "metadata": {
    "papermill": {
     "duration": 0.009697,
     "end_time": "2022-11-05T07:07:31.085524",
     "exception": false,
     "start_time": "2022-11-05T07:07:31.075827",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# combine & submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6b4264f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-05T07:07:31.106591Z",
     "iopub.status.busy": "2022-11-05T07:07:31.106267Z",
     "iopub.status.idle": "2022-11-05T07:07:31.117051Z",
     "shell.execute_reply": "2022-11-05T07:07:31.116017Z"
    },
    "papermill": {
     "duration": 0.023703,
     "end_time": "2022-11-05T07:07:31.119067",
     "exception": false,
     "start_time": "2022-11-05T07:07:31.095364",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_predictions = (svr_predictions + final_fine_tuned_predictions)/2\n",
    "final_predictions = np.clip(final_predictions, 1, 5)\n",
    "test[target_cols] = final_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f730d182",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-05T07:07:31.140506Z",
     "iopub.status.busy": "2022-11-05T07:07:31.139721Z",
     "iopub.status.idle": "2022-11-05T07:07:31.194806Z",
     "shell.execute_reply": "2022-11-05T07:07:31.193945Z"
    },
    "papermill": {
     "duration": 0.06789,
     "end_time": "2022-11-05T07:07:31.196957",
     "exception": false,
     "start_time": "2022-11-05T07:07:31.129067",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>cohesion</th>\n",
       "      <th>syntax</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>phraseology</th>\n",
       "      <th>grammar</th>\n",
       "      <th>conventions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000C359D63E</td>\n",
       "      <td>2.944444</td>\n",
       "      <td>2.800925</td>\n",
       "      <td>3.171588</td>\n",
       "      <td>3.003978</td>\n",
       "      <td>2.728065</td>\n",
       "      <td>2.668828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000BAD50D026</td>\n",
       "      <td>2.743960</td>\n",
       "      <td>2.464014</td>\n",
       "      <td>2.746629</td>\n",
       "      <td>2.374458</td>\n",
       "      <td>2.162961</td>\n",
       "      <td>2.631519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00367BB2546B</td>\n",
       "      <td>3.574466</td>\n",
       "      <td>3.367263</td>\n",
       "      <td>3.538278</td>\n",
       "      <td>3.547838</td>\n",
       "      <td>3.400012</td>\n",
       "      <td>3.281111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text_id  cohesion    syntax  vocabulary  phraseology   grammar  conventions\n",
       "0  0000C359D63E  2.944444  2.800925    3.171588     3.003978  2.728065     2.668828\n",
       "1  000BAD50D026  2.743960  2.464014    2.746629     2.374458  2.162961     2.631519\n",
       "2  00367BB2546B  3.574466  3.367263    3.538278     3.547838  3.400012     3.281111"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "submission = pd.read_csv(SUBMISSION_PATH)\n",
    "submission = submission.drop(columns=target_cols).merge(test[['text_id'] + target_cols], on='text_id', how='left')\n",
    "display(submission.head())\n",
    "submission[['text_id'] + target_cols].to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb3a638",
   "metadata": {
    "papermill": {
     "duration": 0.009986,
     "end_time": "2022-11-05T07:07:31.216966",
     "exception": false,
     "start_time": "2022-11-05T07:07:31.206980",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 473.566168,
   "end_time": "2022-11-05T07:07:35.067836",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-11-05T06:59:41.501668",
   "version": "2.3.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0acb7dee2a194be9b93121c18a75a56d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "0adff95fa5834bfd8e15ba56fdcf21e8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "0e8e97e546bc4ba3b25252d03693a1ac": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "10d6d14d641847fd80bf086b2f708964": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1221b6060e754350897f0ecc47a10575": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_4e3710498ede43ffae7444aab62f94ef",
       "placeholder": "​",
       "style": "IPY_MODEL_0adff95fa5834bfd8e15ba56fdcf21e8",
       "value": "100%"
      }
     },
     "25e1fbe343c74396b239b6244b2adc00": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_1221b6060e754350897f0ecc47a10575",
        "IPY_MODEL_b0d754b5985244ef8c9bdcd49c9e1f11",
        "IPY_MODEL_27a8997529804136bf77eeb487a52892"
       ],
       "layout": "IPY_MODEL_10d6d14d641847fd80bf086b2f708964"
      }
     },
     "27a8997529804136bf77eeb487a52892": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_35ac9e6a3c914676a0a97533e71d1d1b",
       "placeholder": "​",
       "style": "IPY_MODEL_452a5e83c97245b489c2c68c95f8c646",
       "value": " 1/1 [00:42&lt;00:00, 42.66s/it]"
      }
     },
     "2fa09a4133bf4f4293b7f44118877011": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "35ac9e6a3c914676a0a97533e71d1d1b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "41d6488f6a054716a92e8fa075b76a6c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ff8cbdacb5684319addded8a14350edc",
       "max": 15.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_0acb7dee2a194be9b93121c18a75a56d",
       "value": 15.0
      }
     },
     "452a5e83c97245b489c2c68c95f8c646": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "4ba59acd1d084adf89ef3e0e085e6e9a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4e3710498ede43ffae7444aab62f94ef": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "56c89bb038a14f66b9fc2e31d79219b5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "5dcc5dca7a9d4cc493a30aac52f9337d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "6d22f32f61ce4256b3722cf7be7b0b40": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_0e8e97e546bc4ba3b25252d03693a1ac",
       "placeholder": "​",
       "style": "IPY_MODEL_5dcc5dca7a9d4cc493a30aac52f9337d",
       "value": "100%"
      }
     },
     "844525c31b88485aab467a21787e5926": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_ab796dea7ea9439eb60d34e681448303",
        "IPY_MODEL_41d6488f6a054716a92e8fa075b76a6c",
        "IPY_MODEL_958e5296fe2d494982e35162c79341b1"
       ],
       "layout": "IPY_MODEL_c7ef9eff56ce4b0d88089a16230f07f3"
      }
     },
     "8c3a8fea250346cea19fff21c55a2ef1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "9241aed3befd44ca978438139186d4a7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "93c199d34c14487d85e9bd6033eccc7c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_b4aef6de9fdc4ab78a0b9ace89221d57",
       "max": 12.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_2fa09a4133bf4f4293b7f44118877011",
       "value": 12.0
      }
     },
     "958e5296fe2d494982e35162c79341b1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a4f4379989e040e3987e4b432316fc29",
       "placeholder": "​",
       "style": "IPY_MODEL_9241aed3befd44ca978438139186d4a7",
       "value": " 15/15 [01:07&lt;00:00,  4.51s/it]"
      }
     },
     "9ff95abebc5247d7b6373fdb3b03626d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a4f4379989e040e3987e4b432316fc29": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ab796dea7ea9439eb60d34e681448303": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_9ff95abebc5247d7b6373fdb3b03626d",
       "placeholder": "​",
       "style": "IPY_MODEL_56c89bb038a14f66b9fc2e31d79219b5",
       "value": "100%"
      }
     },
     "b038401228344bdca2f777f8cbcbd66b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b0d754b5985244ef8c9bdcd49c9e1f11": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_b038401228344bdca2f777f8cbcbd66b",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_8c3a8fea250346cea19fff21c55a2ef1",
       "value": 1.0
      }
     },
     "b4aef6de9fdc4ab78a0b9ace89221d57": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b5ea37ae17d642d2a8900b4918729dae": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_4ba59acd1d084adf89ef3e0e085e6e9a",
       "placeholder": "​",
       "style": "IPY_MODEL_e1295b36d43441ae92cd0c318456be98",
       "value": " 12/12 [03:45&lt;00:00, 20.72s/it]"
      }
     },
     "c1e586e2f03b45fe894ffc606ca8fc9e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c7ef9eff56ce4b0d88089a16230f07f3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e1295b36d43441ae92cd0c318456be98": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "fe8b55a77d434246b1777d1b45e521f2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_6d22f32f61ce4256b3722cf7be7b0b40",
        "IPY_MODEL_93c199d34c14487d85e9bd6033eccc7c",
        "IPY_MODEL_b5ea37ae17d642d2a8900b4918729dae"
       ],
       "layout": "IPY_MODEL_c1e586e2f03b45fe894ffc606ca8fc9e"
      }
     },
     "ff8cbdacb5684319addded8a14350edc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
