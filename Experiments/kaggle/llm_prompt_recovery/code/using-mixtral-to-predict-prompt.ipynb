{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6779d076",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T03:47:46.507139Z",
     "iopub.status.busy": "2024-04-16T03:47:46.506790Z",
     "iopub.status.idle": "2024-04-16T03:48:25.268429Z",
     "shell.execute_reply": "2024-04-16T03:48:25.267226Z"
    },
    "papermill": {
     "duration": 38.769967,
     "end_time": "2024-04-16T03:48:25.270873",
     "exception": false,
     "start_time": "2024-04-16T03:47:46.500906",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -U /kaggle/input/bitsandbytes-0-42-0-py3-none-any-whl/bitsandbytes-0.42.0-py3-none-any.whl -qq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c6490d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T03:48:25.281165Z",
     "iopub.status.busy": "2024-04-16T03:48:25.280814Z",
     "iopub.status.idle": "2024-04-16T04:02:32.485516Z",
     "shell.execute_reply": "2024-04-16T04:02:32.484450Z"
    },
    "papermill": {
     "duration": 847.212786,
     "end_time": "2024-04-16T04:02:32.488082",
     "exception": false,
     "start_time": "2024-04-16T03:48:25.275296",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c72f3957ae1a43a89b59ff379fdb262e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, AutoConfig\n",
    "\n",
    "\n",
    "# MODEL_PATH = \"/kaggle/input/mixtral/pytorch/8x7b-instruct-v0.1-hf/1\"\n",
    "MODEL_PATH = \"/kaggle/input/mixtral/pytorch/8x7b-instruct-v0.1-hf/1\"\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit = True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "# To prevent GPU memory overflow in Mixtral8x7b\n",
    "config = AutoConfig.from_pretrained(MODEL_PATH)\n",
    "config.gradient_checkpointing = True\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_PATH,\n",
    "    device_map = \"auto\",\n",
    "    trust_remote_code = True,\n",
    "    quantization_config=quantization_config,\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6213b6ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T04:02:32.499115Z",
     "iopub.status.busy": "2024-04-16T04:02:32.498649Z",
     "iopub.status.idle": "2024-04-16T04:02:34.349461Z",
     "shell.execute_reply": "2024-04-16T04:02:34.348469Z"
    },
    "papermill": {
     "duration": 1.864784,
     "end_time": "2024-04-16T04:02:34.357782",
     "exception": false,
     "start_time": "2024-04-16T04:02:32.492998",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>original_text</th>\n",
       "      <th>rewritten_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>The competition dataset comprises text passage...</td>\n",
       "      <td>Here is your shanty: (Verse 1) The text is rew...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                      original_text  \\\n",
       "0  -1  The competition dataset comprises text passage...   \n",
       "\n",
       "                                      rewritten_text  \n",
       "0  Here is your shanty: (Verse 1) The text is rew...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "tdf = pd.read_csv('/kaggle/input/llm-prompt-recovery/test.csv')\n",
    "display(tdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acdfc167",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T04:02:34.369425Z",
     "iopub.status.busy": "2024-04-16T04:02:34.369128Z",
     "iopub.status.idle": "2024-04-16T04:02:34.380615Z",
     "shell.execute_reply": "2024-04-16T04:02:34.379746Z"
    },
    "papermill": {
     "duration": 0.019984,
     "end_time": "2024-04-16T04:02:34.382732",
     "exception": false,
     "start_time": "2024-04-16T04:02:34.362748",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def truncate_txt(text, length):\n",
    "    text_list = text.split()\n",
    "    if len(text_list) <= length:\n",
    "        return text    \n",
    "    return \" \".join(text_list[:length])\n",
    "\n",
    "\n",
    "def gen_prompt_sample(og_text, rewritten_text):\n",
    "    og_text = truncate_txt(og_text, 256)\n",
    "    rewritten_text = truncate_txt(rewritten_text, 256)\n",
    "    \n",
    "    return f\"\"\"\n",
    "    Original Essay:\n",
    "    \\\"\"\"{og_text}\\\"\"\"\n",
    "\n",
    "    Rewritten Essay:\n",
    "    \\\"\"\"{rewritten_text}\\\"\"\"\n",
    "\n",
    "    Given are 2 essays, the Rewritten essay was created from the Original essay using the google Gemma model.\n",
    "    You are trying to understand how the original essay was transformed into a new version.\n",
    "    Analyzing the changes in style, theme, etc., please come up with a prompt that must have been used to guide the transformation from the original to the rewritten essay.\n",
    "    Keep your output concise, to the point(only the prompt), and less than a 100 words.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "SAMPLE_OUTPUT = \"\"\"Please improve the following text using the writing style of, maintaining the original meaning but altering the tone, diction, and stylistic elements to match the new style.Enhance the clarity, elegance, and impact of the following text by adopting the writing style of , ensuring the core message remains intact while transforming the tone, word choice, and stylistic features to align with the specified style.\"\"\"\n",
    "\n",
    "SAMPLE_OUTPUT_1 = \"\"\"Please improve this text using the writing style with maintaining the original meaning but altering the tone.\"\"\"\n",
    "\n",
    "SAMPLE_OUTPUT_2 = \"\"\"Refine the following passage by emulating the writing style of, with a focus on enhancing its clarity, elegance, and overall impact. Preserve the essence and original meaning of the text, while meticulously adjusting its tone, vocabulary, and stylistic elements to resonate with the chosen style.Please improve the following text using the writing style of, maintaining the original meaning but altering the tone, diction, and stylistic elements to match the new style.Enhance the clarity, elegance, and impact of the following text by adopting the writing style of , ensuring the core message remains intact while transforming the tone, word choice, and stylistic features to align with the specified style.\"\"\"\n",
    "\n",
    "SAMPLE_OUTPUT_3 = \"\"\"Please improve this text using the writing style with maintaining the original meaning but altering the tone, ensuring the core message remains intact while transforming the tone, word choice, and stylistic features to align with the specified style.\"\"\"\n",
    "\n",
    "\n",
    "def gen_prompt(og_text, rewritten_text):\n",
    "    \n",
    "    # Truncate the texts to first 200 words for now\n",
    "    # As we are having memory issues on Mixtral8x7b\n",
    "    og_text = truncate_txt(og_text, 256)\n",
    "    rewritten_text = truncate_txt(rewritten_text, 256)\n",
    "    \n",
    "    return f\"\"\"    \n",
    "    Original Essay:\n",
    "    \\\"\"\"{og_text}\\\"\"\"\n",
    "    \n",
    "    Rewritten Essay:\n",
    "    \\\"\"\"{rewritten_text}\\\"\"\"\n",
    "    \n",
    "    Given are 2 essays, the Rewritten essay was created from the Original essay using the google Gemma model.\n",
    "    You are trying to understand how the original essay was transformed into a new version.\n",
    "    Analyzing the changes in style, theme, etc., please come up with a prompt that must have been used to guide the transformation from the original to the rewritten essay.\n",
    "    Keep your output concise, to the point(only the prompt), and less than a 100 words.\n",
    "    Make sure that the generated prompt is in the format of \"Please improve this text by [adding a magician].\".\n",
    "    \n",
    "    Sample output:\n",
    "    \\\"\"\"{SAMPLE_OUTPUT}\\\"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "def gen_prompt_1(og_text, rewritten_text):\n",
    "    \n",
    "    # Truncate the texts to first 200 words for now\n",
    "    # As we are having memory issues on Mixtral8x7b\n",
    "    og_text = truncate_txt(og_text, 256)\n",
    "    rewritten_text = truncate_txt(rewritten_text, 256)\n",
    "    \n",
    "    return f\"\"\"    \n",
    "    Original Essay:\n",
    "    \\\"\"\"{og_text}\\\"\"\"\n",
    "    \n",
    "    Rewritten Essay:\n",
    "    \\\"\"\"{rewritten_text}\\\"\"\"\n",
    "    \n",
    "    Given are 2 essays, the Rewritten essay was created from the Original essay using the google Gemma model.\n",
    "    You are trying to understand how the original essay was transformed into a new version.\n",
    "    Analyzing the changes in style, theme, etc., please come up with a prompt that must have been used to guide the transformation from the original to the rewritten essay.\n",
    "    Keep your output concise, to the point(only the prompt), and less than a 100 words.\n",
    "\n",
    "    Sample output:\n",
    "    {SAMPLE_OUTPUT_1}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fb6ca3a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T04:02:34.393517Z",
     "iopub.status.busy": "2024-04-16T04:02:34.393213Z",
     "iopub.status.idle": "2024-04-16T04:02:34.409747Z",
     "shell.execute_reply": "2024-04-16T04:02:34.408762Z"
    },
    "papermill": {
     "duration": 0.024571,
     "end_time": "2024-04-16T04:02:34.412072",
     "exception": false,
     "start_time": "2024-04-16T04:02:34.387501",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>rewrite_prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9559194</td>\n",
       "      <td>Improve that text.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id      rewrite_prompt\n",
       "0  9559194  Improve that text."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "device = 'cuda'\n",
    "sub = pd.read_csv('/kaggle/input/llm-prompt-recovery/sample_submission.csv')\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ddea7ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T04:02:34.423536Z",
     "iopub.status.busy": "2024-04-16T04:02:34.423258Z",
     "iopub.status.idle": "2024-04-16T04:02:34.429866Z",
     "shell.execute_reply": "2024-04-16T04:02:34.428745Z"
    },
    "papermill": {
     "duration": 0.014872,
     "end_time": "2024-04-16T04:02:34.432037",
     "exception": false,
     "start_time": "2024-04-16T04:02:34.417165",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub[\"rewrite_prompt\"] = str(SAMPLE_OUTPUT_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a94baeb2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T04:02:34.443329Z",
     "iopub.status.busy": "2024-04-16T04:02:34.443037Z",
     "iopub.status.idle": "2024-04-16T04:02:34.446752Z",
     "shell.execute_reply": "2024-04-16T04:02:34.445830Z"
    },
    "papermill": {
     "duration": 0.011656,
     "end_time": "2024-04-16T04:02:34.448827",
     "exception": false,
     "start_time": "2024-04-16T04:02:34.437171",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tdf.loc[0,'id'] = 9559194\n",
    "# tdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ad38c02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T04:02:34.459435Z",
     "iopub.status.busy": "2024-04-16T04:02:34.459159Z",
     "iopub.status.idle": "2024-04-16T04:03:14.870921Z",
     "shell.execute_reply": "2024-04-16T04:03:14.870004Z"
    },
    "papermill": {
     "duration": 40.428665,
     "end_time": "2024-04-16T04:03:14.882298",
     "exception": false,
     "start_time": "2024-04-16T04:02:34.453633",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]2024-04-16 04:02:48.400315: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-16 04:02:48.400447: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-16 04:02:48.651645: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL:          id                                     rewrite_prompt\n",
      "0  9559194  Please improve this text using the writing sty...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:40, 40.39s/it]\n"
     ]
    }
   ],
   "source": [
    "for row in tqdm(tdf.itertuples()):\n",
    "    try:\n",
    "    \n",
    "        query_prompt = gen_prompt(row[2], row[3])\n",
    "#         query_prompt = gen_prompt_sample(row[2], row[3])\n",
    "        \n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": query_prompt\n",
    "            }\n",
    "        ]\n",
    "#         messages = [\n",
    "#             {\n",
    "#                 \"role\": \"user\",\n",
    "#                 \"content\": query_prompt\n",
    "#             },\n",
    "#             {\n",
    "#                 \"role\": \"assistant\",\n",
    "#                 \"content\": f\"\"\"Sample prompt:\n",
    "#                 \\\"\"\"{SAMPLE_OUTPUT}\\\"\"\"\n",
    "#                 \"\"\"\n",
    "#             }\n",
    "#         ]\n",
    "\n",
    "#         encoded_input = tokenizer(query_prompt, return_tensors=\"pt\").to(device)\n",
    "        inputs = tokenizer.apply_chat_template(messages, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "        with torch.no_grad():\n",
    "            encoded_output = model.generate(inputs, max_new_tokens=80, do_sample=True, pad_token_id=tokenizer.eos_token_id)\n",
    "\n",
    "        decoded_output = tokenizer.decode(encoded_output[0], skip_special_tokens=True).replace(query_prompt, '').replace(\"[INST]\", \"\").replace(\"[/INST]\", \"\").strip()\n",
    "    \n",
    "        sub.loc[sub['id'] == row[1], 'rewrite_prompt'] = decoded_output.replace('Prediction:','').replace('prediction:','').replace('Sample Output:', '').replace('output:', '')\n",
    "\n",
    "        print(\"FINAL: \", sub)\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        sub.loc[sub['id'] == row[1], 'rewrite_prompt'] = str(SAMPLE_OUTPUT_1)\n",
    "#     finally:\n",
    "#         if not (sub['id'] == row[1]).any():\n",
    "#             sub.loc[sub['id'] == row[1], 'rewrite_prompt'] = str(SAMPLE_OUTPUT_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7c448b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T04:03:14.897616Z",
     "iopub.status.busy": "2024-04-16T04:03:14.897068Z",
     "iopub.status.idle": "2024-04-16T04:03:14.914367Z",
     "shell.execute_reply": "2024-04-16T04:03:14.913510Z"
    },
    "papermill": {
     "duration": 0.026412,
     "end_time": "2024-04-16T04:03:14.916428",
     "exception": false,
     "start_time": "2024-04-16T04:03:14.890016",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub.to_csv(\"submission.csv\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98685736",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T04:03:14.927925Z",
     "iopub.status.busy": "2024-04-16T04:03:14.927626Z",
     "iopub.status.idle": "2024-04-16T04:03:14.932756Z",
     "shell.execute_reply": "2024-04-16T04:03:14.931858Z"
    },
    "papermill": {
     "duration": 0.012942,
     "end_time": "2024-04-16T04:03:14.934830",
     "exception": false,
     "start_time": "2024-04-16T04:03:14.921888",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please improve this text using the writing style with maintaining the original meaning but altering the tone.\n"
     ]
    }
   ],
   "source": [
    "print(sub.iloc[0]['rewrite_prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5b40f3",
   "metadata": {
    "papermill": {
     "duration": 0.004834,
     "end_time": "2024-04-16T04:03:14.944781",
     "exception": false,
     "start_time": "2024-04-16T04:03:14.939947",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 7806901,
     "sourceId": 67121,
     "sourceType": "competition"
    },
    {
     "datasetId": 4281572,
     "sourceId": 7369493,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelInstanceId": 3104,
     "sourceId": 4309,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelInstanceId": 3900,
     "sourceId": 5112,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelInstanceId": 4761,
     "sourceId": 5994,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelInstanceId": 8318,
     "sourceId": 11382,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelInstanceId": 8332,
     "sourceId": 11394,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30665,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 935.378056,
   "end_time": "2024-04-16T04:03:17.877087",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-16T03:47:42.499031",
   "version": "2.5.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "011010e92922479bb5d0acc06e881cae": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "20b00900fe9e4f1399cb3723233cf85d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "2ff39fe902894bd8861c8797a6605e9f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6b1898fb2d0c42c092eac12f64e5c56e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_710e4c53832c4f98ac8ab693ed8b12d7",
       "placeholder": "​",
       "style": "IPY_MODEL_8181f5d4c697481dab78d73d032ddf59",
       "value": "Loading checkpoint shards: 100%"
      }
     },
     "710e4c53832c4f98ac8ab693ed8b12d7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8181f5d4c697481dab78d73d032ddf59": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "aaf8b5844bad4225bf430b2ef5c636e4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_011010e92922479bb5d0acc06e881cae",
       "placeholder": "​",
       "style": "IPY_MODEL_20b00900fe9e4f1399cb3723233cf85d",
       "value": " 19/19 [13:47&lt;00:00, 41.26s/it]"
      }
     },
     "bd22e6276014410c9373d4f4110be289": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_2ff39fe902894bd8861c8797a6605e9f",
       "max": 19.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_e6ed2ec5c1324f9ba54250407a059fce",
       "value": 19.0
      }
     },
     "c72f3957ae1a43a89b59ff379fdb262e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_6b1898fb2d0c42c092eac12f64e5c56e",
        "IPY_MODEL_bd22e6276014410c9373d4f4110be289",
        "IPY_MODEL_aaf8b5844bad4225bf430b2ef5c636e4"
       ],
       "layout": "IPY_MODEL_fb9e17c9840c4142a1c390beb54e63c1"
      }
     },
     "e6ed2ec5c1324f9ba54250407a059fce": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "fb9e17c9840c4142a1c390beb54e63c1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
