{"cells":[{"cell_type":"markdown","id":"6dacf133","metadata":{"id":"6dacf133"},"source":["# Our SAWYER Process"]},{"cell_type":"markdown","id":"60ea3c2a","metadata":{"id":"60ea3c2a"},"source":["# Step 2: Training SAWYER's Reward Model using Human Preferences"]},{"cell_type":"code","execution_count":null,"id":"7cd73d82","metadata":{"id":"7cd73d82","outputId":"1abeec85-842e-4fba-a009-cba49c654c22"},"outputs":[{"data":{"text/plain":["device(type='cuda')"]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["import os\n","import torch\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n","device = torch.device(\"cuda\")\n","\n","device"]},{"cell_type":"code","execution_count":null,"id":"d709bec4","metadata":{"id":"d709bec4"},"outputs":[],"source":["import os\n","\n","import torch\n","import evaluate\n","import numpy as np\n","import torch.nn as nn\n","from dataclasses import dataclass, field\n","from typing import Any, Dict, List, Optional, Union\n","from datasets import load_dataset\n","from transformers import (\n","    AutoConfig,\n","    AutoModelForSequenceClassification,\n","    AutoTokenizer,\n","    HfArgumentParser,\n","    PreTrainedTokenizerBase,\n","    Trainer,\n","    TrainingArguments,\n","    set_seed,\n",")\n","from transformers.utils import PaddingStrategy\n"]},{"cell_type":"markdown","id":"c5e1ecf4","metadata":{"id":"c5e1ecf4"},"source":["comparison_data_v2.json ranked responses from LLMs including:\n","\n","1. GPT-4\n","2. GPT-3.5\n","3. OPT-IML\n","4. DaVinci (InstructGPT)\n","\n","by asking GPT-4 to rate the quality.\n","\n","Each data element has keys:\n","\n","- user_input: str, prompts used for quering LLMs.\n","- responses_and_scores: list[str], list of\n","    - response: the response from the LLM\n","    - source: the LLM that generated the response\n","    - score: Score given to the response (from GPT-4)\n"]},{"cell_type":"code","execution_count":null,"id":"1dd22b4a","metadata":{"id":"1dd22b4a"},"outputs":[],"source":["import json\n","c = json.load(open('../data/comparison_data_v2.json'))"]},{"cell_type":"code","execution_count":null,"id":"2ae5bcb4","metadata":{"id":"2ae5bcb4","outputId":"68e82aaf-7eca-4381-9dc5-0326f8d0dda3"},"outputs":[{"data":{"text/plain":["{'user_input': 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nDescribe the importance of renewable energy',\n"," 'responses_and_scores': [{'response': 'Renewable energy is becoming increasingly important in our world today as we strive to reduce our dependence on fossil fuels and shift to more sustainable sources of energy. Renewable energy sources such as wind, solar, and hydropower provide clean and reliable energy that can be used to power our homes, businesses, and vehicles. Renewable energy is also more cost-effective and efficient compared to other sources of energy. Additionally, renewable energy sources generate little to no pollution and greenhouse gas emissions, helping to reduce climate change. Renewable energy also helps to reduce our reliance on foreign countries for oil imports, thus making our nation more secure. Renewable energy is an important part of building a more sustainable future for our planet.',\n","   'score': 9.0,\n","   'source': 'text-davinci-003'},\n","  {'response': 'Renewable energy is an essential aspect of modern life, as it plays a crucial role in protecting the environment, reducing our dependence on finite resources, and promoting a sustainable and secure future. There are several reasons why renewable energy is so important, including:\\n\\n1. Environmental protection: Renewable energy sources, like solar, wind, and hydroelectric power, produce significantly fewer emissions than traditional fossil fuels. This means that by relying more on renewable energy, we can reduce our carbon footprint and reduce the harmful effects of climate change.\\n\\n2. Sustainability: Traditional fossil fuels are finite resources, meaning that they will eventually run out. Renewable energy, on the other hand, is sourced from natural and sustainable resources, like the sun, wind, and water, which are constantly replenished and will never run out. By embracing renewable energy, we can develop a more sustainable energy system that guarantees a reliable and secure supply for future generations.\\n\\n3. Economic benefits: The renewable energy industry is growing at an unprecedented rate, creating new jobs and opportunities for economic growth. By investing in renewable energy, we can support local economies, reduce energy costs, and reduce our dependence on foreign oil.\\n\\n4. Energy security: By generating electricity from renewable sources, we can reduce our reliance on foreign oil and gas, which can be subject to price fluctuations and supply disruptions. This makes our energy system more resilient and secure, reducing the risk of power outages or price spikes.\\n\\nIn conclusion, renewable energy is essential for a sustainable, secure, and prosperous future. By investing in renewable energy, we can protect the environment, promote economic growth, and ensure that future generations have access to reliable and affordable energy.',\n","   'score': 9.0,\n","   'source': 'gpt4'},\n","  {'response': 'Renewable energy is energy that is produced from renewable sources.',\n","   'score': 3.0,\n","   'source': 'icm-1.3b'}]}"]},"execution_count":38,"metadata":{},"output_type":"execute_result"}],"source":["c[345]"]},{"cell_type":"code","execution_count":null,"id":"32aa2746","metadata":{"id":"32aa2746","outputId":"4281be6b-e7f0-4299-d69c-7ec80e37a9f2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Below is an instruction that describes a task. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Describe the importance of renewable energy\n"]}],"source":["print(c[345]['user_input'])"]},{"cell_type":"code","execution_count":null,"id":"4f4639ff","metadata":{"id":"4f4639ff","outputId":"5215dab2-7abf-4c76-ad77-25c9dff875f7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Response: Renewable energy is becoming increasingly important in our world today as we strive to reduce our dependence on fossil fuels and shift to more sustainable sources of energy. Renewable energy sources such as wind, solar, and hydropower provide clean and reliable energy that can be used to power our homes, businesses, and vehicles. Renewable energy is also more cost-effective and efficient compared to other sources of energy. Additionally, renewable energy sources generate little to no pollution and greenhouse gas emissions, helping to reduce climate change. Renewable energy also helps to reduce our reliance on foreign countries for oil imports, thus making our nation more secure. Renewable energy is an important part of building a more sustainable future for our planet.\n","Source: text-davinci-003\n","Score: 9.0\n","----\n","Response: Renewable energy is an essential aspect of modern life, as it plays a crucial role in protecting the environment, reducing our dependence on finite resources, and promoting a sustainable and secure future. There are several reasons why renewable energy is so important, including:\n","\n","1. Environmental protection: Renewable energy sources, like solar, wind, and hydroelectric power, produce significantly fewer emissions than traditional fossil fuels. This means that by relying more on renewable energy, we can reduce our carbon footprint and reduce the harmful effects of climate change.\n","\n","2. Sustainability: Traditional fossil fuels are finite resources, meaning that they will eventually run out. Renewable energy, on the other hand, is sourced from natural and sustainable resources, like the sun, wind, and water, which are constantly replenished and will never run out. By embracing renewable energy, we can develop a more sustainable energy system that guarantees a reliable and secure supply for future generations.\n","\n","3. Economic benefits: The renewable energy industry is growing at an unprecedented rate, creating new jobs and opportunities for economic growth. By investing in renewable energy, we can support local economies, reduce energy costs, and reduce our dependence on foreign oil.\n","\n","4. Energy security: By generating electricity from renewable sources, we can reduce our reliance on foreign oil and gas, which can be subject to price fluctuations and supply disruptions. This makes our energy system more resilient and secure, reducing the risk of power outages or price spikes.\n","\n","In conclusion, renewable energy is essential for a sustainable, secure, and prosperous future. By investing in renewable energy, we can protect the environment, promote economic growth, and ensure that future generations have access to reliable and affordable energy.\n","Source: gpt4\n","Score: 9.0\n","----\n","Response: Renewable energy is energy that is produced from renewable sources.\n","Source: icm-1.3b\n","Score: 3.0\n","----\n"]}],"source":["for response in c[345]['responses_and_scores']:\n","    print(f'Response: {response[\"response\"]}')\n","    print(f'Source: {response[\"source\"]}')\n","    print(f'Score: {response[\"score\"]}')\n","    print('----')"]},{"cell_type":"code","execution_count":null,"id":"afbe1978","metadata":{"id":"afbe1978"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"a3a7f40e","metadata":{"scrolled":true,"colab":{"referenced_widgets":["c77e2bc7fb5047639900819d7caf1d54","fe0158484f16423f8abbc412267efd94",""]},"id":"a3a7f40e","outputId":"0603a5d6-a9ed-44cc-a394-f89de1b4e629"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading and preparing dataset json/default to /Users/sinanozdemir/.cache/huggingface/datasets/json/default-20104efc7083c999/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c77e2bc7fb5047639900819d7caf1d54","version_major":2,"version_minor":0},"text/plain":["Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fe0158484f16423f8abbc412267efd94","version_major":2,"version_minor":0},"text/plain":["Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Generating train split: 0 examples [00:00, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Dataset json downloaded and prepared to /Users/sinanozdemir/.cache/huggingface/datasets/json/default-20104efc7083c999/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4. Subsequent calls will reuse this data.\n"]}],"source":["set_seed(42)\n","\n","dataset = load_dataset(\"json\", data_files='../data/comparison_data_v2.json', split=\"train\")\n"]},{"cell_type":"code","execution_count":null,"id":"7d5afd47","metadata":{"id":"7d5afd47","outputId":"a12b9d19-6ddb-46f4-f0d4-5c06b29aa585"},"outputs":[{"data":{"text/plain":["{'responses_and_scores': [{'response': 'Telegram',\n","   'score': 10.0,\n","   'source': 'text-davinci-003'},\n","  {'response': 'The odd one out is Telegram. Twitter and Instagram are social media platforms mainly for sharing information, images and videos while Telegram is a cloud-based instant messaging and voice-over-IP service.',\n","   'score': 9.0,\n","   'source': 'gpt4'},\n","  {'response': 'Instagram', 'score': 9.0, 'source': 'icm-1.3b'}],\n"," 'user_input': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nIdentify the odd one out.\\n\\n### Input:\\nTwitter, Instagram, Telegram'}"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["dataset[5]"]},{"cell_type":"code","execution_count":null,"id":"0facd22f","metadata":{"id":"0facd22f"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"b209ecc8","metadata":{"id":"b209ecc8"},"outputs":[],"source":["def get_score_tuples(dictionary):\n","    responses = dictionary['responses_and_scores']\n","    tuples = []\n","\n","    for i in range(len(responses)):\n","        for j in range(i + 1, len(responses)):\n","            response_i = responses[i]\n","            response_j = responses[j]\n","            score_i = response_i['score']\n","            score_j = response_j['score']\n","\n","            if score_i > score_j:\n","                score_difference = score_i - score_j\n","                tuples.append(((response_i['response'], score_i), (response_j['response'], score_j), score_difference))\n","\n","    return tuples\n"]},{"cell_type":"code","execution_count":null,"id":"17bbcd28","metadata":{"id":"17bbcd28"},"outputs":[],"source":["new_examples = []\n","for row in dataset:\n","    for pair in get_score_tuples(row):\n","        new_examples.append({\n","            'instruction': row['user_input'].split('### Instruction:\\n')[-1].replace('### Input:\\n', ''),\n","            'text_j': pair[0][0],\n","            'text_k': pair[1][0],\n","            'score_diff': pair[2]\n","        })"]},{"cell_type":"code","execution_count":null,"id":"2454e7f1","metadata":{"id":"2454e7f1","outputId":"9df74885-4143-4fa0-b039-a4bd39605710"},"outputs":[{"data":{"text/plain":["95147"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["len(new_examples)"]},{"cell_type":"code","execution_count":null,"id":"60393bf0","metadata":{"id":"60393bf0","outputId":"dc813a7f-a20f-4bc6-b9e1-b8d45ec22a50"},"outputs":[{"data":{"text/plain":["{'instruction': 'Give three tips for staying healthy.',\n"," 'text_j': '1.Eat a balanced diet and make sure to include plenty of fruits and vegetables. \\n2. Exercise regularly to keep your body active and strong. \\n3. Get enough sleep and maintain a consistent sleep schedule.',\n"," 'text_k': 'Eat healthy, exercise, and sleep.',\n"," 'score_diff': 1.0}"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["new_examples[0]"]},{"cell_type":"code","execution_count":null,"id":"a5d3bc2b","metadata":{"id":"a5d3bc2b","outputId":"2d1b9c1e-981f-48e6-c273-ded899215a45"},"outputs":[{"data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['instruction', 'text_j', 'text_k', 'score_diff'],\n","        num_rows: 76117\n","    })\n","    test: Dataset({\n","        features: ['instruction', 'text_j', 'text_k', 'score_diff'],\n","        num_rows: 19030\n","    })\n","})"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["from datasets import Dataset\n","\n","pairs_dataset = Dataset.from_list(new_examples)\n","pairs_dataset = pairs_dataset.train_test_split(train_size=.8, seed=42)\n","pairs_dataset"]},{"cell_type":"code","execution_count":null,"id":"6a1c4cca","metadata":{"id":"6a1c4cca","outputId":"6072c748-f0a6-4b38-929a-3bcd522efee5"},"outputs":[{"data":{"text/plain":["{'instruction': 'How did the Battle of Gettysburg change the course of the American Civil War?',\n"," 'text_j': 'The Battle of Gettysburg, fought from July 1 to July 3 1863, is considered one of the most important and decisive battles in the American Civil War as it marked a major turning point in the conflict. Before the battle, the Confederate army, commanded by General Robert E. Lee, had been enjoying a string of victories and launched an invasion of the Northern states, hoping that a major victory on Northern soil would demoralize the Union and force them to seek peace. However, the Union army, led by General George G. Meade, was able to successfully repel the Confederate attack in a bloody and costly battle, with an estimated 23,000 Union and 28,000 Confederate casualties.\\n\\nThe Union victory at Gettysburg, along with the capture of the Confederate stronghold of Vicksburg on July 4 1863, changed the momentum of the war in favor of the Union. The Confederate army was forced to retreat, severely weakened, and was unable to launch another major offensive operation. The battle also boosted the morale of the Union army, and President Abraham Lincoln used the victory to reframe the war as a struggle not just for the preservation of the Union, but as a fight against slavery with the issuance of the Gettysburg Address in November of that year.\\n\\nFrom a strategic standpoint, it proved to be a lost opportunity for the Confederacy, as they never again had the chance to launch a major invasion of the North. The battle also depleted much of their manpower, and losses of that scale could not be recovered. It meant that, from that point on, they were largely on the defensive, fighting to protect their own territory.\\n\\nIn summary, the Battle of Gettysburg represented a major turning point in the course of the American Civil War. It stopped the Confederate advance in the North, depleted their resources, and boosted Union morale, encouraging them to continue the fight.',\n"," 'text_k': 'The battle of Gettysburg changed the course of the war.',\n"," 'score_diff': 6.0}"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["pairs_dataset['test'][0]"]},{"cell_type":"code","execution_count":null,"id":"167bffe2","metadata":{"colab":{"referenced_widgets":["50204aea344b48aba5ddce0c9985089a"]},"id":"167bffe2","outputId":"0596e05a-f1a4-48c2-abcc-d0ead6d39bf7"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"50204aea344b48aba5ddce0c9985089a","version_major":2,"version_minor":0},"text/plain":["Downloading model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight']\n","- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["training_args = TrainingArguments(\n","    output_dir='sawyer_rm',\n","    per_device_train_batch_size=8,\n","    per_device_eval_batch_size=32,\n","    num_train_epochs=2,\n","    evaluation_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    gradient_accumulation_steps=4,\n","    save_total_limit=5,\n","    remove_unused_columns=False,\n","    label_names=[],\n","    fp16=True,\n","    load_best_model_at_end=True,\n","    logging_strategy=\"steps\",\n","    logging_steps=10,\n",")\n","\n","# Using a cross-encoder to encode question and answer together to produce a score\n","#  This is an expected use-case for a cross-encoder, just like we used them in our semantic search\n","#  system to perform re-ranking\n","\n","model_name = 'roberta-base'\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","config = AutoConfig.from_pretrained(model_name)\n","\n","model = AutoModelForSequenceClassification.from_pretrained(\n","    model_name, num_labels=1,\n",")\n"]},{"cell_type":"code","execution_count":null,"id":"d28120e9","metadata":{"id":"d28120e9"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"578de7a9","metadata":{"scrolled":true,"colab":{"referenced_widgets":[""]},"id":"578de7a9","outputId":"224c4ec9-77d7-4d4a-bad5-25e81aa7ca33"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/76117 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/19030 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# Turn the dataset into pairs of input + output, where text_j is the preferred question + answer and text_k is the other.\n","# Then tokenize the dataset.\n","def preprocess_function(example):\n","    new_examples = {\n","        \"input_ids_j\": [],\n","        \"attention_mask_j\": [],\n","        \"input_ids_k\": [],\n","        \"attention_mask_k\": [],\n","        \"score_diff\": []\n","    }\n","\n","    new_examples['score_diff'].append(example['score_diff'])\n","    question = example[\"instruction\"]\n","    tokenized_j = tokenizer(question, example['text_j'], truncation=True)\n","    tokenized_k = tokenizer(question, example['text_k'], truncation=True)\n","\n","    new_examples[\"input_ids_j\"].append(tokenized_j[\"input_ids\"])\n","    new_examples[\"attention_mask_j\"].append(tokenized_j[\"attention_mask\"])\n","    new_examples[\"input_ids_k\"].append(tokenized_k[\"input_ids\"])\n","    new_examples[\"attention_mask_k\"].append(tokenized_k[\"attention_mask\"])\n","\n","    return new_examples\n","\n","# preprocess the dataset and filter out QAs that are longer than max_length\n","pairs_dataset = pairs_dataset.map(preprocess_function, batched=False)\n"]},{"cell_type":"code","execution_count":null,"id":"d7d13dd6","metadata":{"id":"d7d13dd6"},"outputs":[],"source":["pairs_dataset.set_format('pt')"]},{"cell_type":"code","execution_count":null,"id":"69dcd56a","metadata":{"id":"69dcd56a","outputId":"11ea4836-4671-4d37-97ad-823cdfa67769"},"outputs":[{"data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['instruction', 'text_j', 'text_k', 'score_diff', 'input_ids_j', 'attention_mask_j', 'input_ids_k', 'attention_mask_k'],\n","        num_rows: 76117\n","    })\n","    test: Dataset({\n","        features: ['instruction', 'text_j', 'text_k', 'score_diff', 'input_ids_j', 'attention_mask_j', 'input_ids_k', 'attention_mask_k'],\n","        num_rows: 19030\n","    })\n","})"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["pairs_dataset"]},{"cell_type":"code","execution_count":null,"id":"949550ae","metadata":{"id":"949550ae","outputId":"8203ecbd-491b-4118-f2a7-1e4f9f5d0695"},"outputs":[{"data":{"text/plain":["{'instruction': 'Write an article about climate change.',\n"," 'text_j': \"Climate change is one of the most pressing and urgent issues of the modern world. It is an ever-evolving environmental threat that threatens the planet's future, especially with regards to the natural environment that we as humans depend upon. Over the decades, the scientific community has recorded a consistent and steady rise in global temperatures that can only be attributed to the increasing concentrations of Greenhouse gases in the atmosphere due to our continued burning of fossil fuels. This has sparked a chain reaction of catastrophic events that is wreaking havoc on the planet, such as extreme weather events, melting of polar ice caps and the ocean rising to unprecedented levels, threatening the future of entire cities and coastal areas.\\n\\nThe urgency of this global crisis is only compounded by the fact that climate change is happening much faster than predicted. This means that in order to maintain a livable and functioning planet, drastic measures need to be taken immediately on a global scale. Governments, industry and citizens alike will need to significantly reduce emissions and transition to renewable energy sources in order to avoid a future we cannot imagine. \\n\\nWith the technology and knowledge available to us, the task of mitigating and adapting to climate change is not insurmountable. But in order to save our planet, collective action is needed - and fast.\",\n"," 'text_k': \"I can't write an article about climate change.\",\n"," 'score_diff': tensor([5.]),\n"," 'input_ids_j': tensor([[    0, 45714,    41,  1566,    59,  2147,   464,     4,     2,     2,\n","          40466,   464,    16,    65,     9,     5,   144, 10275,     8,  9047,\n","            743,     9,     5,  2297,   232,     4,    85,    16,    41,   655,\n","             12,  3623, 21241,  3039,  1856,    14, 13546,     5,  5518,    18,\n","            499,     6,   941,    19, 11246,     7,     5,  1632,  1737,    14,\n","             52,    25,  5868,  6723,  2115,     4,  2306,     5,  1724,     6,\n","              5,  6441,   435,    34,  2673,    10,  4292,     8,  5204,  1430,\n","             11,   720,  3971,    14,    64,   129,    28,  9702,     7,     5,\n","           2284, 26069,     9,  1628,  3138, 20038,    11,     5,  5466,   528,\n","              7,    84,  1143,  6574,     9, 11422, 12174,     4,   152,    34,\n","           6246,    10,  3206,  4289,     9, 15532,  1061,    14,    16, 21679,\n","           7520, 19705,    15,     5,  5518,     6,   215,    25,  5004,  1650,\n","           1061,     6, 23187,     9, 13744,  2480,  9686,     8,     5,  6444,\n","           2227,     7,  7071,  1389,     6,  5608,     5,   499,     9,  1445,\n","           1947,     8,  8095,   911,     4, 50118, 50118,   133, 14195,     9,\n","             42,   720,  1486,    16,   129, 24094,    30,     5,   754,    14,\n","           2147,   464,    16,  2909,   203,  3845,    87,  6126,     4,   152,\n","            839,    14,    11,   645,     7,  3014,    10, 32126,   868,     8,\n","          13838,  5518,     6, 19167,  1797,   240,     7,    28,   551,  1320,\n","             15,    10,   720,  3189,     4, 26581,     6,   539,     8,  2286,\n","           9829,    40,   240,     7,  3625,  1888,  5035,     8,  3868,     7,\n","           8741,  1007,  1715,    11,   645,     7,  1877,    10,   499,    52,\n","           1395,  4744,     4,  1437, 50118, 50118,  3908,     5,   806,     8,\n","           2655,   577,     7,   201,     6,     5,  3685,     9, 31904,     8,\n","          26493,     7,  2147,   464,    16,    45, 36686, 17336,   868,     4,\n","            125,    11,   645,     7,  1871,    84,  5518,     6,  6981,   814,\n","             16,   956,   111,     8,  1769,     4,     2]]),\n"," 'attention_mask_j': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","          1, 1, 1]]),\n"," 'input_ids_k': tensor([[    0, 45714,    41,  1566,    59,  2147,   464,     4,     2,     2,\n","            100,    64,    75,  3116,    41,  1566,    59,  2147,   464,     4,\n","              2]]),\n"," 'attention_mask_k': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["pairs_dataset['train'][5]"]},{"cell_type":"code","execution_count":null,"id":"257e93c0","metadata":{"id":"257e93c0"},"outputs":[],"source":["# We need to define a special data collator that batches the data in our j vs k format.\n","@dataclass\n","class RewardDataCollatorWithPadding:\n","    tokenizer: PreTrainedTokenizerBase\n","    padding: Union[bool, str, PaddingStrategy] = True\n","    max_length: Optional[int] = None\n","    pad_to_multiple_of: Optional[int] = None\n","    return_tensors: str = \"pt\"\n","\n","    def __call__(self, features: List[Dict[str, Any]]) -> Dict[str, Any]:\n","        features_j = []\n","        features_k = []\n","        for feature in features:\n","            features_j.append(\n","                {\n","                    \"input_ids\": feature[\"input_ids_j\"].squeeze(),\n","                    \"attention_mask\": feature[\"attention_mask_j\"].squeeze(),\n","                }\n","            )\n","            features_k.append(\n","                {\n","                    \"input_ids\": feature[\"input_ids_k\"].squeeze(),\n","                    \"attention_mask\": feature[\"attention_mask_k\"].squeeze(),\n","                }\n","            )\n","        batch_j = self.tokenizer.pad(\n","            features_j,\n","            padding=self.padding,\n","            max_length=self.max_length,\n","            pad_to_multiple_of=self.pad_to_multiple_of,\n","            return_tensors=self.return_tensors,\n","        )\n","        batch_k = self.tokenizer.pad(\n","            features_k,\n","            padding=self.padding,\n","            max_length=self.max_length,\n","            pad_to_multiple_of=self.pad_to_multiple_of,\n","            return_tensors=self.return_tensors,\n","        )\n","        batch = {\n","            \"input_ids_j\": batch_j[\"input_ids\"],\n","            \"attention_mask_j\": batch_j[\"attention_mask\"],\n","            \"input_ids_k\": batch_k[\"input_ids\"],\n","            \"attention_mask_k\": batch_k[\"attention_mask\"],\n","            \"score_diff\": [feature['score_diff'] for feature in features],\n","            \"return_loss\": True,\n","        }\n","        return batch\n","\n","# Define the metric that we'll use for validation.\n","accuracy = evaluate.load(\"accuracy\")\n"]},{"cell_type":"code","execution_count":null,"id":"5effdbd9","metadata":{"id":"5effdbd9"},"outputs":[],"source":["def compute_metrics(eval_pred):\n","    predictions, _ = eval_pred\n","    # Here, predictions is rewards_j and rewards_k.\n","    # We want to see how much of the time rewards_j > rewards_k.\n","    predictions = np.argmax(predictions, axis=0)\n","    labels = np.zeros(predictions.shape)\n","    return accuracy.compute(predictions=predictions, references=labels)\n","\n","# We are subclassing the Hugging Face Trainer class to customize the loss computation\n","class RewardTrainer(Trainer):\n","    # Overriding the compute_loss function to define how to compute the loss for our specific task\n","    def compute_loss(self, model, inputs, return_outputs=False):\n","        # Calculate the reward for a preferred response y_j using the model. The input IDs and attention masks for y_j are provided in inputs.\n","        rewards_j = model(input_ids=inputs[\"input_ids_j\"], attention_mask=inputs[\"attention_mask_j\"])[0]\n","\n","        # Similarly, calculate the reward for a lesser preferred response y_k.\n","        rewards_k = model(input_ids=inputs[\"input_ids_k\"], attention_mask=inputs[\"attention_mask_k\"])[0]\n","\n","        # Calculate the loss using the negative log-likelihood function.\n","        # We take the difference of rewards (rewards_j - rewards_k) and multiply it by the squared score difference provided in the inputs.\n","        # Then, we apply the sigmoid function (via torch.nn.functional.logsigmoid) and negate the result.\n","        # The mean loss is calculated across all examples in the batch.\n","        loss = -nn.functional.logsigmoid((rewards_j - rewards_k) * torch.pow(torch.tensor(inputs['score_diff'], device=rewards_j.device), 2)).mean()\n","\n","        # If we also want to return the outputs (rewards for y_j and y_k) along with the loss, we do so.\n","        if return_outputs:\n","            return loss, {\"rewards_j\": rewards_j, \"rewards_k\": rewards_k}\n","\n","        # Otherwise, we simply return the computed loss.\n","        return loss\n"]},{"cell_type":"code","execution_count":null,"id":"e99acd95","metadata":{"id":"e99acd95","outputId":"5190631c-c71d-41d2-fb09-304989505aca"},"outputs":[{"data":{"text/plain":["RobertaTokenizerFast(name_or_path='roberta-base', vocab_size=50265, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=False)}, clean_up_tokenization_spaces=True)"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer"]},{"cell_type":"code","execution_count":null,"id":"8a373a07","metadata":{"scrolled":true,"id":"8a373a07","outputId":"c1ab19e7-2477-4173-edf6-7926d177d6d0"},"outputs":[{"name":"stderr","output_type":"stream","text":["You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='596' max='298' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [298/298 3:25:34]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mprofoz\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"data":{"text/html":["wandb version 0.15.2 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.15.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>C:\\Users\\sinan\\Desktop\\wandb\\run-20230513_210736-9e36q1mc</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/profoz/huggingface/runs/9e36q1mc' target=\"_blank\">efficient-wildflower-111</a></strong> to <a href='https://wandb.ai/profoz/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/profoz/huggingface' target=\"_blank\">https://wandb.ai/profoz/huggingface</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/profoz/huggingface/runs/9e36q1mc' target=\"_blank\">https://wandb.ai/profoz/huggingface/runs/9e36q1mc</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'eval_loss': 0.6885457634925842,\n"," 'eval_accuracy': 0.5417761429322123,\n"," 'eval_runtime': 813.115,\n"," 'eval_samples_per_second': 23.404,\n"," 'eval_steps_per_second': 0.366}"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["# Train the model, woohoo.\n","trainer = RewardTrainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=pairs_dataset['train'],\n","    eval_dataset=pairs_dataset['test'],\n","    compute_metrics=compute_metrics,\n","    data_collator=RewardDataCollatorWithPadding(tokenizer=tokenizer, max_length=512, padding='max_length'),\n",")\n","\n","trainer.evaluate()\n"]},{"cell_type":"code","execution_count":null,"id":"5dc657fb","metadata":{"scrolled":true,"id":"5dc657fb","outputId":"eb1226f6-bfe5-4a9f-db47-4ae2f0f8d5ff"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\sinan\\anaconda3\\envs\\DL\\lib\\site-packages\\transformers\\optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","C:\\Users\\sinan\\anaconda3\\envs\\DL\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n","  warnings.warn('PyTorch is not compiled with NCCL support')\n","Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2378' max='2378' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2378/2378 6:17:15, Epoch 1/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>0.168500</td>\n","      <td>0.171356</td>\n","      <td>0.979506</td>\n","    </tr>\n","    <tr>\n","      <td>1</td>\n","      <td>0.252800</td>\n","      <td>0.247183</td>\n","      <td>0.984025</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["C:\\Users\\sinan\\anaconda3\\envs\\DL\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n","  warnings.warn('PyTorch is not compiled with NCCL support')\n"]},{"data":{"text/plain":["TrainOutput(global_step=2378, training_loss=0.17534620220216007, metrics={'train_runtime': 22647.7603, 'train_samples_per_second': 6.722, 'train_steps_per_second': 0.105, 'total_flos': 0.0, 'train_loss': 0.17534620220216007, 'epoch': 2.0})"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["trainer.train()\n"]},{"cell_type":"code","execution_count":null,"id":"774a7ab7","metadata":{"id":"774a7ab7"},"outputs":[],"source":["# Let's use the model after 1 epoch with the losest validation loss. We care less about the raw accuracy and\n","#  more about the loss we constructed"]},{"cell_type":"code","execution_count":null,"id":"39cdf680","metadata":{"id":"39cdf680"},"outputs":[],"source":["trainer.save_model()"]},{"cell_type":"code","execution_count":null,"id":"e616a64a","metadata":{"id":"e616a64a","outputId":"863d9cf9-5ba7-4f9c-e9ee-e833548a6954"},"outputs":[{"data":{"text/plain":["RobertaTokenizerFast(name_or_path='roberta-base', vocab_size=50265, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=False)}, clean_up_tokenization_spaces=True)"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer"]},{"cell_type":"code","execution_count":null,"id":"099bc6cc","metadata":{"id":"099bc6cc","outputId":"f70f709a-0ec9-49a3-8d7f-08fd8ee196bc"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n"]}],"source":["tokenizer.save_pretrained(training_args.output_dir+'\\\\tokenizer')"]},{"cell_type":"code","execution_count":null,"id":"a47b1d04","metadata":{"id":"a47b1d04","outputId":"e6b2d2bb-b33a-4109-90ec-97b3fdad330a"},"outputs":[{"data":{"text/plain":["['<s>How did the Battle of Gettysburg change the course of the American Civil War?</s></s>The battle of Gettysburg changed the course of the war.</s>']"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer.batch_decode(pairs_dataset['test'][0]['input_ids_k'])"]},{"cell_type":"code","execution_count":null,"id":"6088d3c3","metadata":{"id":"6088d3c3"},"outputs":[],"source":["trained_model = AutoModelForSequenceClassification.from_pretrained(\n","    'sawyer_rm', num_labels=1,\n",")\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n"]},{"cell_type":"code","execution_count":null,"id":"8f1fb042","metadata":{"id":"8f1fb042","outputId":"06866157-7892-4f05-e5e3-7f7fc5011a97"},"outputs":[{"data":{"text/plain":["tensor([[-3.0824]], grad_fn=<AddmmBackward0>)"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["# I would expect a negative reward here\n","outputs = trained_model(**tokenizer('how do I greet someone?', 'Tell them to frick off', return_tensors='pt')).logits\n","outputs"]},{"cell_type":"code","execution_count":null,"id":"196246b5","metadata":{"id":"196246b5"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"e4011b14","metadata":{"id":"e4011b14"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}